<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta name="google-adsense-account" content="ca-pub-6504473922193740">
        <title>Apache Kafka 做中學 - Ich bin yiwen.</title><meta name="Description" content="An ordinary space for storing and groups pieces of articles."><meta property="og:url" content="http://wysiwyz.github.io/posts/kk_learn_by_doing_apache_kafka/">
  <meta property="og:site_name" content="Ich bin yiwen.">
  <meta property="og:title" content="Apache Kafka 做中學">
  <meta property="og:description" content="這篇是根據 KK Learn By Doing: Beginner’s Guide to Apache Kafka - Foundation and Development 所做的筆記與實作紀錄。
學習目標是要能夠將 Kafka architecture 以及 essential components 套用在服務紀錄需求面，只是這 2.5 小時的課可能還是遠遠不夠，都有人把 Kafka 寫成 30 篇系列文章了。
A distributed event streaming platform, widely used for building real-time data pipelines and applications
01 introduction to Kafka Kafka 是開源分布式事件串流平台 (open-sourced, distributed, event streaming platform)，由 Apache Software Foundation 開發，原本是 LinkedIn 建立，在 2011 年開源。
Kafka 是設計來處理實時資料，協助組織建構穩定、可擴充、且容錯率高的資料管線。
Core components Producer : 將 record 送往 Kafka topics 的 app，負責選擇要將 record 送到該 topic 中的哪一個 partition Consumer : 從 Kafka topics 讀取 record 的 app，consumer 訂閱 topics 並將訊息作即時處理 Broker : 運行 Kafka 的伺服器，broker 從 producer 接收訊息，存在 disk，再將其發送到 consumers。一個 Kafka cluster 包含多個 brokers，用來確保負載平衡與容錯率 Topic : 是一個 logical channel，使 producer 用以發送 record，consumer 用以讀取 record。為了平行化與可擴張性，topic 會分片 (partitioned) Partition: 每個 topic 都拆分成 partitions，這個 partition 是有序且不可變的紀錄序列 (sequence of records)，使 Kafka 能夠水平擴展並在每個 partition 裡面維持紀錄順序 ZooKeeper or Kraft: 用來做分布式協調、配置管理、Kafka broker 與 topics 的主節點選舉 Kafka architecture Topics &amp; Partitions: Topic 再切分成 partitions，partition 是平行化跟可擴張性的基礎單位。每一個 partition 都是有序不可變的紀錄序列。partition 當中的每一個 record 都會分配到一個唯一的偏移量 (unique offset)。partitions 使得 Kafka 藉由分布式資料以及負載於多個 brokers 這兩種方式，達到可擴展性。 Producers &amp; Consumers: Kafka 支援 pub-sub 模型，多個 conusmer 可以訂閱到相同一個 topic，並獨立處理 data。 Brokers &amp; Clusters: Kafka broker 負責儲存與提供資料。Kafka cluster 包含多個 brokers 用來確保容錯性與高可用性。Brokers 分布在不同個 machines 以避免硬體故障造成資料遺失。 Zooker Coordination : Zookeeper 或 KRaft 管理配置檔以及 Kafka broker 之間合作，協助進行 partitions 主節點選舉，追蹤 broker metadata。但 Kafka 從 verion 2.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-12-03T11:11:57+08:00">
    <meta property="article:modified_time" content="2024-12-03T11:11:57+08:00">
    <meta property="article:tag" content="Apache">
    <meta property="article:tag" content="Kafka">
    <meta property="article:tag" content="Kodekloud">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Apache Kafka 做中學">
  <meta name="twitter:description" content="這篇是根據 KK Learn By Doing: Beginner’s Guide to Apache Kafka - Foundation and Development 所做的筆記與實作紀錄。
學習目標是要能夠將 Kafka architecture 以及 essential components 套用在服務紀錄需求面，只是這 2.5 小時的課可能還是遠遠不夠，都有人把 Kafka 寫成 30 篇系列文章了。
A distributed event streaming platform, widely used for building real-time data pipelines and applications
01 introduction to Kafka Kafka 是開源分布式事件串流平台 (open-sourced, distributed, event streaming platform)，由 Apache Software Foundation 開發，原本是 LinkedIn 建立，在 2011 年開源。
Kafka 是設計來處理實時資料，協助組織建構穩定、可擴充、且容錯率高的資料管線。
Core components Producer : 將 record 送往 Kafka topics 的 app，負責選擇要將 record 送到該 topic 中的哪一個 partition Consumer : 從 Kafka topics 讀取 record 的 app，consumer 訂閱 topics 並將訊息作即時處理 Broker : 運行 Kafka 的伺服器，broker 從 producer 接收訊息，存在 disk，再將其發送到 consumers。一個 Kafka cluster 包含多個 brokers，用來確保負載平衡與容錯率 Topic : 是一個 logical channel，使 producer 用以發送 record，consumer 用以讀取 record。為了平行化與可擴張性，topic 會分片 (partitioned) Partition: 每個 topic 都拆分成 partitions，這個 partition 是有序且不可變的紀錄序列 (sequence of records)，使 Kafka 能夠水平擴展並在每個 partition 裡面維持紀錄順序 ZooKeeper or Kraft: 用來做分布式協調、配置管理、Kafka broker 與 topics 的主節點選舉 Kafka architecture Topics &amp; Partitions: Topic 再切分成 partitions，partition 是平行化跟可擴張性的基礎單位。每一個 partition 都是有序不可變的紀錄序列。partition 當中的每一個 record 都會分配到一個唯一的偏移量 (unique offset)。partitions 使得 Kafka 藉由分布式資料以及負載於多個 brokers 這兩種方式，達到可擴展性。 Producers &amp; Consumers: Kafka 支援 pub-sub 模型，多個 conusmer 可以訂閱到相同一個 topic，並獨立處理 data。 Brokers &amp; Clusters: Kafka broker 負責儲存與提供資料。Kafka cluster 包含多個 brokers 用來確保容錯性與高可用性。Brokers 分布在不同個 machines 以避免硬體故障造成資料遺失。 Zooker Coordination : Zookeeper 或 KRaft 管理配置檔以及 Kafka broker 之間合作，協助進行 partitions 主節點選舉，追蹤 broker metadata。但 Kafka 從 verion 2.">
<meta name="application-name" content="Ich bin yiwen.">
<meta name="apple-mobile-web-app-title" content="Ich bin yiwen."><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="/moon_icon.svg"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://wysiwyz.github.io/posts/kk_learn_by_doing_apache_kafka/" /><link rel="prev" href="http://wysiwyz.github.io/posts/cncf-kubestronaut-01kcna/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css"></noscript><link rel="preload" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Apache Kafka 做中學",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/wysiwyz.github.io\/posts\/kk_learn_by_doing_apache_kafka\/"
        },"genre": "posts","keywords": "apache, kafka, kodekloud","wordcount":  6107 ,
        "url": "http:\/\/wysiwyz.github.io\/posts\/kk_learn_by_doing_apache_kafka\/","datePublished": "2024-12-03T11:11:57+08:00","dateModified": "2024-12-03T11:11:57+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Author"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Ich bin yiwen.">Ich bin yiwen.</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Ich bin yiwen.">Ich bin yiwen.</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Apache Kafka 做中學</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Author</a></span>&nbsp;<span class="post-category">included in <a href="/categories/studynote/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>StudyNote</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-12-03">2024-12-03</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;6107 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;29 minutes&nbsp;<span id="/posts/kk_learn_by_doing_apache_kafka/" class="leancloud_visitors" data-flag-title="Apache Kafka 做中學">
                        <i class="far fa-eye fa-fw" aria-hidden="true"></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;views
                    </span>&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#01-introduction-to-kafka">01 introduction to Kafka</a>
      <ul>
        <li></li>
        <li><a href="#01-tasks">01-tasks</a></li>
      </ul>
    </li>
    <li><a href="#02-components--architecture">02 components &amp; architecture</a>
      <ul>
        <li><a href="#2-1-kafka-broker">2-1 Kafka Broker</a></li>
        <li><a href="#2-2-kafka-producers-and-consumers">2-2 Kafka Producers and Consumers</a></li>
        <li><a href="#2-3-kafka-topics-and-partitions">2-3 Kafka Topics and Partitions</a></li>
        <li><a href="#2-4-kafka-architecture">2-4 Kafka Architecture</a></li>
        <li><a href="#2-5-tasks">2-5 Tasks</a></li>
      </ul>
    </li>
    <li><a href="#03-producer--consumers">03 producer &amp; consumers</a>
      <ul>
        <li><a href="#3-1-kafka-producers">3-1 Kafka Producers</a></li>
        <li><a href="#3-2-kafka-consumers">3-2 Kafka Consumers</a></li>
        <li><a href="#3-3-實務上考量">3-3 實務上考量</a></li>
        <li><a href="#3-4-tasks">3-4 Tasks</a></li>
      </ul>
    </li>
    <li><a href="#04-kafka-topics--partitions">04 Kafka topics &amp; partitions</a>
      <ul>
        <li><a href="#4-1-kafka-topics">4-1 Kafka Topics</a></li>
        <li><a href="#4-2-kafka-partitions">4-2 Kafka Partitions</a></li>
        <li><a href="#4-3-實際案例生產消費訊息">4-3 實際案例：生產/消費訊息</a></li>
        <li><a href="#4-4-tasks">4-4 Tasks</a></li>
      </ul>
    </li>
    <li><a href="#05-kafka-environment-setup">05 Kafka environment setup</a>
      <ul>
        <li><a href="#5-1-先備知識">5-1 先備知識</a></li>
        <li><a href="#5-2-實際步驟">5-2 實際步驟</a></li>
        <li><a href="#5-3-驗證安裝">5-3 驗證安裝</a></li>
        <li><a href="#5-4-task">5-4 Task</a></li>
      </ul>
    </li>
    <li><a href="#06-hands-on-with-producers--consumers">06 hands-on with producers &amp; consumers</a>
      <ul>
        <li><a href="#6-1-撰寫-kafka-producers">6-1 撰寫 Kafka Producers</a></li>
        <li><a href="#6-2-撰寫-kafka-consumers">6-2 撰寫 Kafka Consumers</a></li>
      </ul>
    </li>
    <li><a href="#結語">結語</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>這篇是根據 KK Learn By Doing: Beginner&rsquo;s Guide to Apache Kafka - Foundation and Development 所做的筆記與實作紀錄。</p>
<p>學習目標是要能夠將 Kafka architecture 以及 essential components 套用在服務紀錄需求面，只是這 2.5 小時的課可能還是遠遠不夠，都有人把 Kafka 寫成 <a href="https://ithelp.ithome.com.tw/users/20140255/ironman/4026" target="_blank" rel="noopener noreffer ">30 篇系列文章</a>了。</p>
<blockquote>
<p>A distributed event streaming platform, widely used for building real-time data pipelines and applications</p>
</blockquote>
<h2 id="01-introduction-to-kafka">01 introduction to Kafka</h2>
<p>Kafka 是開源分布式事件串流平台 (open-sourced, distributed, event streaming platform)，由 Apache Software Foundation 開發，原本是 LinkedIn 建立，在 2011 年開源。</p>
<p>Kafka 是設計來處理實時資料，協助組織建構穩定、可擴充、且容錯率高的資料管線。</p>
<p><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="https://i.imgur.com/lQwhpfd.png"
        data-srcset="https://i.imgur.com/lQwhpfd.png, https://i.imgur.com/lQwhpfd.png 1.5x, https://i.imgur.com/lQwhpfd.png 2x"
        data-sizes="auto"
        alt="https://i.imgur.com/lQwhpfd.png"
        title="kafka" /></p>
<h4 id="core-components">Core components</h4>
<ul>
<li>Producer : 將 record 送往 Kafka topics 的 app，負責選擇要將 record 送到該 topic 中的哪一個 partition</li>
<li>Consumer : 從 Kafka topics 讀取 record 的 app，consumer 訂閱 topics 並將訊息作即時處理</li>
<li>Broker : 運行 Kafka 的伺服器，broker 從 producer 接收訊息，存在 disk，再將其發送到 consumers。一個 Kafka cluster 包含多個 brokers，用來確保負載平衡與容錯率</li>
<li>Topic : 是一個 logical channel，使 producer 用以發送 record，consumer 用以讀取 record。為了平行化與可擴張性，topic 會分片 (partitioned)</li>
<li><strong>Partition</strong>: 每個 topic 都拆分成 partitions，這個 partition 是有序且不可變的紀錄序列 (sequence of records)，使 Kafka 能夠水平擴展並在每個 partition 裡面維持紀錄順序</li>
<li>ZooKeeper or Kraft: 用來做分布式協調、配置管理、Kafka broker 與 topics 的主節點選舉</li>
</ul>
<h4 id="kafka-architecture">Kafka architecture</h4>
<ul>
<li><strong>Topics &amp; Partitions</strong>: Topic 再切分成 partitions，partition 是平行化跟可擴張性的基礎單位。每一個 partition 都是有序不可變的紀錄序列。partition 當中的每一個 record 都會分配到一個唯一的偏移量 (unique offset)。partitions 使得 Kafka 藉由分布式資料以及負載於多個 brokers 這兩種方式，達到可擴展性。</li>
<li><strong>Producers &amp; Consumers</strong>: Kafka 支援 pub-sub 模型，多個 conusmer 可以訂閱到相同一個 topic，並獨立處理 data。</li>
<li><strong>Brokers &amp; Clusters</strong>: Kafka broker 負責儲存與提供資料。Kafka cluster 包含多個 brokers 用來確保容錯性與高可用性。Brokers 分布在不同個 machines 以避免硬體故障造成資料遺失。</li>
<li><strong>Zooker Coordination</strong> : Zookeeper 或 KRaft 管理配置檔以及 Kafka broker 之間合作，協助進行 partitions 主節點選舉，追蹤 broker metadata。但 Kafka 從 verion 2.8 開始移除 ZooKeeper 依賴，改用 KRaft mode。</li>
</ul>
<h4 id="kafta-在分布式串流平台的角色">Kafta 在分布式串流平台的角色</h4>
<ul>
<li>即時資料消化：Kafka 可以用於消化不同來源的 (logs, sensors, user interactions) 即時資料，對於大流量資料也有收集儲存的方法，具有擴充性與容錯性</li>
<li>串流處理：Kafka 無縫整合串流處理框架，像是 Apache Flink, Apache Spark, Kafka Streams。結合這些能夠即時處理分析資料，也可以偵測詐騙，推薦引擎技術以及監控</li>
<li>資料整合：Kafka 在資料整合扮演 central hub，使得資料能夠跨系統、跨應用程式移動，支援 connector 連向不同資料來源以及資料槽，方便建構 data pipeline</li>
<li>事件溯源 (event sourcing)：應用程式的狀態變更會被 Kafka 紀錄成事件序列，提供了一個可靠、可審計的方式來追縱過去一段時間內的異動</li>
<li>資料佇列：Kafka 也能作為分布式訊息佇列，在應用程式的不同元件之間能夠非同步溝通，提供了 producer 與 consumer 間的解耦，提高了應用程式的可擴展性與彈性</li>
<li>日誌集成：Kafka 普遍用於日誌集成，從多個不同服務收集 logs 做集中處理，有利於監控、除錯、並從 log 資料獲取事件有關的洞察。</li>
<li>指標集合與監控：Kafka 可以從多個不同系統中搜集並彙整指標，提供了即時監測與告警功能，有利維持應用程式與基礎建設的健康與效能</li>
</ul>
<h4 id="kafka-生態系">Kafka 生態系</h4>
<ul>
<li><a href="https://docs.confluent.io/platform/current/connect/index.html" target="_blank" rel="noopener noreffer ">Kafka Connect</a>：將 Kafka topic 資料匯出到外部系統</li>
<li><a href="https://kafka.apache.org/documentation/streams/" target="_blank" rel="noopener noreffer ">Kafka Streams</a>：輕量化的串流處理 library</li>
<li><a href="https://docs.confluent.io/platform/current/kafka-rest/index.html" target="_blank" rel="noopener noreffer ">Kafka REST Proxy</a>：提供與 kafka 互動的 RESTful 介面，讓 app 可以透過 HTTP 生產/消費訊息</li>
<li><a href="https://docs.confluent.io/platform/current/schema-registry/index.html" target="_blank" rel="noopener noreffer ">Schema Registry</a>：將讀寫數據所需的 schema 作存儲/序列化/反序列化，用於版本控管與前後兼容性</li>
<li><a href="https://docs.confluent.io/platform/current/ksqldb/overview.html" target="_blank" rel="noopener noreffer ">KSQL</a>：用直觀且較為熟悉的 query language 簡化了攥流處理與即時串流資料分析的工作</li>
</ul>
<h4 id="apache-kafka-使用案例">Apache Kafka 使用案例</h4>
<ul>
<li>即時分析：分析即時資料，提供洞察並提供主動決策</li>
<li>事件驅動架構：不同服務透過事件溝通，提高可擴張性與低耦合度</li>
<li>微服務：促進微服務之間非同步且可信賴的資料交互</li>
<li>日誌集成與監控：從不同服務間集成日誌內容，可供集中化管理與告警</li>
<li>資料整合：資料整合、跨系統搬移資料的中心，確保一致性與可靠度</li>
</ul>
<h4 id="為什麼使用-kafka">為什麼使用 Kafka</h4>
<ol>
<li>高吞吐低延遲
<ul>
<li>performance：低延遲處理高吞吐量的即時資料串流，透過有效 disk storage 機制以及高效能 networking capabilities。Kafka 架構讓你能每秒處理上百萬則訊息，相當適合需要高吞吐的應用系統</li>
</ul>
</li>
<li>可擴充性
<ul>
<li>水平擴充：藉由往 cluster 增加更多 broker 來達成，而 Kafka 的每個 topic 都有做 partition，這些 partitions 可以遍佈在多個 brokers 各處，確保 Kafka 處理遞增負荷同時，不會降低效能</li>
<li>Elasticity：卡夫卡的 partition based 架構可以動態擴展。當負荷增加了，會加入更多 partition 與 broker 而不會造成 downtime，提供了彈性化的擴展性</li>
</ul>
</li>
<li>耐久性與容錯
<ul>
<li>Replication：Kafka 在多個不同 broker 間複製資料，確保資料耐久性與可用度。複本機制保證即使其中一個或多個 broker 壞了，還是可以存取資料</li>
<li>Log-based storage：用 append-only 的方式，確保資料在 disk 的持久性，最小化資料毀損 (data corruption) 的可能性也提供了有效率的資料復原</li>
</ul>
</li>
<li>彈性多元
<ul>
<li>多樣的使用案例：Kafka 提供了像是 real-time analytics 即時分析、event sourcing 資料溯源、log aggregation 日誌集成、metric collection 指標收集、stream processing 串流處理等等使用案例，可以應付眾多情境</li>
<li>整合生態系：可以無縫接軌，跟 Kafka Connect 做資料整合、Kafka Streams 做串流處理、串接外部處理框架，例如 Apache Flink 以及 Apache Spark</li>
</ul>
</li>
<li>保證訊息順序
<ul>
<li>Message ordering：Kafka 確保了單一個 partition 內，嚴格的訊息順序，對於需要事件先後順序的應用程式而言至關重要</li>
<li>Delivery semantics：Kafka 支援多樣的傳送語意，包括 <code>at-most-once</code>, <code>at-least-once</code>, <code>exactly-one</code> delivery。可以讓開發者根據需求選擇合適等級的保證度</li>
</ul>
</li>
<li>高可用
<ul>
<li>Leader-follower architecture: 主節點選舉可以確保 HA，每個 partition 有一個 leader 多個 followers，當 leader 倒了會有一個 follower 被升上去，不用人為介入就能達成持續可用性</li>
</ul>
</li>
<li>成本效率
<ul>
<li>有效的資源利用率 (both storage and compute)，log-structure storage 機制將 disk I/O 最小化，distributed nature 保證 cluster 其中的負載平衡</li>
<li>開源，沒有與私人訊息系統相關的 licensing 成本</li>
</ul>
</li>
<li>活躍的社群支援
<ul>
<li>Confluent 提供企業級專業功能</li>
</ul>
</li>
<li>串流處理能力
<ul>
<li>Kafka Streams : 原生自己的 stream processing library</li>
<li>KSQL : 使 user 可以用 SQL-like language query</li>
</ul>
</li>
</ol>
<h4 id="與其它工具評比">與其它工具評比</h4>
<h5 id="kafka-vs-rabbitmq">Kafka v.s. RabbitMQ</h5>
<ul>
<li>Throughput : 相較於 RabbitMQ，Kafka 提供較高的吞吐性，更適合用於高流量資料串流</li>
<li>Scalability : 相較於 RabbitMQ 以訊息佇列為基礎的模型，Kafka 的 partition based 架構在擴展上更簡易有效率</li>
<li>Durability : Kafka 的 log-based 存儲與複製提供更好的耐久性與容錯度</li>
</ul>
<h5 id="kafka-vs-apache-pulsar">Kafka v.s. Apache Pulsar</h5>
<ul>
<li>Architecture : Pulsar 提供分層架構，將 serving layer 與 storage layer 拆分開來，在某些情境下屬於優勢。但 Kafka 整合的架構比較簡單，也已經證實了效能</li>
<li>Maturity &amp; Ecosystem : Kafka 有比較成熟的生態系、區域更廣的整合度與工具。Pulsar 比較新，在社群支援與生態系還有進步空間</li>
</ul>
<h5 id="kafka-vs-amazon-kinesis">Kafka v.s. Amazon Kinesis</h5>
<ul>
<li>Vendor lock-in: 相較於 AWS Kinesis 前者是開源，能夠在本地機房或任何雲端環境上運行，Kinesis 可能會有廠商鎖定問題</li>
<li>Feature Set: Kafka 提供的 feature set，例如 Kafka Connect 以及 Kafka Streams 提供了比 Kinesis 更好的彈性與整合選項</li>
</ul>
<h3 id="01-tasks">01-tasks</h3>
<ol>
<li>Apache Kafka is primarily designed for <strong>real-time data feeds</strong></li>
<li>Which of below best describes Kafka&rsquo;s role in event sourcing? <strong>Tracking state changes in applications</strong></li>
<li>How does Kafka support real-time stream processing? <strong>By using Kafka Streams and integrating with processing frameworks like Apache Flink</strong></li>
<li>What use case does Kafka support by acting as a distributed message queue? <strong>Asynchronous communication between application components</strong></li>
<li>Why is Kafka favored over other providers for high-throughput applications? <strong>Kafka can process millions of messages per second with low latency</strong></li>
<li>How does Kafka achieve fault tolerance in distributed environment? <strong>By replicating data accross multiple brokers</strong></li>
<li>What feature makes Kafka scalable and suitable for elastic workloads? <strong>Kafka&rsquo;s ability to dynamically adjust partitions and brokers without downtime</strong></li>
<li>Which of the following is NOT a common use case for Kafka? <strong>Image process is NOT a common use cases. The other three are real-time analytics, event-driven architecture and log aggregations and monitoring.</strong></li>
<li>What is one key advantage of Kafka over RabbitMQ? <strong>Kafka has better scalability with its partition based architecture</strong></li>
<li>In comparison to Apache Pulsar, what is a key advantage of Kafka? <strong>Kafka&rsquo;s integrated architecture is simpler and more proven compared to Pulsar which has different layers for storage and serving.</strong></li>
<li>What is a significant advantage of Kafka over AWS Kinesis? <strong>Kafka has built-in stream processing with Kafka Streams and KSQL.</strong></li>
<li>How does Kafka ensure strict message ordering within a partition? <strong>By assigning offsets to each message within a partition</strong></li>
</ol>
<hr>
<h2 id="02-components--architecture">02 components &amp; architecture</h2>
<p>這章節繼續介紹 Kafka ABC（基本的元素），像是 broker、producer、consumer、topics、partitions, 以及把它們綁在一起的 architecture，著重於複本與容錯機制。</p>
<h3 id="2-1-kafka-broker">2-1 Kafka Broker</h3>
<h4 id="2-1-1-kafka-broker-是啥">2-1-1 Kafka Broker 是啥</h4>
<p>Kafka Broker 是 Kafka cluster 之中的一個 server，用來存放 data 並且提供 clients (producer &amp; consumer) 服務。Broker 處理所有對於 topics 的讀寫操作，一個 Kafka cluster 包含一到多個 broker 來確保擴展性與容錯性。</p>
<blockquote>
<p>嗯？Kafka 的 Topic 跟 RabbitMQ 的 channel 似曾相似</p>
</blockquote>
<h4 id="2-1-2-broker-在-kafka-的角色">2-1-2 Broker 在 Kafka 的角色</h4>
<p>Broker 從 producer 接收訊息，將偏移量 (offsets) 分派給該訊息，並將該訊息提交給 disk storage。另外也服務 consumer，回應要取得特定 topics 與特定 partitions 的請求。此外 Broker 還負責做訊息複本以確保容錯率。</p>
<h4 id="2-1-3-啟動一個-kafka-broker">2-1-3 啟動一個 kafka broker</h4>
<p>通常是用 shell script 帶入 位於 <code>&lt;some-path&gt;/kafka/config/xxx.properties</code> 的配置檔案，以下是簡易版</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kafka-server-start.sh config/server.properties
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2-2-kafka-producers-and-consumers">2-2 Kafka Producers and Consumers</h3>
<h4 id="2-2-1-kafka-producers">2-2-1 Kafka Producers</h4>
<p>Producer：將訊息發布/寫入到 Kafka topics 的應用程式，決定哪個 record 要被分派到哪一個 topic 的哪一段 partition，如下示例</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;localhost:9092&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;key.serializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;value.serializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">Producer</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">producer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">KafkaProducer</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">props</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">producer</span><span class="p">.</span><span class="na">send</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="p">(</span><span class="s">&#34;my-topic&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;key&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;value&#34;</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">producer</span><span class="p">.</span><span class="na">close</span><span class="p">();</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="2-2-2-kafka-consumers">2-2-2 Kafka Consumers</h4>
<p>Consumer：從 Kafka topics 讀取訊息，或訂閱 topics 的應用程式，可以平行化讀取多個 brokers 並消費訊息，如下示例</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;localhost:9092&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;group.id&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;test&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;key.deserializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;value.deserializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">Consumer</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">consumer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">KafkaConsumer</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">props</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">consumer</span><span class="p">.</span><span class="na">subscribe</span><span class="p">(</span><span class="n">Arrays</span><span class="p">.</span><span class="na">asList</span><span class="p">(</span><span class="s">&#34;my-topic&#34;</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="kc">true</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">records</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">consumer</span><span class="p">.</span><span class="na">poll</span><span class="p">(</span><span class="n">Duration</span><span class="p">.</span><span class="na">ofMillis</span><span class="p">(</span><span class="n">100</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">ConsumerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">record</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">records</span><span class="p">)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">printf</span><span class="p">(</span><span class="s">&#34;offset = %d, key = %s, value = %s%n&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">offset</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">key</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">value</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2-3-kafka-topics-and-partitions">2-3 Kafka Topics and Partitions</h3>
<h4 id="2-3-1-topics">2-3-1 Topics</h4>
<p>Topic：一個種類或者訊息類型名稱，是 records 要發布的標的。Kafka Topics 都是有多個訂閱者，翻成白話文就是一個 topic 可以有零個、一個或者許多個 consumer 訂閱寫入這個 topics 的資料。</p>
<h4 id="2-3-2-partitions">2-3-2 Partitions</h4>
<p>Partition：是一個 topic 的部分片段。Topics 可以有多個 partitions，以便處理總數上下多變的資料，另外 partition 也將 data 分佈在多個不同 brokers 中，以達到 topics 平行化處理。</p>
<h5 id="建立一個具有多重-partitions-的-topic">建立一個具有多重 partitions 的 topic</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--create --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--replication-factor <span class="m">1</span> --partitions <span class="m">3</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2-4-kafka-architecture">2-4 Kafka Architecture</h3>
<p>卡夫卡架構重點有三 (1) 高容錯度 (2) 可擴長性 (3) 能夠處理高流量資料，以下幾個關鍵元素：</p>
<h4 id="2-4-1-role-of-brokers-in-architecture">2-4-1 Role of Brokers in Architecture</h4>
<p>Brokers 是整個 Kafka cluster 的骨幹，每個 broker 能處理 terabytes 數百萬的訊息，又不影響效能。Brokers 共同協作提供服務並負載 clients 請求與 data 平衡。</p>
<h4 id="2-4-2-主節點複本與從節點副本">2-4-2 主節點複本與從節點副本</h4>
<p>每個 topic 的 每一個 partition 都會有一個 broker 作為主節點 (leader)，其它 broker 當作從屬節點 (followers)。主節點處這個 partition 的所有讀跟寫的請求，從屬節點則複製 leader 來確保 data redundancy 以及 fault tolerance</p>
<h5 id="描述-topic-來查看主從節點副本">描述 topic 來查看主從節點副本</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--describe --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-topic
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="2-4-3-藉由副本達成容錯度">2-4-3 藉由副本達成容錯度</h4>
<p>Kafka 對所有配置的 servers 底下的 partition 都會做副本日誌，這樣即便 server 故障，資料還是能夠從另外一個 broker（此 broker 持有故障的 partition 副本）還原。</p>
<p>透過瞭解上述的 Kafka 核心組件與架構，user 能設計更穩固、可擴展、且容錯度高的 streaming apps。</p>
<h3 id="2-5-tasks">2-5 Tasks</h3>
<ol>
<li>
<p>What is the primary role of a Kafka broker? <strong>To store data and server clients (producers and consumers)</strong></p>
</li>
<li>
<p>How does Kafka ensure fault tolerance? <strong>By replicating data across multiple brokers</strong></p>
</li>
<li>
<p>What command is used to start a Kafka broker? <strong>kafka-server-start.sh</strong></p>
</li>
<li>
<p>Which component is responsible for publishing messages to Kafka topics? <strong>Producer</strong></p>
</li>
<li>
<p>In the context of Kafka, what is a topic? <strong>A category or feed name to which records are published</strong></p>
</li>
<li>
<p>What does a Kafka consumer do? <strong>It subscribes to topics and processes messages</strong></p>
</li>
<li>
<p>What is a partition in Kafka? <strong>A subset of a topic&rsquo;s data</strong></p>
</li>
<li>
<p>Which broker is the leader for the partition of <code>my-topic</code>?</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">$ /root/kafka/bin/kafka-topics.sh --describe <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-topic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092
</span></span><span class="line"><span class="cl">Topic: my-topic TopicId: KInvVHdEQQ6jazgiRfjt8Q PartitionCount: <span class="m">1</span>       ReplicationFactor: <span class="m">1</span> Configs: 
</span></span><span class="line"><span class="cl">        Topic: my-topic Partition: <span class="m">0</span>    Leader: <span class="m">0</span>       Replicas: <span class="m">0</span>     Isr: <span class="m">0</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h2 id="03-producer--consumers">03 producer &amp; consumers</h2>
<p>這一段落聚焦於 producers 以及 consumers，將探索這兩個 component 的角色、如何與 Kafka 互動，會使用 Kafka CLI 提供實際練習案例來生產/消費訊息。</p>
<h3 id="3-1-kafka-producers">3-1 Kafka Producers</h3>
<p>Kafka producer 負責發布 records/messages 到 Kafka topics，可以把 topic 看成是 records 要發布的類型或訊息來源名稱。Producer 把資料送進 Kafka brokers，讓 broker 確保資料有儲存，也有副本容錯。</p>
<h4 id="3-1-1-producer-如何作用">3-1-1 Producer 如何作用</h4>
<p>Producer 將資料做序列化（把它轉成 bytes）再透過 network 傳送至 Kafka cluster。這個 cluster 根據所定義的 partition strategy（例如 round-robin, key-based partitioning），將資料存進該 topic 下適當的 partition。</p>
<h5 id="範例產生-message">範例：產生 message</h5>
<p>使用 Kafka CLI 命令 <code>kafka-console-producer</code>，如下範例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-producer.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--broker-list localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic exampleTopic
</span></span></code></pre></td></tr></table>
</div>
</div><p>這個指令會開啟一個 prompt，在這之後你輸入的每一行都會被發佈到在 <code>localhost:9092</code> 運行的 Kafka cluster 當中，名為 <code>exampleTopic</code> 的 topic。</p>
<h4 id="3-1-2-kafka-producer-的幾個重要配置內容">3-1-2 Kafka Producer 的幾個重要配置內容</h4>
<ul>
<li><code>linger.ms</code>：控制了該 producer 在發送一個 batch of messages 之前要等待多久，設置比較高的數值可以透過允許一次發送比較多的訊息量，進而提高 throughput，但也可能提高 latency。</li>
<li><code>acks</code>：決定 producer 在認定一則訊息『已發送』之前，要經過多少 acknowledgements
<ul>
<li><code>acks=all</code> 表示主節點需要等待所有副本都提供 acknowledgement，優點：訊息持久性，缺點：可能提高 latency</li>
</ul>
</li>
<li><code>batch.size</code>：控制 producer 要發送的單一 batch 的最大容量 (in bytes)，比較大包的 batch 可以提高 throughput 但是也需要比較多 memory</li>
</ul>
<h3 id="3-2-kafka-consumers">3-2 Kafka Consumers</h3>
<p>Kafka consumer 從 topics 讀取 records，consumer 訂閱一到多個 topics，按照產生的順序讀取 records</p>
<h4 id="3-2-1-consumer-如何作用">3-2-1 Consumer 如何作用</h4>
<p>Conumer 使用一個 <strong>pull model</strong> 來從 broker 取得資料，另外也透過管理 <strong>offsets</strong> 偏移量來追蹤消費過的 records。Offsets 實質上是 pointers 指向這個 consumer 讀取到的上一則 record。Kafka 儲存這些 offsets，讓 consumer 即使在壞掉或重啟後，都能夠從上一次讀取過的段落重新開始。</p>
<h5 id="consumer-groups">Consumer Groups</h5>
<p>Kafka consumer 可以作為 <strong>consumer groups</strong> 的一部分。當有多個 conumsers 共同處於一個 group，Kafka 則確保每個 partition 只會被這個 consumer groups 的 <strong>其中一個 consumer</strong> 所消費。這個機制可以讓資料分發傳送給多個 consumers 處理，達到可擴展與容錯性。</p>
<h5 id="範例conumer-messages">範例：Conumer messages</h5>
<p>使用 <code>kafka-console-consumer</code> 的 Kafka CLI 指令可以從一個 topic 讀取/消費訊息，如下例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-consumer.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic exampleTopic --from-beginning
</span></span></code></pre></td></tr></table>
</div>
</div><p>這個指令會印出來自於 <code>exampleTopic</code> topic 的訊息，按照產生的順序，從最舊到最新顯示</p>
<h4 id="3-2-2-kafka-consumer-的幾個重要配置內容">3-2-2 Kafka Consumer 的幾個重要配置內容</h4>
<ul>
<li><code>from-beginning</code>：在 consumer command 加入這個 flag，使 client 能夠從 topic 所能提供之 <strong>latest offset</strong> 開始消費訊息。沒有加這個 flag 的話，consumer 只會先從 <strong>latest offset</strong> 讀取訊息</li>
<li><code>group.id</code>：定義這個 consumer 要屬於哪一個 consumer group，Kafka 確保一個 consumer group 當中，一次只會有一個 consumer 處理一個 partition，將其它負載分發傳送到相同 group 裡面的多個 consumers。</li>
<li><code>isolation.level</code>：這個設置控制該 consumer 在處理交易性 topics 時，是否要讀取已提交或者尚未提交的訊息。把他設定為 <code>read_committed</code>，會確保該 consumer 只會讀取完全提交的訊息。</li>
</ul>
<h3 id="3-3-實務上考量">3-3 實務上考量</h3>
<p>serialization/deserialization、partition、offset 管理，在實作 producer consumer 時都需要仔細考量，這三個面向對於 kafka-based application 的效率性與可靠性都至關重要。</p>
<h4 id="3-3-1-serializationdeserialization">3-3-1 Serialization/deserialization</h4>
<p>Producer 把 message 序列化成 bytes &ndash;&gt; 送進 Kafka &ndash;&gt; Consumer 將 bytes 反序列化回原始資料格式。Kafka 支援多種序列化格式，包含 JSON、Avro、Protobuf。</p>
<h4 id="3-3-2-partitioning">3-3-2 Partitioning</h4>
<p>適當的 partitioning 確保在 Kafka cluster 裡面有效率的資料分派。Producer 可以給每個 message 指明一個 key，這個 key 會被 Kafka 用來決定該 message 會被存進指定 topic 當中的哪一個 partition。</p>
<h4 id="3-3-3-offset-management">3-3-3 Offset management</h4>
<p>Consumer 使用 offset 追縱他們的進度，因此 offsets 需要仔細管理，以確保 consumer app 對於所有訊息都有依照產生順序消費，不會有重複讀取/消費的問題。</p>
<h3 id="3-4-tasks">3-4 Tasks</h3>
<ol>
<li>
<p>Apache Kafka is a distributed streaming platform that allows for the building of real-time streaming data pipelines and applications. At its core, Kafka manages records in a fault-tolerant and scalable way. This labs focus on two essential components of Kafka: producer and consumer</p>
</li>
<li>
<p>Kafka producers are responsible for publishing records to Kafka topics, while Kafka consumers <em>read records</em> from topics. Understanding how these components interact with Kafka is crucial for building efficient and reliable streaming applications.</p>
</li>
<li>
<p>Which of the following Kafka producer configurations controls the amount of time a producer waits before sending a batch of messages? <strong>linger.ms</strong></p>
</li>
<li>
<p>Which Kafka producer configuration ensures that the producer waits for acknowledgments from all replicas before considering a message as successfully sent? <strong>acks=all</strong></p>
</li>
<li>
<p>Which Kafka CLI command is used to produce message to a topic? <strong>kafka-console-producer.sh</strong></p>
</li>
<li>
<p>Use the <code>kafka-console-producer</code> command to send <code>Hi, this is my first messsage</code> to the <code>myFirstTopic</code> topic</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nb">cd</span> /root/kafka/bin/
</span></span><span class="line"><span class="cl">ls
</span></span><span class="line"><span class="cl">cat kafka-console-producer.sh
</span></span><span class="line"><span class="cl">kafka-console-producer.sh --topic myFirstTopic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092
</span></span><span class="line"><span class="cl">&gt; Hi, this is my first messsage
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Which Kafka CLI command is used to consume messages to a topic? <strong>kafka-console-consumer.sh</strong></p>
</li>
<li>
<p>When using Kafka&rsquo;s CLI consumer, what does the <code>--from-beginning</code> flag do? <strong>Consumes messages from the start of a topic</strong></p>
</li>
<li>
<p>In Kafka CLI consumer, which of the following command allows you to specify the consumer group that the client should join? <strong>&ndash;group</strong></p>
</li>
<li>
<p>What is the purpose of the <code>--isolation-level</code> configuration in the Kafka consumer CLI? <strong>To determine whether the consumer reads committed or uncommitted messages</strong></p>
</li>
<li>
<p>Use the Kafka console consumer to read messages from the topic <code>myFirstTopic</code> and store them in <code>/root/messages</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-consumer.sh --topic myFirstTopic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--from-beginning --timeout-ms <span class="m">1000</span>
</span></span><span class="line"><span class="cl">Hi, this is my first message
</span></span><span class="line"><span class="cl"><span class="nv">a29kZWtsb3VkCg</span><span class="o">==</span>
</span></span><span class="line"><span class="cl">Processed a total of <span class="m">2</span> messages
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h2 id="04-kafka-topics--partitions">04 Kafka topics &amp; partitions</h2>
<p>這章節要解開 topics 跟 partition 這兩個 kafka 的謎霧。重複強調一下，Kafka 是 distributed streaming platform, 可以協助您達到高吞吐、且具有容錯性的即時資料來源處理。不管是 Kafka 小萌新，或者是打算將這兩個概念了解透徹，要有效率的使用 Kafka，了解 Topic 與 Partition 都是關鍵要素。現在要講如何用 topics 幫 message 分類，以及 partitions 如何啟用 Kafka 的可擴展性以及平行處理的能力。</p>
<h3 id="4-1-kafka-topics">4-1 Kafka Topics</h3>
<p>將 Kafka topic 想像成一個欄位或者一個儲存訊息的資料夾。Topics 是 Kafka producer 與 Kafka consumer 之間溝通的方式。每一則發佈到 Kafka cluster 的訊息都會被分派一個特定的 topic，使得這個 message 能夠被訂閱這個 topic 的任何 consumer group 所讀取/消費。</p>
<h4 id="4-1-1-建立一個-kafka-topic">4-1-1 建立一個 Kafka Topic</h4>
<p>使用 <code>kafka-topics</code> CLI 指令工具建立一個新的 Kafka topic</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --create <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--replication-factor <span class="m">1</span> --partitions <span class="m">3</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic
</span></span></code></pre></td></tr></table>
</div>
</div><p>這指令會建立一個名為 <code>my-first-topic</code> 的 topics，有三個 partition，replication factor 是 1</p>
<h4 id="4-1-2-列出-kafka-topics">4-1-2 列出 Kafka Topics</h4>
<p>要查看 Kafka cluster 現在有的 topic 清單，可以用以下指令</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:9092
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="4-1-3-了解-topics-characteristics">4-1-3 了解 Topics characteristics</h4>
<ul>
<li>Immutability 不可變異性：一旦有訊息寫入一個 topic 就不能被異動。這是 kafka 設計的一個關鍵功能</li>
<li>Retention Policy 保留政策：Kafka topic 可以配置訊息保留政策，決定訊息再被刪除之前要保留多久一段時間（可以根據時間或者訊息大小而定）</li>
</ul>
<h3 id="4-2-kafka-partitions">4-2 Kafka Partitions</h3>
<p>Partitions 是 Kafka 確保擴展性以及容錯的方式。每一個 topic 會被區分成多個 partitions，每一個 partition 可以放在一個 cluster 當中，不同的 kakfa brokers。可以使得一個 topic 的訊息分佈在 cluster 各處，達到平行化處理並提高吞吐量。</p>
<h4 id="4-2-1-為啥需要-partitions">4-2-1 為啥需要 Partitions</h4>
<ul>
<li>Parallelism 平行化：partition 允許多個 consumers 平行化讀取一個 topic 的訊息，顯著提升了系統的吞吐量</li>
<li>Scalability 可擴展性：隨著 message 流量增加，可以加更多 partitions 近來，將負載分派到比較多的 brokers。</li>
</ul>
<h4 id="4-2-2-建立-partitions">4-2-2 建立 Partitions</h4>
<p>建立 topics 可以指定 partitions 數量，您也可以直接修改既有 topics 的 partitions 數量</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --alter <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic --partitions <span class="m">6</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>上述指令會將既有的 <code>my-first-topic</code>partitions 數量升到 6 個</p>
<h4 id="4-2-3-partitions-如何運作">4-2-3 Partitions 如何運作</h4>
<ul>
<li><strong>Ordering</strong>: 在一個 partition 內的所有訊息都保證會以他們寫入的先後順序儲存，但是跨 partitions 的 message 順序就不保證</li>
<li><strong>Consumer Groups</strong>: 一次只能有 consumer group 的唯一一名成員消費這個 partition 的訊息，以確保訊息有按照順序被處理</li>
</ul>
<h3 id="4-3-實際案例生產消費訊息">4-3 實際案例：生產/消費訊息</h3>
<h4 id="4-3-1-發送-message-進一個-topic">4-3-1 發送 message 進一個 topic</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-first-topic
</span></span><span class="line"><span class="cl">&gt; Hello, Kafka!
</span></span><span class="line"><span class="cl">&gt; This is a message.
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="4-3-2-從一個-topic-消費-message">4-3-2 從一個 topic 消費 message</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-first-topic --from-beginning
</span></span></code></pre></td></tr></table>
</div>
</div><p>這指令會從名為 <code>my-first-topic</code> 的 topic，從最先前的地方開始顯示所有訊息</p>
<h3 id="4-4-tasks">4-4 Tasks</h3>
<ol>
<li>
<p>In this section, we will explore the fundamental concepts of Kafka topics and partitions. Topics serve as categories for messages, while partitions allow for scalability and parallel processing.</p>
</li>
<li>
<p>What is a Kafka topic? <strong>A category or a folder where messages are stored</strong></p>
</li>
<li>
<p>Create a Kafka Topic</p>
<ul>
<li>Utilize the Kafka CLI tool to create a topic named <code>my-first-topic</code> with 3 partitions and a replication factor of 1</li>
<li>Use the Kafka binary located at <code>/root/kafka/bin/</code> to interact with Kafka</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--create --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--replication-factor <span class="m">1</span> --partitions <span class="m">3</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>How many topics are in this cluster?</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --list <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 
</span></span><span class="line"><span class="cl">customer-feedback
</span></span><span class="line"><span class="cl">inventory-updates
</span></span><span class="line"><span class="cl">my-first-topic
</span></span><span class="line"><span class="cl">order-processing-queue
</span></span><span class="line"><span class="cl">user-registration-events
</span></span><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --list <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="p">|</span> wc -l
</span></span><span class="line"><span class="cl"><span class="m">5</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Partitions in Kafka play a crucial role in scalability and fault tolerance. By dividing each topic into multiple partitions, Kafka enables parallel processing, which significantly improves throughput and system performance.</p>
</li>
<li>
<p>Why are partitions important in Kafka? <strong>They allow for parallelism and scalability.</strong></p>
</li>
<li>
<p>Increase the number of partitions for the topic <code>my-first-topic</code> to <code>6</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># alter</span>
</span></span><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --alter <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --topic my-first-topic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --partitions <span class="m">6</span>
</span></span><span class="line"><span class="cl"><span class="c1"># verify</span>
</span></span><span class="line"><span class="cl">root/kafka/bin/kafka-topics.sh --describe <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --topic my-first-topic
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>What is the retention policy in Kafka? <strong>A policy to determine how long messages are kept before being deleted</strong></p>
</li>
<li>
<p>Change the retention time for messages in the <code>my-second-topic</code> to 7 days</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># set config &#34;retention.ms&#34; to 7 days (=604800000 milliseconds)</span>
</span></span><span class="line"><span class="cl">/root/kafka/bin/kafka-configs.sh --alter <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--entity-type topics <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--entity-name my-second-topic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--add-config retention.ms<span class="o">=</span><span class="m">604800000</span>
</span></span><span class="line"><span class="cl"><span class="c1"># verfy</span>
</span></span><span class="line"><span class="cl">/root/kafka/bin/kafka-configs.sh --describe <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-second-topic
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Produce messages to a Kafka topic</p>
<p>Use the Kafka-console-producer to send the message <code>{&quot;user&quot;: &quot;Alice&quot;, &quot;action&quot;: &quot;login&quot;, &quot;timestamp&quot;: &quot;2024-12-03T10:00:00Z&quot;}</code> to the topic <code>my-first-topic</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-producer.sh <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--broker-list localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic
</span></span><span class="line"><span class="cl">&gt; <span class="o">{</span><span class="s2">&#34;user&#34;</span>: <span class="s2">&#34;Alice&#34;</span>, <span class="s2">&#34;action&#34;</span>: <span class="s2">&#34;login&#34;</span>, <span class="s2">&#34;timestamp&#34;</span>: <span class="s2">&#34;2024-09-30T10:00:00Z&#34;</span><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Consume messages from a Kafka topic</p>
<p>Use the Kafka console consumer to read messages from the topic <code>my-first-topic</code> and store them in <code>/root/messages</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-consumer.sh --topic my-first-topic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--from-beginning --timeout-ms <span class="m">1000</span> &gt; /root/messages
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Delete a Kafka topic</p>
<p>Use the Kafka CLI tool to delete the topic <code>my-first-topic</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-topics.sh --delete <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--topic my-first-topic <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--bootstrap-server localhost:9092
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h2 id="05-kafka-environment-setup">05 Kafka environment setup</h2>
<p>這一章節目的要帶你走過整個從零開始建立 Kafka 環境的流程，使用到 Kafka 本身以及 ZooKeeper 用於 cluster 管理，程度適合 beginner。</p>
<h3 id="5-1-先備知識">5-1 先備知識</h3>
<p>在建立 kafka setup 之前要有以下知識背景：</p>
<ul>
<li>Linux-based 的系統（這裡提到的指令都用於 linux 環境）</li>
<li>Command-line 基本知識</li>
<li>系統已安裝 <code>curl</code> ，用來下載 Kafka</li>
<li><code>tar</code> 用於解壓縮 Kafka archive</li>
<li>系統已安裝 <code>Java</code>，用來運行 Kafka</li>
<li>Root 或者 sudo 權限，用來建立 service files</li>
</ul>
<h3 id="5-2-實際步驟">5-2 實際步驟</h3>
<h4 id="step-1-下載-kafka">Step 1: 下載 Kafka</h4>
<p>可以從官網下載 Apache Kafka，但是為了便利性，這裡使用 curl 從 command line 直接下載 Kafka，以下指令下載的是 version 3.7.1 版本。需要新的版本的話，可以去 Kafka 下載頁面查看</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">curl -L https://downloads.apache.org/kafka/3.7.1/kafka_2.13-3.7.1.tgz -o ~/Downloads/kafka.tgz
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="step-2-解壓縮-kafka">Step 2: 解壓縮 Kafka</h4>
<p>一旦下載完成，需要解壓縮到你想要放的目錄裡。以下指令會在你的 home 目錄建立一個新的 directory 給 Kafka，並將 archive 解壓縮至此</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">mkdir ~/kafka <span class="o">&amp;&amp;</span> <span class="nb">cd</span> ~/kafka
</span></span><span class="line"><span class="cl">tar -xvzf ~/Downloads/kafka.tgz --strip <span class="m">1</span> -C ~/kafka
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="step-3-建立-zookeeper-systemd-service">Step 3: 建立 ZooKeeper Systemd Service</h4>
<p>使用以下指令建立 ZooKeeper 的 systemd service file</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo vi /etc/systemd/system/zookeeper.service
</span></span><span class="line"><span class="cl"><span class="c1"># paste below config to the editor</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>Unit<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Requires</span><span class="o">=</span>network.target remote-fs.target
</span></span><span class="line"><span class="cl"><span class="nv">After</span><span class="o">=</span>network.target remote-fs.target
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Service<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Type</span><span class="o">=</span>simple
</span></span><span class="line"><span class="cl"><span class="nv">User</span><span class="o">=</span>root
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/root/kafka/bin/zookeeper-server-start.sh /root/kafka/config/zookeeper.properties
</span></span><span class="line"><span class="cl"><span class="nv">ExecStop</span><span class="o">=</span>/root/kafka/bin/zookeeper-server-stop.sh
</span></span><span class="line"><span class="cl"><span class="nv">Restart</span><span class="o">=</span>on-abnormal
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Install<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</span></span><span class="line"><span class="cl"><span class="c1"># save and close vi editor</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="step-4-設定-kafka-server">Step 4: 設定 Kafka Server</h4>
<p>類似 ZooKeeper，Kafka 也需要 system service 來做自動化管理，使用以下指令建立 Kafka service file</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo vi /etc/systemd/system/kafka.service
</span></span><span class="line"><span class="cl"><span class="c1"># paste below config to the editor</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>Unit<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Requires</span><span class="o">=</span>zookeeper.service
</span></span><span class="line"><span class="cl"><span class="nv">After</span><span class="o">=</span>zookeeper.service
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Service<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Type</span><span class="o">=</span>simple
</span></span><span class="line"><span class="cl"><span class="nv">User</span><span class="o">=</span>root
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/bin/sh -c <span class="s1">&#39;/root/kafka/bin/kafka-server-start.sh /root/kafka/config/server.properties &gt; /root/kafka/kafka.log 2&gt;&amp;1&#39;</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStop</span><span class="o">=</span>/root/kafka/bin/kafka-server-stop.sh
</span></span><span class="line"><span class="cl"><span class="nv">Restart</span><span class="o">=</span>on-abnormal
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Install<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</span></span><span class="line"><span class="cl"><span class="c1"># save and close vi editor</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="step-5-啟動服務">Step 5: 啟動服務</h4>
<p>兩個 services files 皆到位，就可以 enable and start ZooKeeper 跟 Kafka</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> zookeeper
</span></span><span class="line"><span class="cl">sudo systemctl start zookeeper
</span></span><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> kafka
</span></span><span class="line"><span class="cl">sudo systemctl start kafka
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="5-3-驗證安裝">5-3 驗證安裝</h3>
<p>以下指令用來驗證 Kafka 以及 Zookeeper 皆已正確安裝。如果都正確無誤，那這兩個 services 應該都在 active 狀態</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo systemctl status zookeeper
</span></span><span class="line"><span class="cl">sudo systemctl status kafka
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="5-4-task">5-4 Task</h3>
<ol>
<li>
<p>Apache Kafka is a powerful distributed streaming platform that enables you to build real-time streaming data pipelines and applications. Setting up a Kafka environment involves installing Kafka itself along with ZooKeeper, which Kafka uses for cluster management.</p>
</li>
<li>
<p>Pre-requisite per above</p>
</li>
<li>
<p>Install Java 17 as Kafka depends on this</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo apt update <span class="o">&amp;&amp;</span> sudo apt install -y openjdk-17-jdk
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>What is the primary purpose of ZooKeeper in a Kafka environment? <strong>To manage cluster metadata and configurations</strong></p>
</li>
<li>
<p>Download the latest version of Kafka and store it in the <code>/home/bob/</code> directory with the filename <code>kafka.tgz</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">curl -L https://downloads.apache.org/kafka/3.7.1/kafka_2.13-3.7.1.tgz -o /home/bob/kafka.tgz
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Extract the Kafka archive to the <code>/home/bob/kafka/</code> directory</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">mkdir -p /home/bob/kafka <span class="o">&amp;&amp;</span> tar -xvzf /home/bob/kafka.tgz --strip <span class="m">1</span> -C /home/bob/kafka
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>What is the correct path to the Kafka config file? <strong>/home/bob/kafka/config/server.properties</strong></p>
</li>
<li>
<p>What is the correct path to the ZooKeeper config file? <strong>/home/bob/kafka/config/zookeeper.properties</strong></p>
</li>
<li>
<p>Create a systemd service file to manage ZooKeeper as a service.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo vi /etc/systemd/system/zookeeper.service
</span></span><span class="line"><span class="cl"><span class="c1"># paste below</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>Unit<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Requires</span><span class="o">=</span>network.target remote-fs.target
</span></span><span class="line"><span class="cl"><span class="nv">After</span><span class="o">=</span>network.target remote-fs.target
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Service<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Type</span><span class="o">=</span>simple
</span></span><span class="line"><span class="cl"><span class="nv">User</span><span class="o">=</span>root
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/home/bob/kafka/bin/zookeeper-server-start.sh /home/bob/kafka/config/zookeeper.properties
</span></span><span class="line"><span class="cl"><span class="nv">ExecStop</span><span class="o">=</span>/home/bob/kafka/bin/zookeeper-server-stop.sh
</span></span><span class="line"><span class="cl"><span class="nv">Restart</span><span class="o">=</span>on-abnormal
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Install<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># reload the systemd daemon to recognize the new service file</span>
</span></span><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Create a systemd service file to manage Kafka as a service.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo vi /etc/systemd/system/kafka.service
</span></span><span class="line"><span class="cl"><span class="c1"># paste</span>
</span></span><span class="line"><span class="cl"><span class="o">[</span>Unit<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Requires</span><span class="o">=</span>zookeeper.service
</span></span><span class="line"><span class="cl"><span class="nv">After</span><span class="o">=</span>zookeeper.service
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Service<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">Type</span><span class="o">=</span>simple
</span></span><span class="line"><span class="cl"><span class="nv">User</span><span class="o">=</span>root
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/bin/sh -c <span class="s1">&#39;/home/bob/kafka/bin/kafka-server-start.sh /home/bob/kafka/config/server.properties &gt; /home/bob/kafka/kafka.log 2&gt;&amp;1&#39;</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStop</span><span class="o">=</span>/home/bob/kafka/bin/kafka-server-stop.sh
</span></span><span class="line"><span class="cl"><span class="nv">Restart</span><span class="o">=</span>on-abnormal
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="o">[</span>Install<span class="o">]</span>
</span></span><span class="line"><span class="cl"><span class="nv">WantedBy</span><span class="o">=</span>multi-user.target
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># reload the systemd daemon to apply the changes</span>
</span></span><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Enable and start both the ZooKeeper and Kafka services to ensure they run at boot and are active immediately.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># enable ZooKeeper to start at boot</span>
</span></span><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> zookeeper
</span></span><span class="line"><span class="cl"><span class="c1"># start the ZooKeeper service</span>
</span></span><span class="line"><span class="cl">sudo systemctl start zookeeper
</span></span><span class="line"><span class="cl"><span class="c1"># enable Kafka to start at boot</span>
</span></span><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> kafka
</span></span><span class="line"><span class="cl"><span class="c1"># start the Kafka service</span>
</span></span><span class="line"><span class="cl">sudo systemctl start kafka
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Install Kafdrop as a UI for managing your Kafka cluster with a graphical interface. Create Kafkaui as a service and ensure it is enabled and started automatically on boot?</p>
<h5 id="solution">Solution</h5>
<p>Follow these steps to install <strong>Kafdrop</strong> and set it up as a <strong>systemd service</strong> for your Kafka cluster:
<strong>Step 1: Download Kafdrop</strong></p>
<p>Use the following <strong>curl</strong> command to download the Kafdrop JAR file to the <code>/opt</code> directory:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo curl -L https://github.com/obsidiandynamics/kafdrop/releases/download/4.0.2/kafdrop-4.0.2.jar -o /opt/kafdrop-4.0.2.jar
</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Step 2: Create a systemd Service for Kafdrop</strong></p>
<ol>
<li><strong>Create a systemd service</strong> file for <strong>Kafdrop</strong>. Open a new file using a text editor:</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo vi /etc/systemd/system/kafkaui.service
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>Add the following content to the service file:</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-properties" data-lang="properties"><span class="line"><span class="cl"><span class="err">[Unit]</span>
</span></span><span class="line"><span class="cl"><span class="na">Description</span><span class="o">=</span><span class="s">Web UI for administration of Kafka clusters</span>
</span></span><span class="line"><span class="cl"><span class="na">Requires</span><span class="o">=</span><span class="s">kafka.service</span>
</span></span><span class="line"><span class="cl"><span class="na">After</span><span class="o">=</span><span class="s">kafka.service</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">[Service]</span>
</span></span><span class="line"><span class="cl"><span class="na">User</span><span class="o">=</span><span class="s">root</span>
</span></span><span class="line"><span class="cl"><span class="na">WorkingDirectory</span><span class="o">=</span><span class="s">/opt/</span>
</span></span><span class="line"><span class="cl"><span class="na">ExecStart</span><span class="o">=</span><span class="s">/usr/bin/java --add-opens=java.base/sun.nio.ch=ALL-UNNAMED -jar kafdrop-4.0.2.jar --kafka.brokerConnect=ubuntu-host:9092</span>
</span></span><span class="line"><span class="cl"><span class="na">StartLimitInterval</span><span class="o">=</span><span class="s">0</span>
</span></span><span class="line"><span class="cl"><span class="na">RestartSec</span><span class="o">=</span><span class="s">10</span>
</span></span><span class="line"><span class="cl"><span class="na">Restart</span><span class="o">=</span><span class="s">always</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="err">[Install]</span>
</span></span><span class="line"><span class="cl"><span class="na">WantedBy</span><span class="o">=</span><span class="s">multi-user.target</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li><strong>Reload</strong> the <strong>systemd daemon</strong> to recognize the new service file:</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="4">
<li><strong>Enable and Start</strong> the Kafdrop Service:</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> kafkaui.service
</span></span><span class="line"><span class="cl">sudo systemctl start kafkaui.service
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h2 id="06-hands-on-with-producers--consumers">06 hands-on with producers &amp; consumers</h2>
<h3 id="6-1-撰寫-kafka-producers">6-1 撰寫 Kafka Producers</h3>
<p>Producer 負責將 data 送到 Kafka topics 以利 consumer 消費。這章節會分別使用 Java 與 Python 展示建立連線、傳送訊息、處理錯誤的細節：</p>
<h4 id="6-1-1-producer-長話短說">6-1-1 Producer 長話短說</h4>
<p>Kafka producers 是負責將 records 傳送進 Kafka topics 的應用程式，負責處理資料序列化（data &ndash;&gt; byte streams) 以及分派 records 到一個 topic 的哪些個 partitions。</p>
<p>一個好的 Kafka producer should be designed to be efficient, scalable, resilient。</p>
<h4 id="6-1-2-以-java-建立-kafka-producer">6-1-2 以 Java 建立 Kafka Producer</h4>
<h5 id="建立一個-gradle-project">建立一個 Gradle Project</h5>
<ol>
<li>
<p>Create a new directory for the project</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">mkdir kafka-producer
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> kafka-producer
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Initialize the Gradle project</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">gradle init --type java-applications
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Add Kafka dependencies</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-groovy" data-lang="groovy"><span class="line"><span class="cl">   <span class="n">plugins</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">       <span class="n">id</span> <span class="s1">&#39;application&#39;</span>
</span></span><span class="line"><span class="cl">   <span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="n">repositories</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">       <span class="n">mavenCentral</span><span class="o">()</span>
</span></span><span class="line"><span class="cl">   <span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="n">dependencies</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">       <span class="n">implementation</span> <span class="s1">&#39;org.apache.kafka:kafka-clients:3.0.0&#39;</span>
</span></span><span class="line"><span class="cl">   <span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   <span class="n">application</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">       <span class="n">mainClassName</span> <span class="o">=</span> <span class="s1">&#39;com.example.SimpleProducer&#39;</span>
</span></span><span class="line"><span class="cl">   <span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h5 id="4-建立連線">4. 建立連線</h5>
<p>Create a Java class for the producer</p>
<p>建立 <code>src/main/&lt;path-to-your-producer-package&gt;/SimpleProducer.java</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="w">   </span><span class="kn">package</span><span class="w"> </span><span class="nn">com.example</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.producer.KafkaProducer</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.producer.Producer</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.producer.ProducerRecord</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Properties</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="kd">public</span><span class="w"> </span><span class="kd">class</span> <span class="nc">SimpleProducer</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">       </span><span class="kd">public</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">String</span><span class="o">[]</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;bootstrap.servers&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;localhost:9092&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;key.serializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="s">&#34;value.serializer&#34;</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">Producer</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">producer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">KafkaProducer</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">props</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">String</span><span class="w"> </span><span class="n">topicName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;example-topic&#34;</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">String</span><span class="w"> </span><span class="n">message</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;Hello, Kafka!&#34;</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">producer</span><span class="p">.</span><span class="na">send</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ProducerRecord</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">topicName</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;key1&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">message</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">           </span><span class="n">producer</span><span class="p">.</span><span class="na">close</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">       </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">   </span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋">解釋</h6>
<ul>
<li><code>bootstrap.servers</code>：要使用的 Kafka cluster 位址</li>
<li><code>key.serializer</code> &amp; <code>value.serializer</code>：如何將 producer 要傳送的 key-value 物件轉成 bytes</li>
</ul>
<h5 id="5-發送訊息">5. 發送訊息</h5>
<p>要發送訊息的話，則要建立 <code>ProducerRecord</code> 內容包含 topic name、key、value，再呼叫 <code>send</code> 方法。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="n">String</span><span class="w"> </span><span class="n">topicName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;example-topic&#34;</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">String</span><span class="w"> </span><span class="n">key</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;key1&#34;</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">String</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&#34;Hello, Kafka!&#34;</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// Create a ProducerRecord</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">ProducerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">record</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">ProducerRecord</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">topicName</span><span class="p">,</span><span class="w"> </span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// Send the record</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">producer</span><span class="p">.</span><span class="na">send</span><span class="p">(</span><span class="n">record</span><span class="p">);</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋-1">解釋</h6>
<ul>
<li>
<p><code>ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topicName, key, value);</code></p>
<blockquote>
<p>這裡建立了一個 record，包含指定的 topic, key, value</p>
</blockquote>
</li>
<li>
<p><code>producer.send(record);</code></p>
<blockquote>
<p>將 record 發送至 Kafka cluster</p>
</blockquote>
</li>
</ul>
<h5 id="6-錯誤處理">6. 錯誤處理</h5>
<p>使用 callbacks 以及 try-catch block 處裡錯誤，這裡修改一下 <code>send</code> 方法讓它包含 callback</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="n">producer</span><span class="p">.</span><span class="na">send</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ProducerRecord</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">topicName</span><span class="p">,</span><span class="w"> </span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">),</span><span class="w"> </span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span><span class="w"> </span><span class="n">exception</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">exception</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">log</span><span class="p">.</span><span class="na">info</span><span class="p">(</span><span class="s">&#34;Message sent successfully to topic {} partition {}, offset {}&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">topic</span><span class="p">(),</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">partition</span><span class="p">(),</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">offset</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">log</span><span class="p">.</span><span class="na">error</span><span class="p">(</span><span class="s">&#34;Error sending message: {}&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">exception</span><span class="p">.</span><span class="na">getMessage</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">});</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>除此之外也要用 <code>finally</code> 把 producer 給關閉以釋放資源</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="k">try</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">producer</span><span class="p">.</span><span class="na">send</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ProducerRecord</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">topicName</span><span class="p">,</span><span class="w"> </span><span class="n">key</span><span class="p">,</span><span class="w"> </span><span class="n">value</span><span class="p">),</span><span class="w"> </span><span class="p">(</span><span class="n">metadata</span><span class="p">,</span><span class="w"> </span><span class="n">exception</span><span class="p">)</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">exception</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="kc">null</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">log</span><span class="p">.</span><span class="na">info</span><span class="p">(</span><span class="s">&#34;Message sent successfully to topic {}, partition {}, offset {}&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">topic</span><span class="p">(),</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">partition</span><span class="p">(),</span><span class="w"> </span><span class="n">metadata</span><span class="p">.</span><span class="na">offset</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">log</span><span class="p">.</span><span class="na">error</span><span class="p">(</span><span class="s">&#34;Error sending message: {}&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">exception</span><span class="p">.</span><span class="na">getMessage</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">});</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w"> </span><span class="k">catch</span><span class="w"> </span><span class="p">(</span><span class="n">Exception</span><span class="w"> </span><span class="n">e</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">log</span><span class="p">.</span><span class="na">error</span><span class="p">(</span><span class="s">&#34;Error: {}&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">.</span><span class="na">getMessage</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w"> </span><span class="k">finally</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">producer</span><span class="p">.</span><span class="na">close</span><span class="p">();</span><span class="w">   </span><span class="err">#</span><span class="w"> </span><span class="n">donnot</span><span class="w"> </span><span class="n">forget</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">release</span><span class="w"> </span><span class="n">resources</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋-2">解釋</h6>
<ul>
<li><code>try-catch-finally</code>：確保 producer 在成功/有錯誤失敗的情況後，都正確關閉</li>
<li><code>callback</code>：處理 send 操作的結果，印出成功/失敗錯誤訊息</li>
</ul>
<h4 id="6-1-3-以-python-建立-kafka-producer">6-1-3 以 Python 建立 Kafka Producer</h4>
<h5 id="建立一個-python-project">建立一個 Python Project</h5>
<ol>
<li>
<p>create a new directory for the project</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">mkdir kafka-producer
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> kafka-producer
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>create and activate a virtual environment</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">python3 -m venv venv
</span></span><span class="line"><span class="cl"><span class="nb">source</span> venv/bin/activate
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>install Kafka-Python</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">pip install kafka-python
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h5 id="建立連線">建立連線</h5>
<p>新增一個 file <code>producer.py</code> 撰寫以下這些程式碼</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaProducer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">producer</span> <span class="o">=</span> <span class="n">KafkaProducer</span><span class="p">(</span><span class="n">bootstrap_servers</span><span class="o">=</span><span class="s1">&#39;localhost:9092&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                         <span class="n">key_serializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                         <span class="n">value_serializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">topic_name</span> <span class="o">=</span> <span class="s1">&#39;example-topic&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">message</span> <span class="o">=</span> <span class="s1">&#39;Hello, Kafka!&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">topic_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s1">&#39;key1&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">message</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">producer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋-3">解釋</h6>
<ul>
<li><code>bootstrap.servers</code>：要使用的 Kafka cluster 位址</li>
<li><code>key.serializer</code> &amp; <code>value.serializer</code>：如何將 producer 要傳送的 key-value 物件轉成 bytes</li>
</ul>
<h5 id="發送訊息">發送訊息</h5>
<p>要發送訊息的話，則呼叫 <code>send</code> 方法，包含 topic name, key, value。serializers 確保 key value 都被加密成 bytes</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">topic_name</span> <span class="o">=</span> <span class="s1">&#39;example-topic&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">key</span> <span class="o">=</span> <span class="s1">&#39;key1&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">value</span> <span class="o">=</span> <span class="s1">&#39;Hello, Kafka!&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">topic_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋-4">解釋</h6>
<ul>
<li>
<p><code>producer.send(topic_name, key=key, value=value)</code></p>
<blockquote>
<p>將 record/message 發送至 Kafka cluster，內容包含指定 topic, key, value</p>
</blockquote>
</li>
</ul>
<h5 id="錯誤處理">錯誤處理</h5>
<p>使用 <code>try-except</code> 區塊處理錯誤，並調整 <code>send</code> 方法以納入錯誤處理</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka.errors</span> <span class="kn">import</span> <span class="n">KafkaError</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">try</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">future</span> <span class="o">=</span> <span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">topic_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s1">&#39;key1&#39;</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">message</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">record_metadata</span> <span class="o">=</span> <span class="n">future</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">timeout</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Message sent successfully to topic </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">topic</span><span class="si">}</span><span class="s1">, partition </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">partition</span><span class="si">}</span><span class="s1">, offset </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">offset</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">except</span> <span class="n">KafkaError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Error sending message: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">finally</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h6 id="解釋-5">解釋</h6>
<ul>
<li><code>try-except-finally</code>：確保 producer 不管成功失敗都正確關閉</li>
<li><code>KafkaError</code>：捕獲 Kafka operation 相關的錯誤</li>
<li><code>future.get(timeout=10)</code>：等待發送操作完成，並取得 metadata 或拋出錯誤</li>
</ul>
<h4 id="6-1-4-task">6-1-4 Task</h4>
<ol>
<li>
<p>Introduction to Kafka Producers: Kafka producers are applications that send records to Kafka topics. A record is a key-value pair that can also have metadata such as a timestamp. Producers send these records to categories called topics.</p>
</li>
<li>
<p>What is the role of a Kafka producer? <strong>An application that sends records to Kafka topics</strong></p>
</li>
<li>
<p>Which property specifies the address of your Kafka cluster in the producer configuration? <strong>bootstrap.servers</strong></p>
</li>
<li>
<p>What does the <code>acks</code> property in Kafka producer configuration signify? <strong>The number of acknowledgements the producer requires from the cluster</strong></p>
</li>
<li>
<p>Add below in the build.gradle file</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-groovy" data-lang="groovy"><span class="line"><span class="cl"><span class="n">dependencies</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">implementation</span> <span class="s1">&#39;org.apache.kafka:kafka-clients:3.3.1&#39;</span>   <span class="err">#</span> <span class="n">add</span> <span class="k">this</span>
</span></span><span class="line"><span class="cl">    <span class="n">implementation</span> <span class="s1">&#39;ch.qos.logback:logback-classic:1.2.10&#39;</span>  
</span></span><span class="line"><span class="cl">    <span class="n">testImplementation</span> <span class="s1">&#39;junit:junit:4.13.2&#39;</span>                 
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Which serializer is used for the key in the producer configuration?</p>
<p><code>org.apache.kafka.common.serialization.IntegerSerializer</code></p>
<p><code>org.apache.kafka.common.serialization.ByteArraySerializer</code></p>
<blockquote>
<p>The key and value serializers need to convert the data into bytes.</p>
</blockquote>
<p><code>org.apache.kafka.common.serialization.StringSerializer</code></p>
<p><code>org.apache.kafka.common.serialization.LongSerializer</code></p>
</li>
<li>
<p>Configure the Kafka producer in <code>/root/kafka-producer/.../SimpleProducer</code>. Build the project after configuring SimpleProducer.java</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">vi src/main/java/com/example/SimpleProducer.java
</span></span><span class="line"><span class="cl"><span class="c1"># paste</span>
</span></span><span class="line"><span class="cl">   package com.example<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   import org.apache.kafka.clients.producer.KafkaProducer<span class="p">;</span>
</span></span><span class="line"><span class="cl">   import org.apache.kafka.clients.producer.Producer<span class="p">;</span>
</span></span><span class="line"><span class="cl">   import org.apache.kafka.clients.producer.ProducerRecord<span class="p">;</span>
</span></span><span class="line"><span class="cl">   import java.util.Properties<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">   public class SimpleProducer <span class="o">{</span>
</span></span><span class="line"><span class="cl">       public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">           Properties <span class="nv">props</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           props.put<span class="o">(</span><span class="s2">&#34;bootstrap.servers&#34;</span>, <span class="s2">&#34;localhost:9092&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           props.put<span class="o">(</span><span class="s2">&#34;key.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           props.put<span class="o">(</span><span class="s2">&#34;value.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           Producer&lt;String, String&gt; <span class="nv">producer</span> <span class="o">=</span> new KafkaProducer&lt;&gt;<span class="o">(</span>props<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           String <span class="nv">topicName</span> <span class="o">=</span> <span class="s2">&#34;example-topic&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           String <span class="nv">message</span> <span class="o">=</span> <span class="s2">&#34;Hello, Kafka!&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">           producer.send<span class="o">(</span>new ProducerRecord&lt;&gt;<span class="o">(</span>topicName, <span class="s2">&#34;key1&#34;</span>, message<span class="o">))</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           try <span class="o">{</span>
</span></span><span class="line"><span class="cl">               producer.send<span class="o">(</span>new ProducerRecord&lt;&gt;<span class="o">(</span>topicName, <span class="s2">&#34;key1&#34;</span>, message<span class="o">))</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="o">}</span> catch <span class="o">(</span>Exception e<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">               System.out.println<span class="o">(</span><span class="s2">&#34;Error: &#34;</span>+ e.getMessage<span class="o">())</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">           <span class="o">}</span> finally <span class="o">{</span>
</span></span><span class="line"><span class="cl">               producer.close<span class="o">()</span><span class="p">;</span> 
</span></span><span class="line"><span class="cl">           <span class="o">}</span>  
</span></span><span class="line"><span class="cl">       <span class="o">}</span>
</span></span><span class="line"><span class="cl">   <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /root/kafka-producer
</span></span><span class="line"><span class="cl"><span class="c1"># ls and check that the gradlew is here</span>
</span></span><span class="line"><span class="cl"><span class="c1"># run gradle to build the project</span>
</span></span><span class="line"><span class="cl">./gradlew build
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>What does producer.send() do? <strong>It sends record to Kafka cluster.</strong></p>
</li>
<li>
<p>Send the message <code>Hi, this message is from the Java producer</code> to the <code>kodekloud</code> Kafka topic using the Java producer.</p>
<p>Build the project after configuring SimpleProducer.java</p>
<p>To run the java code use <code>java -jar /root/kafka-producer/build/libs/kafka-producer.jar</code> command.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># navigate to the project directory</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /root/kafka-producer
</span></span><span class="line"><span class="cl"><span class="c1"># create the necessary directories for your Java source files if they do not already exist</span>
</span></span><span class="line"><span class="cl">mkdir -p src/main/java/com/example
</span></span><span class="line"><span class="cl"><span class="c1"># use the SimpleProducer created per previous task to modify</span>
</span></span><span class="line"><span class="cl">package com.example<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.KafkaProducer<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.Producer<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.ProducerRecord<span class="p">;</span>
</span></span><span class="line"><span class="cl">import java.util.Properties<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">public class SimpleProducer <span class="o">{</span>
</span></span><span class="line"><span class="cl">    public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">        Properties <span class="nv">props</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;bootstrap.servers&#34;</span>, <span class="s2">&#34;localhost:9092&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;key.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;value.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        Producer&lt;String, String&gt; <span class="nv">producer</span> <span class="o">=</span> new KafkaProducer&lt;&gt;<span class="o">(</span>props<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Send the message to the <span class="s2">&#34;kodekloud&#34;</span> Kafka topic
</span></span><span class="line"><span class="cl">        String <span class="nv">topicName</span> <span class="o">=</span> <span class="s2">&#34;kodekloud&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        String <span class="nv">message</span> <span class="o">=</span> <span class="s2">&#34;Hi, this message is from the Java producer&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        producer.send<span class="o">(</span>new ProducerRecord&lt;&gt;<span class="o">(</span>topicName, <span class="s2">&#34;messageKey&#34;</span>, message<span class="o">))</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        System.out.println<span class="o">(</span><span class="s2">&#34;Message sent: &#34;</span> + message<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        producer.close<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># run the java code</span>
</span></span><span class="line"><span class="cl">./gradlew clean build
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Which command is used to retrieve the message from the <code>kodekloud</code> topic on a Kafka broker running at localhost:9092?</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">/root/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --topic kodekloud <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --from-beginning
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>What is the purpose of the callback mechanism in Kafka producer? Error handling</p>
</li>
<li>
<p>Implement error handling in the Kafka producer using a callback.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># implemente error handling in the Kafka producer using a callback</span>
</span></span><span class="line"><span class="cl">package com.example<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.KafkaProducer<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.Producer<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.ProducerRecord<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.RecordMetadata<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.producer.Callback<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import java.util.Properties<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">public class SimpleProducer <span class="o">{</span>
</span></span><span class="line"><span class="cl">    public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">        // Step 1: Set the properties <span class="k">for</span> the Kafka producer
</span></span><span class="line"><span class="cl">        Properties <span class="nv">props</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;bootstrap.servers&#34;</span>, <span class="s2">&#34;localhost:9092&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;key.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span><span class="s2">&#34;value.serializer&#34;</span>, <span class="s2">&#34;org.apache.kafka.common.serialization.StringSerializer&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Step 2: Create a Kafka producer
</span></span><span class="line"><span class="cl">        Producer&lt;String, String&gt; <span class="nv">producer</span> <span class="o">=</span> new KafkaProducer&lt;&gt;<span class="o">(</span>props<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Step 3: Define the topic and message to send
</span></span><span class="line"><span class="cl">        String <span class="nv">topicName</span> <span class="o">=</span> <span class="s2">&#34;kodekloud&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        String <span class="nv">message</span> <span class="o">=</span> <span class="s2">&#34;Hi, this message is from the Java producer&#34;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Step 4: Create a callback to handle success and error scenarios
</span></span><span class="line"><span class="cl">        Callback <span class="nv">callback</span> <span class="o">=</span> new Callback<span class="o">()</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">            @Override
</span></span><span class="line"><span class="cl">            public void onCompletion<span class="o">(</span>RecordMetadata metadata, Exception exception<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="o">(</span><span class="nv">exception</span> <span class="o">==</span> null<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">                    // The message was sent successfully
</span></span><span class="line"><span class="cl">                    System.out.println<span class="o">(</span><span class="s2">&#34;Message sent successfully to topic &#34;</span> + metadata.topic<span class="o">()</span> +
</span></span><span class="line"><span class="cl">                                       <span class="s2">&#34; partition &#34;</span> + metadata.partition<span class="o">()</span> +
</span></span><span class="line"><span class="cl">                                       <span class="s2">&#34; offset &#34;</span> + metadata.offset<span class="o">())</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">                <span class="o">}</span> <span class="k">else</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">                    // There was an error sending the message
</span></span><span class="line"><span class="cl">                    System.err.println<span class="o">(</span><span class="s2">&#34;Error sending message: &#34;</span> + exception.getMessage<span class="o">())</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">                <span class="o">}</span>
</span></span><span class="line"><span class="cl">            <span class="o">}</span>
</span></span><span class="line"><span class="cl">        <span class="o">}</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Step 5: Send the message with the callback
</span></span><span class="line"><span class="cl">        producer.send<span class="o">(</span>new ProducerRecord&lt;&gt;<span class="o">(</span>topicName, <span class="s2">&#34;messageKey&#34;</span>, message<span class="o">)</span>, callback<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Step 6: Close the producer
</span></span><span class="line"><span class="cl">        producer.close<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl">./gradlew clean build
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Implement a <strong>Kafka producer</strong> using <strong>Python</strong>. Your implementation should include setting up the producer to connect to a Kafka broker running on <code>localhost:9092</code> and define a topic named <code>payment-transactions</code>. Use the <strong>kafka-python</strong> library to achieve this. Send the following message to the payment-transactions topic: <code>Payment processed successfully</code></p>
<p>Create a file named <code>SimpleProducer.py</code> in the <code>/root/kafka-producer</code> directory and write your script in this file.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">pip install kafka-python
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">vi /root/kafka-producer/SimpleProducer.py
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">from kafka import KafkaProducer
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">def main<span class="o">()</span>:
</span></span><span class="line"><span class="cl">    <span class="c1"># Kafka configuration</span>
</span></span><span class="line"><span class="cl">    <span class="nv">kafka_config</span> <span class="o">=</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;bootstrap_servers&#39;</span>: <span class="s1">&#39;localhost:9092&#39;</span>,
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;key_serializer&#39;</span>: str.encode,
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;value_serializer&#39;</span>: str.encode
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Create Kafka producer</span>
</span></span><span class="line"><span class="cl">    <span class="nv">producer</span> <span class="o">=</span> KafkaProducer<span class="o">(</span>**kafka_config<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Send the message to the &#34;payment-transactions&#34; Kafka topic</span>
</span></span><span class="line"><span class="cl">    <span class="nv">topic_name</span> <span class="o">=</span> <span class="s2">&#34;payment-transactions&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nv">message_key</span> <span class="o">=</span> <span class="s2">&#34;transactionKey&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nv">message_value</span> <span class="o">=</span> <span class="s2">&#34;Payment processed successfully&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Produce the message</span>
</span></span><span class="line"><span class="cl">    producer.send<span class="o">(</span>topic_name, <span class="nv">key</span><span class="o">=</span>message_key, <span class="nv">value</span><span class="o">=</span>message_value<span class="o">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Wait for all messages to be sent</span>
</span></span><span class="line"><span class="cl">    producer.flush<span class="o">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="nv">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span>:
</span></span><span class="line"><span class="cl">    main<span class="o">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>To implement <strong>error handling</strong> in the Kafka producer using a <strong>KafkaError</strong>. We can use the below code.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaProducer</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka.errors</span> <span class="kn">import</span> <span class="n">KafkaError</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">on_send_success</span><span class="p">(</span><span class="n">record_metadata</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Message sent to topic: </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">topic</span><span class="si">}</span><span class="s2">, partition: </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">partition</span><span class="si">}</span><span class="s2">, offset: </span><span class="si">{</span><span class="n">record_metadata</span><span class="o">.</span><span class="n">offset</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">on_send_error</span><span class="p">(</span><span class="n">excp</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Error while producing message: </span><span class="si">{</span><span class="n">excp</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Kafka configuration</span>
</span></span><span class="line"><span class="cl">    <span class="n">kafka_config</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;bootstrap_servers&#39;</span><span class="p">:</span> <span class="s1">&#39;localhost:9092&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;key_serializer&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="o">.</span><span class="n">encode</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;value_serializer&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="o">.</span><span class="n">encode</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Create Kafka producer</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer</span> <span class="o">=</span> <span class="n">KafkaProducer</span><span class="p">(</span><span class="o">**</span><span class="n">kafka_config</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Send the message to the &#34;payment-transactions&#34; Kafka topic</span>
</span></span><span class="line"><span class="cl">    <span class="n">topic_name</span> <span class="o">=</span> <span class="s2">&#34;payment-transactions&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">message_key</span> <span class="o">=</span> <span class="s2">&#34;transactionKey&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">message_value</span> <span class="o">=</span> <span class="s2">&#34;Payment processed successfully&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Produce the message with error handling</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer</span><span class="o">.</span><span class="n">send</span><span class="p">(</span><span class="n">topic_name</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">message_key</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">message_value</span><span class="p">)</span><span class="o">.</span><span class="n">add_callback</span><span class="p">(</span><span class="n">on_send_success</span><span class="p">)</span><span class="o">.</span><span class="n">add_errback</span><span class="p">(</span><span class="n">on_send_error</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Wait for all messages to be sent</span>
</span></span><span class="line"><span class="cl">    <span class="n">producer</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&#34;__main__&#34;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">main</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<hr>
<h3 id="6-2-撰寫-kafka-consumers">6-2 撰寫 Kafka Consumers</h3>
<p>此章節目的在讓讀者了解如何使用 Java API + Gradle 以及 Python 撰寫 Kafka consumer，重點在於 consumer 配置、資料讀取、管理 offset。Consumer 在實現即時資料處理分析扮演很重要的角色（從 Kafka topics 讀取資料）。</p>
<h4 id="6-2-1-kafka-consumer">6-2-1 Kafka Consumer</h4>
<p>Kafka Consumer 從 Kafka cluster 讀取資料，consumers 會訂閱一到多個 topics，並處理收到的 streams of records。在 Kafka 中，consumer 負責追蹤它已經處理的 record，這個追蹤行為就稱為管理偏移量。</p>
<h5 id="使用-kafka-consumer-的原因">使用 Kafka Consumer 的原因</h5>
<ul>
<li>可擴展性：consumer 能夠水平擴展，以平行化讀取 topics 內容</li>
<li>容錯：支援 automatic offset commit 能力，確保 consumer 故障時也不會有資料遺失</li>
<li>彈性：consumer 可以從某一個特定的 offset 開始讀取，允許多樣的 processing strategies（例如 reprocessing historical data）</li>
</ul>
<h4 id="6-2-2-設定環境">6-2-2 設定環境</h4>
<p>在撰寫 Kafka consumer 之前，需要先設定開發環境，包括安裝 Kafka、用 gradle 建立 Java project、建立 Python 合適環境。</p>
<h5 id="安裝-kafka">安裝 Kafka</h5>
<p>從官網下載 / 解壓縮 Kafka，啟動 ZooKeeper 以及 Kafka server</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># Start Zookeeper</span>
</span></span><span class="line"><span class="cl">bin/zookeeper-server-start.sh config/zookeeper.properties
</span></span><span class="line"><span class="cl"><span class="c1"># Start Kafka Server</span>
</span></span><span class="line"><span class="cl">bin/kafka-server-start.sh config/server.properties
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="6-2-3-以-java-建立-kafka-consumer">6-2-3 以 Java 建立 Kafka Consumer</h4>
<p>建立一個目錄，然後初始化一個 Gradle 專案</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">mkdir kafka-consumer-java
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> kafka-consumer-java
</span></span><span class="line"><span class="cl">gradle init --type java-application
</span></span></code></pre></td></tr></table>
</div>
</div><p>將 Kafka client dependency 加入 <code>build.gradle</code> 檔案</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-groovy" data-lang="groovy"><span class="line"><span class="cl"><span class="n">dependencies</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">implementation</span> <span class="s1">&#39;org.apache.kafka:kafka-clients:2.8.0&#39;</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>接下來要撰寫一個 Kafka consumer 用來訂閱 topics 並將 message 印到 console</p>
</blockquote>
<h5 id="基本的-consumer-config">基本的 consumer config</h5>
<p>建立 <code>src/&lt;path-to-your-consumer-package&gt;/SimpleConsumer.java</code> 初始化</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.ConsumerConfig</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Arrays</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Properties</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">public</span><span class="w"> </span><span class="kd">class</span> <span class="nc">SimpleConsumer</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">String</span><span class="o">[]</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">BOOTSTRAP_SERVERS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;localhost:9092&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">GROUP_ID_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;test-group&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;org.apache.kafka.common.serialization.StringDeserializer&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">AUTO_OFFSET_RESET_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;earliest&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">try</span><span class="w"> </span><span class="p">(</span><span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">consumer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">KafkaConsumer</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">props</span><span class="p">))</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">consumer</span><span class="p">.</span><span class="na">subscribe</span><span class="p">(</span><span class="n">Arrays</span><span class="p">.</span><span class="na">asList</span><span class="p">(</span><span class="s">&#34;test-topic&#34;</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">// Consumer logic goes here</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h5 id="讀取訊息">讀取訊息</h5>
<p>在 try block 裡面加入 poll for new message 並印出來的邏輯</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="kc">true</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">records</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">consumer</span><span class="p">.</span><span class="na">poll</span><span class="p">(</span><span class="n">Duration</span><span class="p">.</span><span class="na">ofMillis</span><span class="p">(</span><span class="n">100</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">ConsumerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">record</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">records</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">printf</span><span class="p">(</span><span class="s">&#34;offset = %d, key = %s, value = %s%n&#34;</span><span class="p">,</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">offset</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">key</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">value</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>以上是簡單的 Java Kafka Consumer。</p>
<h4 id="6-2-4-以-python-建立-kafka-consumer">6-2-4 以 Python 建立 Kafka Consumer</h4>
<p>確定已經安裝了 Python，然後建立一個新的 virtual environment</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">python3 -m venv kafka-consumer-python
</span></span><span class="line"><span class="cl"><span class="nb">source</span> kafka-consumer-python/bin/activate
</span></span></code></pre></td></tr></table>
</div>
</div><p>安裝 Kafka Python package</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">pip install kafka-python
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="基本的-consumer-config-1">基本的 consumer config</h5>
<p>建立一個 python script <code>simple_consumer.py</code>，以下是基本的配置內容：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaConsumer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;test-topic&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;localhost:9092&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">auto_offset_reset</span><span class="o">=</span><span class="s1">&#39;earliest&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_id</span><span class="o">=</span><span class="s1">&#39;test-group&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">value_deserializer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h5 id="讀取訊息-1">讀取訊息</h5>
<p>加入持續讀取訊息並印出來的邏輯</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">consumer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;offset = </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">offset</span><span class="si">}</span><span class="s2">, key = </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">key</span><span class="si">}</span><span class="s2">, value = </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">value</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>以上是簡單的 Python Kafka Consumer。</p>
<h4 id="6-2-5-管理-offsets">6-2-5 管理 Offsets</h4>
<p>Kafka consumer 使用 offset 來追蹤已經消費過的訊息。預設會自動提交 offset，但是也能做手動管理以提供更精細的控制。</p>
<h5 id="自動-offset-提交">自動 offset 提交</h5>
<p>上述兩個 consumers 都使用 automatic offset commiting，這個行為是由 <code>enable.auto.commit</code> 的配置所控制（預設是 <code>true</code>)</p>
<h5 id="手動-offset-提交">手動 offset 提交</h5>
<p>如果要 manual offset commiting 的話：</p>
<ul>
<li>
<p>Java：將 <code>enable.auto.commit=false</code> ，在 message loop 裡面調用 <code>commitSync</code> 方法</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">ENABLE_AUTO_COMMIT_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;false&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c1">// Inside the polling loop</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="n">consumer</span><span class="p">.</span><span class="na">commitSync</span><span class="p">();</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Python：在 message loop 裡面調用 <code>commit</code> 方法</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span><span class="n">enable_auto_commit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Inside the message loop</span>
</span></span><span class="line"><span class="cl"><span class="n">consumer</span><span class="o">.</span><span class="n">commit</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h4 id="6-2-6-task">6-2-6 Task</h4>
<ol>
<li>
<p>What is the primary role of a Kafka consumer in a Kafka ecosystem? <strong>To read and process messages from Kafka topics</strong></p>
</li>
<li>
<p>What is a Kafka Consumer Group used for? <strong>To allow multiple consumers to read messages from a topic in parallel without overlapping</strong></p>
</li>
<li>
<p>What is the first step in creating a Kafka consumer in Java? <strong>Configuring consumer properties such as bootstrap server and group ID</strong></p>
</li>
<li>
<p>Which of the following is a required configuration property when creating a Kafka consumer in Java? <strong>group.id</strong></p>
</li>
<li>
<p>After configuring the properties, which class is used to instantiate a Kafka consumer in Java? <strong>KafkaConsumer</strong></p>
</li>
<li>
<p>After instantiating a Kafka consumer, what method is used to subscribe to a Kafka topic? <strong>subscribe()</strong></p>
</li>
<li>
<p>Once a Kafka consumer is subscribe to a topic, which method is typically used to pull messages from Kafka? <strong>poll()</strong></p>
</li>
<li>
<p>After calling the poll() method, what data structure is returned to the consumer containing the records? <strong>ConsumerRecords</strong></p>
</li>
<li>
<p>To commit the offsets of processed messages manually, which method should be used? <strong>commitSync()</strong></p>
</li>
<li>
<p>Configure the <strong>Kafka Consumer</strong> in Java using the <code>/root/kafka-consumer</code> project. Create a Java class <strong><code>SimpleConsumer</code></strong> in <code>kafka-consumer/src/main/java/com/example</code> and set up the <strong>consumer</strong>.</p>
<p><strong>Build the project after configuring SimpleConsumer.java</strong></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nb">cd</span> /root/kafka-consumer
</span></span><span class="line"><span class="cl">mkdir -p src/main/java/com/example
</span></span><span class="line"><span class="cl">vi src/main/java/com/example/SimpleConsumer.java
</span></span><span class="line"><span class="cl">package com.example<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.consumer.ConsumerConfig<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.clients.consumer.KafkaConsumer<span class="p">;</span>
</span></span><span class="line"><span class="cl">import org.apache.kafka.common.serialization.StringDeserializer<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">import java.util.Properties<span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">public class  SimpleConsumer <span class="o">{</span>
</span></span><span class="line"><span class="cl">    public static void main<span class="o">(</span>String<span class="o">[]</span> args<span class="o">)</span> <span class="o">{</span>
</span></span><span class="line"><span class="cl">        Properties <span class="nv">props</span> <span class="o">=</span> new Properties<span class="o">()</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span>ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="s2">&#34;localhost:9092&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span>ConsumerConfig.GROUP_ID_CONFIG, <span class="s2">&#34;my-group&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span>ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName<span class="o">())</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span>ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName<span class="o">())</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        props.put<span class="o">(</span>ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, <span class="s2">&#34;earliest&#34;</span><span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        // Create the Kafka consumer
</span></span><span class="line"><span class="cl">        KafkaConsumer&lt;String, String&gt; <span class="nv">consumer</span> <span class="o">=</span> new KafkaConsumer&lt;&gt;<span class="o">(</span>props<span class="o">)</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># save and exit</span>
</span></span><span class="line"><span class="cl">./gradlew build
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>After configuring and subscribing the Kafka consumer to the topic order-event, write the Java code snippet that pulls messages from the topic.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-java" data-lang="java"><span class="line"><span class="cl"><span class="kn">package</span><span class="w"> </span><span class="nn">com.example</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.ConsumerConfig</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.ConsumerRecord</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.ConsumerRecords</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.clients.consumer.KafkaConsumer</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">org.apache.kafka.common.serialization.StringDeserializer</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.time.Duration</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Collections</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kn">import</span><span class="w"> </span><span class="nn">java.util.Properties</span><span class="p">;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="kd">public</span><span class="w"> </span><span class="kd">class</span>  <span class="nc">SimpleConsumer</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="kd">public</span><span class="w"> </span><span class="kd">static</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="nf">main</span><span class="p">(</span><span class="n">String</span><span class="o">[]</span><span class="w"> </span><span class="n">args</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">BOOTSTRAP_SERVERS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;localhost:9092&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">GROUP_ID_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;my-group&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">KEY_DESERIALIZER_CLASS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="n">StringDeserializer</span><span class="p">.</span><span class="na">class</span><span class="p">.</span><span class="na">getName</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">VALUE_DESERIALIZER_CLASS_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="n">StringDeserializer</span><span class="p">.</span><span class="na">class</span><span class="p">.</span><span class="na">getName</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">props</span><span class="p">.</span><span class="na">put</span><span class="p">(</span><span class="n">ConsumerConfig</span><span class="p">.</span><span class="na">AUTO_OFFSET_RESET_CONFIG</span><span class="p">,</span><span class="w"> </span><span class="s">&#34;earliest&#34;</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Create the Kafka consumer</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">KafkaConsumer</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">consumer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">KafkaConsumer</span><span class="o">&lt;&gt;</span><span class="p">(</span><span class="n">props</span><span class="p">);</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Add below codes for task# 11 🌟</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Subscribe to the &#39;order-events&#39; topic</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="n">consumer</span><span class="p">.</span><span class="na">subscribe</span><span class="p">(</span><span class="n">Collections</span><span class="p">.</span><span class="na">singletonList</span><span class="p">(</span><span class="s">&#34;order-events&#34;</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c1">// Poll for new messages and print them to the console</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="k">try</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="kc">true</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="c1">// Poll Kafka broker for new records (with a timeout of 1000 milliseconds)</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="n">ConsumerRecords</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">records</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">consumer</span><span class="p">.</span><span class="na">poll</span><span class="p">(</span><span class="n">Duration</span><span class="p">.</span><span class="na">ofMillis</span><span class="p">(</span><span class="n">1000</span><span class="p">));</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="c1">// Process each record and print to console</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">ConsumerRecord</span><span class="o">&lt;</span><span class="n">String</span><span class="p">,</span><span class="w"> </span><span class="n">String</span><span class="o">&gt;</span><span class="w"> </span><span class="n">record</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">records</span><span class="p">)</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                    </span><span class="c1">// Print consumed message details to the console</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                    </span><span class="n">System</span><span class="p">.</span><span class="na">out</span><span class="p">.</span><span class="na">printf</span><span class="p">(</span><span class="s">&#34;Consumed message: key = %s, value = %s, partition = %d, offset = %d%n&#34;</span><span class="p">,</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                            </span><span class="kd">record</span><span class="err">.</span><span class="nc">key</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">value</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">partition</span><span class="p">(),</span><span class="w"> </span><span class="n">record</span><span class="p">.</span><span class="na">offset</span><span class="p">());</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">                </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w"> </span><span class="k">finally</span><span class="w"> </span><span class="p">{</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="c1">// Ensure the consumer is closed properly</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="n">consumer</span><span class="p">.</span><span class="na">close</span><span class="p">();</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="p">}</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="p">}</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>Which library provides Python support for working with Kafka in a more Kafka-native style, supporting both consumers and producers? <strong>kafka-python</strong></p>
</li>
<li>
<p><strong>Write the Python code snippet</strong> that <strong>pulls messages</strong> from the <code>payment-transactions</code> topic using <strong><code>kafka-python</code></strong>.</p>
<p>Create a file named <code>SimpleConsumer.py</code> in the <code>/root/</code> directory and write your script in this file.</p>
<p><strong>NOTE</strong>: Run the <strong>Python code</strong> to <strong>pull messages</strong> by executing: <code>python3 /root/SimpleConsumer.py</code> and <strong>do not stop</strong> or <strong>terminate</strong> the code.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># install kafka-python library</span>
</span></span><span class="line"><span class="cl">pip install kafka-python
</span></span><span class="line"><span class="cl"><span class="c1"># create a python script</span>
</span></span><span class="line"><span class="cl">vi /root/SimpleConsumer.py
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># At SimpleConsumer.py</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">kafka</span> <span class="kn">import</span> <span class="n">KafkaConsumer</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Set up the Kafka consumer</span>
</span></span><span class="line"><span class="cl"><span class="n">consumer</span> <span class="o">=</span> <span class="n">KafkaConsumer</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;payment-transactions&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">group_id</span><span class="o">=</span><span class="s1">&#39;my-group&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">bootstrap_servers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;localhost:9092&#39;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">    <span class="n">auto_offset_reset</span><span class="o">=</span><span class="s1">&#39;earliest&#39;</span>
</span></span><span class="line"><span class="cl"><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Poll messages from the topic</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">message</span> <span class="ow">in</span> <span class="n">consumer</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Topic: </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">topic</span><span class="si">}</span><span class="s2">, Partition: </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">partition</span><span class="si">}</span><span class="s2">, Offset: </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">offset</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;Key: </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">key</span><span class="si">}</span><span class="s2">, Value: </span><span class="si">{</span><span class="n">message</span><span class="o">.</span><span class="n">value</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># run the python code to pull messages</span>
</span></span><span class="line"><span class="cl">python3 /root/SimpleConsumer.py
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="結語">結語</h2>
<ol>
<li>不確定是否要用 http api 進行 producer 發佈訊息的動作？如果是的話，可能需要再 study Kafka Rest Proxy</li>
<li>不確定 consumer 這段用 Kafka Connect + MongoDB 方向是否正確？如果是的話，則要再 study Kafka MongoDB Sink Connector ，或者可能有 best practice example 可查看</li>
<li>Zilla 這個工具看他放在官網的 before / after 示意圖，看來能夠直接取代 Kafka Rest Proxy 跟 Kafka Connect。</li>
</ol>
</li>
</ol>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-12-03</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://wysiwyz.github.io/posts/kk_learn_by_doing_apache_kafka/" data-hashtag="apache"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://wysiwyz.github.io/posts/kk_learn_by_doing_apache_kafka/" data-title="Apache Kafka 做中學"><i data-svg-src="https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/apache/">Apache</a>,&nbsp;<a href="/tags/kafka/">Kafka</a>,&nbsp;<a href="/tags/kodekloud/">Kodekloud</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/cncf-kubestronaut-01kcna/" class="prev" rel="prev" title="01 Kubestronaut KCNA &amp; KCSA"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>01 Kubestronaut KCNA & KCSA</a></div>
</div>
<div id="comments"><div id="disqus_thread" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://disqus.com/?ref_noscript">Disqus</a>.
            </noscript><div id="valine" class="comment"></div><noscript>
                Please enable JavaScript to view the comments powered by <a href="https://valine.js.org/">Valine</a>.
            </noscript></div></article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">strict with yourself; lenient with others.</div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/valine/valine.min.css"><script type="text/javascript" src="https://.disqus.com/embed.js" defer></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/valine@1.5.0/dist/Valine.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/twemoji@14.0.2/dist/twemoji.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js"></script><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{"valine":{"appId":"","appKey":"","avatar":"mp","el":"#valine","emojiCDN":"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/","emojiMaps":{"100":"1f4af.png","alien":"1f47d.png","anger":"1f4a2.png","angry":"1f620.png","anguished":"1f627.png","astonished":"1f632.png","black_heart":"1f5a4.png","blue_heart":"1f499.png","blush":"1f60a.png","bomb":"1f4a3.png","boom":"1f4a5.png","broken_heart":"1f494.png","brown_heart":"1f90e.png","clown_face":"1f921.png","cold_face":"1f976.png","cold_sweat":"1f630.png","confounded":"1f616.png","confused":"1f615.png","cry":"1f622.png","crying_cat_face":"1f63f.png","cupid":"1f498.png","dash":"1f4a8.png","disappointed":"1f61e.png","disappointed_relieved":"1f625.png","dizzy":"1f4ab.png","dizzy_face":"1f635.png","drooling_face":"1f924.png","exploding_head":"1f92f.png","expressionless":"1f611.png","face_vomiting":"1f92e.png","face_with_cowboy_hat":"1f920.png","face_with_hand_over_mouth":"1f92d.png","face_with_head_bandage":"1f915.png","face_with_monocle":"1f9d0.png","face_with_raised_eyebrow":"1f928.png","face_with_rolling_eyes":"1f644.png","face_with_symbols_on_mouth":"1f92c.png","face_with_thermometer":"1f912.png","fearful":"1f628.png","flushed":"1f633.png","frowning":"1f626.png","ghost":"1f47b.png","gift_heart":"1f49d.png","green_heart":"1f49a.png","grimacing":"1f62c.png","grin":"1f601.png","grinning":"1f600.png","hankey":"1f4a9.png","hear_no_evil":"1f649.png","heart":"2764-fe0f.png","heart_decoration":"1f49f.png","heart_eyes":"1f60d.png","heart_eyes_cat":"1f63b.png","heartbeat":"1f493.png","heartpulse":"1f497.png","heavy_heart_exclamation_mark_ornament":"2763-fe0f.png","hole":"1f573-fe0f.png","hot_face":"1f975.png","hugging_face":"1f917.png","hushed":"1f62f.png","imp":"1f47f.png","innocent":"1f607.png","japanese_goblin":"1f47a.png","japanese_ogre":"1f479.png","joy":"1f602.png","joy_cat":"1f639.png","kiss":"1f48b.png","kissing":"1f617.png","kissing_cat":"1f63d.png","kissing_closed_eyes":"1f61a.png","kissing_heart":"1f618.png","kissing_smiling_eyes":"1f619.png","laughing":"1f606.png","left_speech_bubble":"1f5e8-fe0f.png","love_letter":"1f48c.png","lying_face":"1f925.png","mask":"1f637.png","money_mouth_face":"1f911.png","nauseated_face":"1f922.png","nerd_face":"1f913.png","neutral_face":"1f610.png","no_mouth":"1f636.png","open_mouth":"1f62e.png","orange_heart":"1f9e1.png","partying_face":"1f973.png","pensive":"1f614.png","persevere":"1f623.png","pleading_face":"1f97a.png","pouting_cat":"1f63e.png","purple_heart":"1f49c.png","rage":"1f621.png","relaxed":"263a-fe0f.png","relieved":"1f60c.png","revolving_hearts":"1f49e.png","right_anger_bubble":"1f5ef-fe0f.png","robot_face":"1f916.png","rolling_on_the_floor_laughing":"1f923.png","scream":"1f631.png","scream_cat":"1f640.png","see_no_evil":"1f648.png","shushing_face":"1f92b.png","skull":"1f480.png","skull_and_crossbones":"2620-fe0f.png","sleeping":"1f634.png","sleepy":"1f62a.png","slightly_frowning_face":"1f641.png","slightly_smiling_face":"1f642.png","smile":"1f604.png","smile_cat":"1f638.png","smiley":"1f603.png","smiley_cat":"1f63a.png","smiling_face_with_3_hearts":"1f970.png","smiling_imp":"1f608.png","smirk":"1f60f.png","smirk_cat":"1f63c.png","sneezing_face":"1f927.png","sob":"1f62d.png","space_invader":"1f47e.png","sparkling_heart":"1f496.png","speak_no_evil":"1f64a.png","speech_balloon":"1f4ac.png","star-struck":"1f929.png","stuck_out_tongue":"1f61b.png","stuck_out_tongue_closed_eyes":"1f61d.png","stuck_out_tongue_winking_eye":"1f61c.png","sunglasses":"1f60e.png","sweat":"1f613.png","sweat_drops":"1f4a6.png","sweat_smile":"1f605.png","thinking_face":"1f914.png","thought_balloon":"1f4ad.png","tired_face":"1f62b.png","triumph":"1f624.png","two_hearts":"1f495.png","unamused":"1f612.png","upside_down_face":"1f643.png","weary":"1f629.png","white_frowning_face":"2639-fe0f.png","white_heart":"1f90d.png","wink":"1f609.png","woozy_face":"1f974.png","worried":"1f61f.png","yawning_face":"1f971.png","yellow_heart":"1f49b.png","yum":"1f60b.png","zany_face":"1f92a.png","zipper_mouth_face":"1f910.png","zzz":"1f4a4.png"},"enableQQ":false,"highlight":true,"lang":"en","pageSize":10,"placeholder":"Your comment ...","recordIP":true,"visitor":true}},"twemoji":true};</script><script type="text/javascript" src="/js/theme.min.js"></script><script type="text/javascript">
            window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}gtag('js', new Date());
            gtag('config', 'G-CCS3QPVY5N', { 'anonymize_ip': true });
        </script><script type="text/javascript" src="https://www.googletagmanager.com/gtag/js?id=G-CCS3QPVY5N" async></script></body>
</html>
