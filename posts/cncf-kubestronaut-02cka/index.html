<!DOCTYPE html>
<html lang="en-us">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title>Kubestronaut 02 CKA - Ich bin yiwen.</title><meta name="Description" content="An ordinary space for storing and groups pieces of articles."><meta property="og:url" content="http://localhost:1313/posts/cncf-kubestronaut-02cka/">
  <meta property="og:site_name" content="Ich bin yiwen.">
  <meta property="og:title" content="Kubestronaut 02 CKA">
  <meta property="og:description" content="11/30 è¨»ï¼šå¯«éœ€æ±‚åˆ†æä¸å¯æ§çš„å› ç´ å¤ªå¤šäº†ï¼Œé™¤äº†è¦å…¼é¡§ bigger pictureã€detailed processã€granular fields for programmingã€é‚„è¦é¡§æ…®åˆ° user sentimentã€senior criticsã€ â€¦
å°±ç¾éšæ®µè€Œè¨€ï¼Œå·¥ä½œæœ‰é—œçµ¦äººæœ€å¤šæˆå°±æ„Ÿçš„æ˜¯æ‹¿åˆ°è­‰ç…§é€™æ¢è·¯ï¼ˆä¾†äººæ‹¿çƒæ£’æ•²é†’é€™å€‹äººå§ï¼‰ï¼Œå…¶å®ƒéƒ½åƒæ˜¯ç·´ç¿’ï¼Œä¸åœè£½é€ éŒ¯èª¤å†ä¸åœè¢«å°å›æ­£é€”
![image-20241129110027476](/Users/yiwen/Library/Application Support/typora-user-images/image-20241129110027476.png)
Topics not on CKAD but on CKA Workloads/Services
DaemonSets Scheduling/Deploying
Manual Scheduling kube-scheduler Multiple Schedulers Static pods Storage
Hostpath volume Storage Class (creating) Security
Certificate API Obervability
Managing Application Logs Cluster Setup and Maintenance
Cluster install (need to know it but itâ€™s never tested) Cluster upgrade etcd architecture, backup and restore kube-proxy CoreDNS Trouble shooting">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-11-30T06:22:38+08:00">
    <meta property="article:modified_time" content="2024-11-30T06:22:38+08:00">
    <meta property="article:tag" content="Cloud Native">
    <meta property="article:tag" content="Kubernetes">
    <meta property="article:tag" content="CKA">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Kubestronaut 02 CKA">
  <meta name="twitter:description" content="11/30 è¨»ï¼šå¯«éœ€æ±‚åˆ†æä¸å¯æ§çš„å› ç´ å¤ªå¤šäº†ï¼Œé™¤äº†è¦å…¼é¡§ bigger pictureã€detailed processã€granular fields for programmingã€é‚„è¦é¡§æ…®åˆ° user sentimentã€senior criticsã€ â€¦
å°±ç¾éšæ®µè€Œè¨€ï¼Œå·¥ä½œæœ‰é—œçµ¦äººæœ€å¤šæˆå°±æ„Ÿçš„æ˜¯æ‹¿åˆ°è­‰ç…§é€™æ¢è·¯ï¼ˆä¾†äººæ‹¿çƒæ£’æ•²é†’é€™å€‹äººå§ï¼‰ï¼Œå…¶å®ƒéƒ½åƒæ˜¯ç·´ç¿’ï¼Œä¸åœè£½é€ éŒ¯èª¤å†ä¸åœè¢«å°å›æ­£é€”
![image-20241129110027476](/Users/yiwen/Library/Application Support/typora-user-images/image-20241129110027476.png)
Topics not on CKAD but on CKA Workloads/Services
DaemonSets Scheduling/Deploying
Manual Scheduling kube-scheduler Multiple Schedulers Static pods Storage
Hostpath volume Storage Class (creating) Security
Certificate API Obervability
Managing Application Logs Cluster Setup and Maintenance
Cluster install (need to know it but itâ€™s never tested) Cluster upgrade etcd architecture, backup and restore kube-proxy CoreDNS Trouble shooting">
<meta name="application-name" content="Ich bin yiwen.">
<meta name="apple-mobile-web-app-title" content="Ich bin yiwen."><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="icon" href="/moon_icon.svg"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://localhost:1313/posts/cncf-kubestronaut-02cka/" /><link rel="prev" href="http://localhost:1313/posts/kong-hq-academy/" /><link rel="next" href="http://localhost:1313/posts/kk_learn_by_doing_apache_kafka/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Kubestronaut 02 CKA",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:1313\/posts\/cncf-kubestronaut-02cka\/"
        },"genre": "posts","keywords": "Cloud Native, Kubernetes, CKA","wordcount":  11195 ,
        "url": "http:\/\/localhost:1313\/posts\/cncf-kubestronaut-02cka\/","datePublished": "2024-11-30T06:22:38+08:00","dateModified": "2024-11-30T06:22:38+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Author"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Ich bin yiwen.">Ich bin yiwen.</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Ich bin yiwen.">Ich bin yiwen.</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Kubestronaut 02 CKA</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Author</a></span>&nbsp;<span class="post-category">included in <a href="/categories/studynote/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>StudyNote</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2024-11-30">2024-11-30</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;11195 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;53 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#topics-not-on-ckad-but-on-cka">Topics not on CKAD but on CKA</a>
      <ul>
        <li><a href="#013-etcd-for-beginner">013. ETCD for beginner</a></li>
        <li><a href="#016-kube-api-server">016. Kube-API Server</a></li>
        <li><a href="#017-kube-controller-manager">017. Kube controller manager</a></li>
        <li><a href="#018-kube-scheduler">018. Kube scheduler</a></li>
        <li><a href="#019-kubelet">019. Kubelet</a></li>
        <li><a href="#020-kube-proxy">020. Kube Proxy</a></li>
        <li><a href="#041--namespace">041.  namespace</a></li>
        <li><a href="#048-kubectl-apply-command">048. kubectl apply command</a></li>
      </ul>
    </li>
    <li><a href="#-scheduling">ãˆ¢ Scheduling</a>
      <ul>
        <li><a href="#053-manual-scheduling">053. Manual Scheduling</a></li>
        <li><a href="#067-resource-requirements-and-limits">067. Resource Requirements and Limits</a></li>
        <li><a href="#071-daemonsets">071. DaemonSets</a></li>
        <li><a href="#074-static-pods">074. Static Pods</a></li>
        <li><a href="#077-multiple-schedulers">077. Multiple schedulers</a></li>
        <li><a href="#080-configuring-scheduler-profiles">080. Configuring Scheduler Profiles</a></li>
      </ul>
    </li>
    <li><a href="#logging--monitoring">Logging &amp; Monitoring</a>
      <ul>
        <li><a href="#084-monitor-cluster-components">084. Monitor Cluster Components</a></li>
        <li><a href="#096-application-commands">096. Application commands</a></li>
      </ul>
    </li>
    <li><a href="#-cluster-maintenance">ãˆ¥ Cluster Maintenance</a>
      <ul>
        <li><a href="#122-os-upgrades">122. OS upgrades</a></li>
        <li><a href="#125-k8s-software-versions">125. K8s Software versions</a></li>
        <li><a href="#127-cluster-upgrade-process">127. Cluster upgrade process</a></li>
        <li><a href="#131-backup-and-restore-methods">131. Backup and Restore Methods</a></li>
        <li><a href="#134-back-up-and-restore-1">134. Back up and restore (1)</a></li>
        <li><a href="#136-back-up-and-restore-2">136. Back up and restore (2)</a></li>
        <li><a href="#138-references">138. References</a></li>
      </ul>
    </li>
    <li><a href="#-security">ãˆ¦ Security</a>
      <ul>
        <li></li>
        <li><a href="#151-view-certification-details-">151. View certification details â›‘ï¸â›‘ï¸â›‘ï¸</a></li>
        <li><a href="#153-certificates-api-">153. Certificates API â›‘ï¸â›‘ï¸â›‘ï¸</a></li>
        <li><a href="#155-kubeconfig">155. KubeConfig</a></li>
        <li><a href="#167-service-accounts">167. Service Accounts</a></li>
        <li><a href="#170-image-security">170. Image Security</a></li>
        <li><a href="#177-network-policy">177. Network Policy</a></li>
        <li><a href="#211-explore-k8s-environments-ip-a-ip-link-netstat--anp">211. Explore K8s environments (<code>ip a</code>, <code>ip link</code>, <code>netstat -anp</code>)</a></li>
        <li><a href="#212-pod-networking">212. Pod Networking</a></li>
        <li><a href="#215-cni-weave">215. CNI Weave</a></li>
        <li><a href="#217-explore-cni">217. Explore CNI</a></li>
        <li><a href="#219-deploy-network-solution---weave">219. Deploy network solution - Weave</a></li>
        <li><a href="#222-networking-weave">222. Networking Weave</a></li>
        <li><a href="#225-service-networking">225. Service Networking</a></li>
        <li><a href="#226-dns-in-kubernetes">226. DNS in Kubernetes</a></li>
        <li><a href="#243-kubeadm-introduction">243. kubeadm introduction</a></li>
        <li><a href="#245-provision-vms-with-vagrant">245. Provision VMs with Vagrant</a></li>
        <li><a href="#248-deploy-a--k8s-cluster-using-kubeadm">248. Deploy a  K8s Cluster using kubeadm</a></li>
        <li><a href="#226-dns-in-kubernetes-1">226. DNS in Kubernetes</a></li>
        <li><a href="#229-explore-dns">229. Explore DNS</a></li>
        <li><a href="#249-end-to-end-tests">249. End-to-End tests</a></li>
        <li><a href="#257-controlplane-failure">257. Controlplane failure</a></li>
        <li><a href="#254">254.</a></li>
        <li><a href="#257">257.</a></li>
        <li><a href="#260">260.</a></li>
        <li><a href="#260-workernode-failure">260. WorkerNode failure</a></li>
        <li><a href="#262-troubleshoot-network">262. Troubleshoot network</a></li>
        <li><a href="#264-json-path-">264. JSON Path ğŸš§ğŸš§ğŸš§</a></li>
        <li><a href="#268-lightning-lab---1-">268. Lightning Lab - 1 ğŸš§ğŸš§ğŸš§</a></li>
        <li><a href="#deployment-creation-and-update-with-annotation">Deployment Creation and Update with Annotation</a></li>
        <li><a href="#step-1-create-the-deployment">Step 1: Create the Deployment</a></li>
        <li><a href="#step-2-update-the-deployment-image">Step 2: Update the Deployment Image</a></li>
        <li><a href="#step-3-annotate-the-deployment-to-record-the-change">Step 3: Annotate the Deployment to Record the Change</a></li>
        <li><a href="#269270-mock-exam---1">269/270. Mock Exam - 1</a></li>
        <li><a href="#271272-mock-exam---2-">271/272. Mock Exam - 2 ğŸš§ğŸš§ğŸš§</a></li>
        <li><a href="#273274-mock-exam---3-">273/274. Mock Exam - 3 ğŸš§</a></li>
        <li><a href="#notes-on-mousepad">Notes on Mousepad</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><blockquote>
<p>11/30 è¨»ï¼šå¯«éœ€æ±‚åˆ†æä¸å¯æ§çš„å› ç´ å¤ªå¤šäº†ï¼Œé™¤äº†è¦å…¼é¡§ bigger pictureã€detailed processã€granular fields for programmingã€é‚„è¦é¡§æ…®åˆ° user sentimentã€senior criticsã€ &hellip;</p>
<p>å°±ç¾éšæ®µè€Œè¨€ï¼Œå·¥ä½œæœ‰é—œçµ¦äººæœ€å¤šæˆå°±æ„Ÿçš„æ˜¯æ‹¿åˆ°è­‰ç…§é€™æ¢è·¯ï¼ˆä¾†äººæ‹¿çƒæ£’æ•²é†’é€™å€‹äººå§ï¼‰ï¼Œå…¶å®ƒéƒ½åƒæ˜¯ç·´ç¿’ï¼Œä¸åœè£½é€ éŒ¯èª¤å†ä¸åœè¢«å°å›æ­£é€”</p>
<p>![image-20241129110027476](/Users/yiwen/Library/Application Support/typora-user-images/image-20241129110027476.png)</p>
</blockquote>
<h2 id="topics-not-on-ckad-but-on-cka">Topics not on CKAD but on CKA</h2>
<ul>
<li>
<p>Workloads/Services</p>
<ul>
<li>DaemonSets</li>
</ul>
</li>
<li>
<p>Scheduling/Deploying</p>
<ul>
<li>Manual Scheduling</li>
<li>kube-scheduler</li>
<li>Multiple Schedulers</li>
<li>Static pods</li>
</ul>
</li>
<li>
<p>Storage</p>
<ul>
<li>Hostpath volume</li>
<li>Storage Class (creating)</li>
</ul>
</li>
<li>
<p>Security</p>
<ul>
<li>Certificate API</li>
</ul>
</li>
<li>
<p>Obervability</p>
<ul>
<li>Managing Application Logs</li>
</ul>
</li>
<li>
<p>Cluster Setup and Maintenance</p>
<ul>
<li>Cluster install (need to know it but it&rsquo;s never tested)</li>
<li>Cluster upgrade</li>
<li>etcd architecture, backup and restore</li>
<li>kube-proxy</li>
<li>CoreDNS</li>
</ul>
</li>
<li>
<p>Trouble shooting</p>
<ul>
<li>Application failure</li>
<li>Control plane failure</li>
<li>Worker node failure</li>
</ul>
</li>
</ul>
<blockquote>
<p>A service with three pods. We provide label for each pod</p>
</blockquote>
<h3 id="013-etcd-for-beginner">013. ETCD for beginner</h3>
<p>ETCD - distributed reliable key-value data store</p>
<h4 id="etcdctl-version-2">ETCDCTL version 2</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">etcdctl backup
</span></span><span class="line"><span class="cl">etcdctl cluster-health
</span></span><span class="line"><span class="cl">etcdctl mk
</span></span><span class="line"><span class="cl">etcdctl mkdir
</span></span><span class="line"><span class="cl">etcdctl <span class="nb">set</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="etcdctl-version-3">ETCDCTL version 3</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">etcdctl snapshot save
</span></span><span class="line"><span class="cl">etcdctl endpoint health
</span></span><span class="line"><span class="cl">etcdctl get
</span></span><span class="line"><span class="cl">etcdctl put
</span></span></code></pre></td></tr></table>
</div>
</div><p>To set the right version of API, see the environment variable ETCDCTL_API command</p>
<p><code>export ETCDCTL_API=3</code></p>
<p>If you did not set an API version, the default would be version, and if the API version is set to version, the commands listd above for version won&rsquo;t work.</p>
<p>Also, it&rsquo;s mandatory to specify path toe certificate files, such as ca.crt, server.cert, server.key, in order to let ETCDCTL authenticated to the ETCD API Server.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">  --cacert /etc/kubernetes/pki/etcd/ca.crt     
</span></span><span class="line"><span class="cl">  --cert /etc/kubernetes/pki/etcd/server.crt     
</span></span><span class="line"><span class="cl">  --key /etc/kubernetes/pki/etcd/server.key
</span></span></code></pre></td></tr></table>
</div>
</div><p>So a command that execute get verb in the etcd-master pod of namespace kube-system would look like this:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl <span class="nb">exec</span> etcd-master -n kube-system -- sh -c <span class="s2">&#34;ETCDCTL_API=3 etcdctl get / --prefix --keys-only --limit=10 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt  --key /etc/kubernetes/pki/etcd/server.key&#34;</span> 
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="016-kube-api-server">016. Kube-API Server</h3>
<p>The kube-apiserver is responsible for authenticating and validating requests, retrieving and updating data in the etcd data store.</p>
<p>The other components such as the scheduler, kube-controller-manager and kubelet uses the API server to perform updates in the cluster in their respective areas.</p>
<pre tabindex="0"><code>wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-apiserver

kubectl get pods -n kube-system
cat /etc/kubernetes/manifests/kube-apiserver.yaml
cat /etc/systemd/system/kube-apiserver.service
ps -aux | grep kube-apiserver
</code></pre><h3 id="017-kube-controller-manager">017. Kube controller manager</h3>
<p>Continuously monitor the state of various components within the system and works towards bringing the whole system to the desired functioning state.</p>
<p>Besides for the node-controller as stated below, there are many more controllers available such as replication-controller,  deployment-controller, namespace-controller, endpoint-controller, job-controller, pv-protection-controller, pv-binder-controller.</p>
<h4 id="node-controller">Node Controller</h4>
<p>Node monitor period = every 5 seconds (tests the status of each node</p>
<p>Node monitor grace period = 40s (once the node-controller stops receiving hearbeat from a note, it&rsquo;s marked as unreachable, but the node-controller waits for 40 seconds before marking it unreachable.)</p>
<p>POD Eviction Timeout = 5m (after a node is marked unreachable, the node-controller gives it 5 minutes to come back up.)</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get po kube-controller-manager-master -n kube-system
</span></span><span class="line"><span class="cl">cat /etc/systemd/system/kube-controller-manager.service
</span></span><span class="line"><span class="cl">ps -aux <span class="p">|</span> grep kube-controller-manager
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="018-kube-scheduler">018. Kube scheduler</h3>
<p>A kube- scheduler decides which pod goes to where depending on resource requirement.</p>
<ol>
<li>Filter nodes
<ul>
<li>e.g. those with insufficient CPU and memory resources requested by the pod</li>
</ul>
</li>
<li>Rank nodes
<ul>
<li>assign a score to the node from point 0 ~ 10</li>
<li>e.g. the scheduler calculates the amount of resources that will be freed on the nodes after placing the pod on them</li>
</ul>
</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># installing kube-scheduler binary</span>
</span></span><span class="line"><span class="cl">https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-scheduler
</span></span><span class="line"><span class="cl"><span class="c1"># view kube-scheduler options - kubeadm</span>
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/kube-scheduler.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># view the running process and the effective options by listing the process on the master node and search for kube-scheduler</span>
</span></span><span class="line"><span class="cl">ps -aux <span class="p">|</span> grep kube-scheduler
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="019-kubelet">019. Kubelet</h3>
<p>Kubelets are the sole point of contact between worker nodes and master node, and they also send back reports at regular intervals on the status of the ship and the containers on them.</p>
<ul>
<li>Register node</li>
<li>Require runtime to pull image and create pods</li>
<li>Monitor node and pods and report on a timely basis</li>
</ul>
<p>Kubeadm does not deploy kubelets. You must manually install the kubelet on your worker nodes.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># installing kubelet binary</span>
</span></span><span class="line"><span class="cl">https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kubelet
</span></span><span class="line"><span class="cl">ps -aux <span class="p">|</span> grep kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="020-kube-proxy">020. Kube Proxy</h3>
<p>Whenever a pod tries to reach the service using its IP or name, it forwards the traffic to the backend pod.</p>
<p>The service is not an actual thing and cannot join the pod network. It&rsquo;s not a container like pods, so it doesn&rsquo;t have any interfaces or an actively listening process. It&rsquo;s a virtual components that only lives in the K8s memory. But then the service should be accessible across the cluster from any nodes. How is that achieved? That&rsquo;s where kube-proxy comes in.</p>
<p>Kube-proxy is a process that runs on each node in the Kubernetes cluster. Its job is to look for new services, and every time a new services is created, it creates the appropriate rules on each node to forward traffic to those services to the backend pods. One way it does this is using iptables rules.</p>
<p>In this case, it creates an ip-table rules on each node in the cluster to forward <strong>traffic heading to the IP of the service</strong> to the <strong>IP of the actual pod</strong>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># installing kube-proxy binary</span>
</span></span><span class="line"><span class="cl">wget https://storage.googleapis.com/kubernetes-release/release/v1.13.0/bin/linux/amd64/kube-proxy
</span></span><span class="line"><span class="cl"><span class="c1"># extract and run it as servce</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl get pods -n kube-system
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">kube-system		kube-proxy-snmd1
</span></span><span class="line"><span class="cl">kube-system 	kube-proxy-rzhjr
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl get daemonset -n kube-system
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="041--namespace">041.  namespace</h3>
<h4 id="resource-quota">Resource Quota</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ResourceQuota</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">compute-quota</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">dev</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">hard</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">pods</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;10&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">requests.cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;4&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">requests.memory</span><span class="p">:</span><span class="w"> </span><span class="l">5Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">limits.cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;10&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">limits.memory</span><span class="p">:</span><span class="w"> </span><span class="l">10Gi</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="048-kubectl-apply-command">048. kubectl apply command</h3>
<p>to manage object in a declarative way.</p>
<p>The yaml that we wrote is converted to a json format, and it&rsquo;s then stored as the last applied configuration.</p>
<p>Why do we need the &ldquo;last applied configuration&rdquo;? It helped us to figure out what fields have been removed from the local file.</p>
<ul>
<li>Local file: stored in our local system</li>
<li>Last applied configuration:
<ul>
<li>The json file is store on the live object annotation</li>
</ul>
</li>
<li>Kubernetes: stored in memory</li>
</ul>
<h2 id="-scheduling">ãˆ¢ Scheduling</h2>
<h3 id="053-manual-scheduling">053. Manual Scheduling</h3>
<h4 id="how-scheduling-works">How scheduling works?</h4>
<p>Every pod has a <code>spec.nodeName</code> field that is by default unset. Kubernetes add this filed automatically. The scheduler goes through each node and looks for those do not have this property set. Those are the candidate for scheduling. It then identify the right node for the pod by running the scheduling algorithm.</p>
<p>If there&rsquo;s no scheduler to monitor and schedule nodes, what happens? The pods continue to be in a pending state. Without a scheduler, the easiest way to schedule a pod is to simply set the <code>nodeName</code> field to the name of the node in your pod specification while creating the pod. The pod then gets assigned to the specified node.</p>
<p>You can only specify the node name at creation time. What if the pod is already created and you want to assign the pod to a node? K8S won&rsquo;t allow you to modify the nodeName property of a pod, so another way to assign a node to an existing pod is to create a binding object and send a POST request to the pod&rsquo;s binding API, thus mimicking what the actual scheduler does.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># pod-bind-definition.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Binding</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">target</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Node</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">node01</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">curl --header <span class="s2">&#34;Content-Type:application/json&#34;</span> --request POST --data <span class="s1">&#39;{&#34;apiVersion&#34;:&#34;v1&#34;, &#34;kind&#34;:&#34;Binding ....&#34;}&#39;</span> http://<span class="nv">$SERVER</span>/api/vi/namespaces/default/pods/<span class="nv">$PODNAME</span>/binding/
</span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">cat nginx.yaml
</span></span><span class="line"><span class="cl">k create -f nginx.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="067-resource-requirements-and-limits">067. Resource Requirements and Limits</h3>
<p>(æœ‰äº›è·Ÿ CKAD é‡ç–Š ç•¥éä¸ç´€éŒ„)</p>
<p>CPU the best practice: With requests but no limits</p>
<h4 id="limitrange">LimitRange</h4>
<p>Note that these limits are enforced when a pod is created. So if you create or change a limit range, it does not affect existing pods. It&rsquo;ll only affect newer pods that are created after the limit range is created or updated.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">LimitRange</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cpu-resource-constraint</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">limits</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">default</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">500m</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">defaultRequest</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">500m</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">max</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">min</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="l">100m</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">type</span><span class="p">:</span><span class="w"> </span><span class="l">Container</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="resource-quotas">Resource Quotas</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">ResourceQuota</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-resource-quota</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">hard</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">requests.cpu</span><span class="p">:</span><span class="w"> </span><span class="m">4</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">requests.memory</span><span class="p">:</span><span class="w"> </span><span class="l">4Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">limits.cpu</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">limits.memory</span><span class="p">:</span><span class="w"> </span><span class="l">10Gi</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>Both <code>LimitRange</code> and <code>ResourceQuota</code> are objects used to control resources usage by a Kubernetes cluster administrator. éƒ½æ˜¯é€éç®¡ç†è€…è§’è‰²æ§åˆ¶è³‡æºä½¿ç”¨é‡</p>
<p><code>ResourceQuota</code> : limit the total consumption of a namespace</p>
<p><code>LimitRange</code> : manage constraints at a pod and container level within the project</p>
<p>Credit to: <a href="https://stackoverflow.com/questions/54929714/in-kubernetes-what-is-the-difference-between-resourcequota-vs-limitrange-object#:~:text=LimitRange%20is%20for%20managing%20constraints,container%20level%20within%20the%20project.&amp;text=An%20individual%20Pod%20or%20Container,namespace%2Fproject%27s%20objects%20in%20aggregate." target="_blank" rel="noopener noreffer ">P Ackerman at Stack overflow</a></p>
</blockquote>
<h3 id="071-daemonsets">071. DaemonSets</h3>
<p>Daemon sets are like replica sets, as in it helps you deploy multiple instances of pods, but it runs one copy of your pod on each node in your cluster. Whenever a new node is added to the cluster, a replica of the pod is automatically added to that node. And when a node is removed, the pod is automatically removed. The daemon set ensures that one copy of the pod is always present in all nodes in the cluster.</p>
<p>What are some use cases of DaemonSets? Say you would like to deploy a monitoring agent or log collector on each of your nodes in the cluster, so you can monitor your cluster better. A DaemonSet is perfect for that, as it can deploy your monitoring agent in the form of a pod in all the nodes in your cluster. Then you don&rsquo;t have to worry about adding or removing monitoring agents form these nodes when there are changes in your cluster, as the DaemonSet will take care of that for you.</p>
<p>Earlier, while discussing the Kubernetes architecture, we learned that one of the worker node components that is required on every node in the cluster is a <strong>kube-proxy</strong>. That is one good used case of DaemonSets. The kube-proxy component can be deployed as a DaemonSet in the cluster.</p>
<p>Another use case is for networking. Networking solutions like V*net requires an agent to be deployed on each node in the cluster. We will discuss about networking concepts in much more detail later during this course.</p>
<h4 id="daemonset-definition">DaemonSet Definition</h4>
<p>Creating a daemon set is similar to the replica set creation process. It has nested pod specification under the template section and selectors to link the DaemonSet to the pods. A DaemonSet definition file has a similar structure.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">apps/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">DaemonSet</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">monitoring-daemon</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">selector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">monitoring-agent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">template</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">app</span><span class="p">:</span><span class="w"> </span><span class="l">monitoring-agent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">monitoring-agent</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">monitoring-agent</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="074-static-pods">074. Static Pods</h3>
<p>Can a kubelet work as an independent node without the help of master node? If so, who would provide the instruction required? How to provide the pod definition file to the kubelet without a kube-api-server? You can configure the kubelet to read the pod definition file from a directory on the server designated to store information about the pod. Place the file under directory <code>/etc/kubernetes/manifests</code>, and kubelet will periodically check this directory for files, read these files and create pods on the host. Kubelet can creat the pod and ensure that the pod is alive. If the application crashes, the kubelet will attempt to restart it. Kubelet also update or delete pod according to changes to the files.</p>
<p>The location of this directory (e.g. <code>/etc/kubernetes/manifests</code>) is passed into the kubelet as an option while running the service. The option is name <code>pod-manifest-path</code>.</p>
<pre tabindex="0"><code>ExecStart=/usr/local/bin/kubelet \\
  --container-runtime=remote \\
  --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\
  --pod-manifest-path=/etc/Kubernetes/manifests \\
</code></pre><p>Apart from specifying the option directly in the <em>kubelet.service</em> file, you could provide a path to another config file.</p>
<pre tabindex="0"><code>ExecStart=/usr/local/bin/kubelet \\
  --container-runtime=remote \\
  --container-runtime-endpoint=unix:///var/run/containerd/containerd.sock \\
  --config=kubeconfig.yaml 
...
</code></pre><p>You can define the directory path as staticPodPath in that file, see below:</p>
<h5 id="kubeconfigyaml">kubeconfig.yaml</h5>
<pre tabindex="0"><code>staticPodPath: /etc/kubernetes/manifests
</code></pre><h4 id="static-pods-vs-daemon-sets">Static Pods v.s. Daemon Sets</h4>
<p>Daemonsets are used to ensure one instance of an application is available on all nodes in the cluster. It is handled by a DaemonSet controller through the kube-apiserver, whereas static pods, as we saw here, are created directly by the kubelet without any interference from the kube-apiserver or rest of the Kubernetes control plane components. Static pods can be used to deploy the Kubernetes controlplane components itself. Both static pods and pods created by Daemon sets are ignored by the kube-scheduler. The kube-scheduler has no effect on these pods.</p>
<table>
<thead>
<tr>
<th>Static pods</th>
<th>Daemon sets</th>
</tr>
</thead>
<tbody>
<tr>
<td>Created by the kubelet</td>
<td>Created by kube-apiserver (Daemonset controller)</td>
</tr>
<tr>
<td>Deploy controlplane components as static pods</td>
<td>Deploy monitoring agents, logging agents on nodes</td>
</tr>
<tr>
<td>Ignored by kube-scheduler</td>
<td>Ignored by kube-scheduler</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get po -A
</span></span><span class="line"><span class="cl">k get po kube-apiserver-controlplane -n kube-system
</span></span><span class="line"><span class="cl">k get po kube-apiserver-controlplane -n kube-system -oyaml <span class="p">|</span> grep -i ownerReferences
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="077-multiple-schedulers">077. Multiple schedulers</h3>
<p>Kube-scheduler has an algorithm that distributes pods across nodes evenly, as well as takes into consideration various conditions we specified through taints and tolerations and node affinity, etc. What if none of these satisfies your needs? Say you have a specific application that requires its components to be placed on nodes after performing some additional checks?</p>
<p>You decided to have your own scheduling algorithm to place pods on nodes, so that you can add your own custom conditions and checks in it. Kubernetes is highly extensible, you can write your own k8s scheduler program, package it and deploy it as the default scheduler or as an additional scheduler in K8s cluster. That way all of the other apps can go through the default scheduler. However, some specific applications that you may choose can use your own custom scheduler. Your kubernetes cluster can have multiple schedulers at a time.</p>
<p>When creating a pod or a deployment, you can instruct Kubernetes to have the pod scheduled by a specific scheduler. Let&rsquo;s see how that&rsquo;s done. When there are multiple schedulers, they must have different name, so that we can identify them as separate schedulers. The default scheduler is named default-scheduler. This name is configured in a kube-scheduler configuration file (see below).</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># scheduler-config.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubescheduler.config.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeSchedulerConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">profiles</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">default-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c"># my-scheduler-config.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubescheduler.config.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeSchedulerConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">profiles</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c"># my-scheduler-2-config.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubescheduler.config.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeSchedulerConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">profiles</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler-2</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h5 id="kube-schedulerservice">Kube-scheduler.service</h5>
<pre tabindex="0"><code>ExecStart=/usr/local/bin/kube-scheduler \\
  --config=/etc/kubernetes/config/kube-scheduler.yaml
</code></pre><h4 id="deploy-additional-scheduler-as-a-pod">Deploy Additional Scheduler as a Pod</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="c"># my-custom-scheduler.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-custom-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">kube-system</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">kube-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- --<span class="l">address=127.0.0.1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- --<span class="l">kubeconfig=/etc/kubernetes/scheduler.conf</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">k8s.gcr.io/kube-scheduler-amd63:v1.11.3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kube-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="c"># my-scheduler-config.yaml</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubescheduler.config.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeSchedulerConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">profiles</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">leaderElection</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">leaderElect</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">resourceNamespace</span><span class="p">:</span><span class="w"> </span><span class="l">kube-system</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">resourceName</span><span class="p">:</span><span class="w"> </span><span class="l">lock-object-my-scheduler</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>The leaderElection option is used when you have multiple copies of the scheduler running on different master nodes as a high-availability setup, where you have multiple master nodes with the K8s scheduler process running on both of them.</p>
<p>If multiple copies of the same scheduler are running on different nodes, only one can be active at a time, and that&rsquo;s where the leader elect option helps in choosing a leader who will lead the scheduling activities.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># kube-scheduler.service</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/usr/local/bin/kube-scheduler <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --config<span class="o">=</span>/etc/kubernetes/config/kube-scheduler.yaml
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># my-scheduler-2.service</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/usr/local/bin/kube-scheduler <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --config<span class="o">=</span>/etc/kubernetes/config/my-scheduler-2-config.yaml
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># my-scheduler.service</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/usr/local/bin/kube-scheduler <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --config<span class="o">=</span>/etc/kubernetes/config/my-scheduler-config.yaml
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="c1"># my-scheduler-2-config.yaml</span>
</span></span><span class="line"><span class="cl">apiVersion: kubescheduler.config.k8s.io/v1
</span></span><span class="line"><span class="cl">kind: KubeSchedulerConfiguration
</span></span><span class="line"><span class="cl">profiles:
</span></span><span class="line"><span class="cl">- schedulerName: my-scheduler-2
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># my-scheduler-config.yaml</span>
</span></span><span class="line"><span class="cl">apiVersion: kubescheduler.config.k8s.io/v1
</span></span><span class="line"><span class="cl">kind: KubeSchedulerConfiguration
</span></span><span class="line"><span class="cl">profiles:
</span></span><span class="line"><span class="cl">- schedulerName: my-scheduler
</span></span></code></pre></td></tr></table>
</div>
</div><p><a href="https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/" target="_blank" rel="noopener noreffer ">Configure Multiple Schedulers</a></p>
<h4 id="view-events">View Events</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get events -o wide
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="view-scheduler-logs">View Scheduler Logs</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl logs my-custom-scheduler --name-space<span class="o">=</span>kube-system
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="080-configuring-scheduler-profiles">080. Configuring Scheduler Profiles</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">simple-web-color</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">priorityClassName</span><span class="p">:</span><span class="w"> </span><span class="l">high-priority </span><span class="w"> </span><span class="c"># ğŸ</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">simple-webapp-color</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">simple-webapp-cluster</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">memory</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;1Gi&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">cpu</span><span class="p">:</span><span class="w"> </span><span class="m">10</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">scheduling.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PriorityClass</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">high-priority </span><span class="w"> </span><span class="c"># ğŸ</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="m">1000000</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">globalDefault</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">description</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;This priority class should be used for XYZ service pods only.&#34;</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="scheduling-plugin-and-extension-points">Scheduling Plugin and Extension Points</h4>
<ul>
<li>[<strong>Stage 1</strong>] Scheduling Queue <code>queueSort</code>
<ul>
<li>PrioritySort</li>
</ul>
</li>
<li>[<strong>Stage 2</strong>] Filtering <code>preFilter</code>,<code>filter</code>, <code>postFilter</code>
<ul>
<li>NodeResourcesFit</li>
<li>NodeName</li>
<li>NodeUnschedulable</li>
<li>TaintToleration</li>
<li>NodePorts</li>
<li>NoteAffinity</li>
</ul>
</li>
<li>[<strong>Stage 3</strong>] Scoring <code>preScore</code>, <code>score</code>, <code>reserve</code>
<ul>
<li>NodeResourcesFit</li>
<li>ImageLocality</li>
</ul>
</li>
<li>[<strong>Stage 4</strong>] Binding <code>permit</code>, <code>preBind</code>, <code>bind</code>, <code>postBind</code>
<ul>
<li>DefaultBinder</li>
</ul>
</li>
</ul>
<h4 id="add-multiple-profiles-within-a-single-scheduler">Add multiple profiles within a single scheduler</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">kubescheduler.config.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">KubeSchedulerConfiguration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">profiles</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler-2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">plugins</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">score</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">disabled</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">TaintToleration</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">enabled</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyCustomPluginA</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">MyCustomPluginB</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler-3</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">plugins</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">preScore</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">disabled</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;*&#39;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">score</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">disabled</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;*&#39;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">schedulerName</span><span class="p">:</span><span class="w"> </span><span class="l">my-scheduler-4</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  
</span></span></span></code></pre></td></tr></table>
</div>
</div><p><a href="https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/" target="_blank" rel="noopener noreffer ">Scheduling Framework</a></p>
<p><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-scheduling/scheduling_code_hierarchy_overview.md" target="_blank" rel="noopener noreffer ">Scheduler code hierarchy overview</a></p>
<p><a href="https://jvns.ca/blog/2017/07/27/how-does-the-kubernetes-scheduler-work/" target="_blank" rel="noopener noreffer ">How des the Kubernetes scheduler work by Julia Evans</a></p>
<h2 id="logging--monitoring">Logging &amp; Monitoring</h2>
<h3 id="084-monitor-cluster-components">084. Monitor Cluster Components</h3>
<p>Open source monitoring solutions such as Metrics Server, Prometheus, Elastic Stack, DataDog, Dynatrace.</p>
<p>Heapster is now deprecated and slimed down to Metrics Server. It&rsquo;s only in-memory though.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get po
</span></span><span class="line"><span class="cl">git clone https://github.com/kodekloudhub/kubernetes-metrics-server.git
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> kubernetes-metrics-server/
</span></span><span class="line"><span class="cl">k create -f .
</span></span><span class="line"><span class="cl">k top node
</span></span><span class="line"><span class="cl">k top pod
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="096-application-commands">096. Application commands</h3>
<p>docker run ubuntu-sleeper <code>sleep 10</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-Dockerfile" data-lang="Dockerfile"><span class="line"><span class="cl"><span class="k">FROM</span><span class="s"> Ubuntu</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">CMD</span> sleep <span class="m">5</span> <span class="c1"># will be replaced by `sleep 10`</span><span class="err">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>docker run ubuntu-sleeper <code>10</code></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="line"><span class="cl"><span class="k">FROM</span><span class="s"> Ubuntu</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">ENTRYPOINT</span> <span class="p">[</span><span class="s2">&#34;sleep&#34;</span><span class="p">]</span><span class="err">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>Combine entrypoint and default argument</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-dockerfile" data-lang="dockerfile"><span class="line"><span class="cl"><span class="k">FROM</span><span class="s"> Ubuntu</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">ENTRYPOINT</span> <span class="p">[</span><span class="s2">&#34;sleep&#34;</span><span class="p">]</span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="k">CMD</span> <span class="p">[</span><span class="s2">&#34;5&#34;</span><span class="p">]</span><span class="err">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="note-kubectl-run-å¸¶-command-arg-æœ‰æ²’æœ‰---command-å·®åœ¨å“ª-">Note: kubectl run å¸¶ command arg æœ‰æ²’æœ‰ <code>--command</code> å·®åœ¨å“ª ?</h4>
<p>æœ‰ <code>--command</code> çš„è©±ï¼Œ<code>--</code> å¾Œé¢æ¥çš„ç¬¬ä¸€å€‹å°±æ˜¯ commandï¼Œæ²’æœ‰çš„è©±å°±åªæ˜¯ args</p>
<pre tabindex="0"><code># Start the nginx pod using the default command, but use custom arguments (arg1 ... argN) for that command
kubectl run nginx --image=nginx -- &lt;arg1&gt; &lt;arg2&gt; ... &lt;argN&gt;

# Start the nginx pod using a different command and custom arguments
kubectl run nginx --image=nginx --command -- &lt;cmd&gt; &lt;arg1&gt; ... &lt;argN&gt;
</code></pre><h4 id="note-ç‚ºå•¥æœ‰æ™‚å€™-pod-container-command-è¦å‰ç¶´-sh--c-æˆ–è€…-binsh--cæœ‰æ™‚å€™ç›´æ¥æ”¾-executable-å°±å¯ä»¥">Note: ç‚ºå•¥æœ‰æ™‚å€™ pod container command è¦å‰ç¶´ <code>sh</code>, <code>-c</code> æˆ–è€… <code>/bin/sh</code>, <code>-c</code>ï¼Œæœ‰æ™‚å€™ç›´æ¥æ”¾ executable å°±å¯ä»¥ï¼Ÿ</h4>
<pre tabindex="0"><code>
The reason some containers need to specify [&#39;sh&#39;, &#39;-c&#39;] or [&#39;/bin/sh&#39;, &#39;-c&#39;] before executing commands like ls, cat, or sleep, whereas others, such as Ubuntu containers, do not, boils down to how the default shell and entry point is configured in different container images.

1. BusyBox or Alpine-based containers: These lightweight containers often have minimal setups, where the command-line interpreter (shell) may not be directly available when you run the container or execute commands within the container. As a result, you need to explicitly invoke a shell, such as /bin/sh with -c to interpret the commands. This allows the shell to process the command string that follows (ls, cat, sleep, etc.).

   * sh -c means &#34;run the following command in a new shell&#34;.
   * Example: [&#39;sh&#39;, &#39;-c&#39;, &#39;ls&#39;] tells the container to first start a shell (sh), and then execute the ls command within that shell.
    
2. Ubuntu-based containers: In contrast, Ubuntu containers typically have a more complete shell environment installed (bash or sh) and are often configured to start with the shell by default when a command is executed. This means you can directly run commands like ls or sleep without needing to explicitly invoke the shell (sh or bash). The shell is already assumed to be the entry point for interpreting commands in these images.

    * Example: In Ubuntu containers, you can simply run ls without prepending sh -c because the shell will automatically process the command.
    
To summarize, the difference arises due to how the container&#39;s base image is configured. Minimal images like BusyBox or Alpine may require an explicit shell invocation, while fuller images like Ubuntu have more complex shells like bash pre-configured to handle command interpretation directly.
</code></pre><h2 id="-cluster-maintenance">ãˆ¥ Cluster Maintenance</h2>
<h3 id="122-os-upgrades">122. OS upgrades</h3>
<p>If a node was down and then came back online immediately, then the kubelet process starts and the pods come back online. However, if the node was down for more than five minutes, then the pods are terminated from that node and Kubernetes considers them as dead. If pods are part of your replicasets, then they are recreated on other nodes. The time it waits for a pod to come back online is known as the <strong>pod-eviction-timeout</strong> and is set on the controller-manager with a default value of 5 minutes.</p>
<p>When a node comes back online after five minutes, it comes up blank without any pod scheduled on it.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># evict pods from node01</span>
</span></span><span class="line"><span class="cl">kubectl drain node01 
</span></span><span class="line"><span class="cl">kubectl drain node01 --ignore-daemonsets
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># make the node02 unschedulable</span>
</span></span><span class="line"><span class="cl">kubectl cordon node02
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># make the node01 schedulable</span>
</span></span><span class="line"><span class="cl">kubectl uncordon node01
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="125-k8s-software-versions">125. K8s Software versions</h3>
<table>
<thead>
<tr>
<th>major</th>
<th>minor</th>
<th>patch</th>
</tr>
</thead>
<tbody>
<tr>
<td>v1.</td>
<td>31.</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>alpha release, beta release, main stable release.</p>
<p>Kube-apiserver, controller-manager, kube-scheduler, kubelet, kube-proxy, kubectl - these share the same release version.</p>
<p><code>ETCD CLUSTER</code>, <code>CoreDNS</code> - these have their own versions (they are separate projects).</p>
<h4 id="references">References</h4>
<ul>
<li>
<p><a href="https://kubernetes.io/docs/concepts/overview/kubernetes-api/" target="_blank" rel="noopener noreffer ">Kubernetes API overview</a></p>
</li>
<li>
<p><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md" target="_blank" rel="noopener noreffer ">API-conventions</a></p>
</li>
<li>
<p><a href="https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api_changes.md" target="_blank" rel="noopener noreffer ">Changing the API</a></p>
</li>
</ul>
<h3 id="127-cluster-upgrade-process">127. Cluster upgrade process</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl describe node <span class="p">|</span> grep Taints
</span></span><span class="line"><span class="cl">kubectl get po -o wide
</span></span><span class="line"><span class="cl">kubeadm upgrade plan
</span></span><span class="line"><span class="cl">kubectl drain controlplane --ignore-daemonsets
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl"><span class="c1"># determine which version to upgrade to</span>
</span></span><span class="line"><span class="cl">cat /etc/*release*
</span></span><span class="line"><span class="cl"><span class="c1"># update the kubeadm tool--Ubuntu way</span>
</span></span><span class="line"><span class="cl">apt update
</span></span><span class="line"><span class="cl">apt-cache madison kubeadm
</span></span><span class="line"><span class="cl">apt-get --version
</span></span><span class="line"><span class="cl"><span class="c1"># since apt-get version 1.1, you can upgrade kubeadm with below command:</span>
</span></span><span class="line"><span class="cl">apt-mark unhold kubeadm <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>apt-get install -y --allow-change-held-packages kubeadm-1.20.0-00
</span></span><span class="line"><span class="cl"><span class="c1"># upgrade the master components</span>
</span></span><span class="line"><span class="cl">kubeadm upgrade plan
</span></span><span class="line"><span class="cl">sudo kubeadm upgrade apply v1.20.0 
</span></span><span class="line"><span class="cl"><span class="c1"># press y to proceed to the upgrade</span>
</span></span><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">k uncordon controlplane
</span></span><span class="line"><span class="cl"><span class="c1"># upgrade the kubelets</span>
</span></span><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">k drain node01 --ignore-daemonsets
</span></span><span class="line"><span class="cl">k get po -o wide
</span></span><span class="line"><span class="cl">ssh node01 
</span></span><span class="line"><span class="cl">ssh &lt;internal-ip-of-node01&gt;
</span></span><span class="line"><span class="cl"><span class="c1"># upgrade the kubeadm tool of node01</span>
</span></span><span class="line"><span class="cl">apt-mark unhold kubeadm <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>apt-get install -y --allow-change-held-packages kubeadm-1.20.0-00
</span></span><span class="line"><span class="cl">sudo kubeadm upgrade node
</span></span><span class="line"><span class="cl">apt-get update <span class="o">&amp;&amp;</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>apt-get install -y --allow-change-held-packages <span class="nv">kubelet</span><span class="o">=</span>1.20.0-00 <span class="nv">kubectl</span><span class="o">=</span>1.20.0-00
</span></span><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span><span class="line"><span class="cl">sudo systemctl restart kubelet
</span></span><span class="line"><span class="cl">kubectl uncordon node01
</span></span><span class="line"><span class="cl">kubectl get nodes <span class="c1"># Best to redo 129 practice test</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="131-backup-and-restore-methods">131. Backup and Restore Methods</h3>
<p>Query the kube-apiserver to get resource configuration and save all resource configurations for all objects created on the cluster.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get all --all-namespaces -o yaml &gt; all-deploy-services.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><p>There are tools like Ark, or now called Velcro, by HeptIO, that can help in taking backups of your Kubernetes cluster, using the Kubernetes API.</p>
<h4 id="backup---etcd">Backup - ETCD</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># etcd.service</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/usr/local/bin/etcd <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --name <span class="si">${</span><span class="nv">ETCD_NAME</span><span class="si">}</span> <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --cert-file<span class="o">=</span>/etc/etcd/kubernees.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --key-file<span class="o">=</span>/etc/etcd/kubernetes-key.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --peer-cert-file<span class="o">=</span>/etc/etcd/kubernetes.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --peer-key-file<span class="o">=</span>/etc/etcd/kubernetes-key.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --trusted-ca-file<span class="o">=</span>/etc/etcd/ca.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --peer-trusted-ca-file<span class="o">=</span>/etc/etcd/ca.pem <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --peer-client-cert-auth <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --client-cert-auth <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --initial-advertise-peer-urls https://<span class="si">${</span><span class="nv">INTERNAL_IP</span><span class="si">}</span>:...
</span></span><span class="line"><span class="cl">  --listen-peer-urls https://<span class="si">${</span><span class="nv">INTERNAL_IP</span><span class="si">}</span>:2380 <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --listen-client-urls https://<span class="si">${</span><span class="nv">INTERNAL_IP</span><span class="si">}</span>:2379,http...
</span></span><span class="line"><span class="cl">  --advertise-client-urls https://<span class="si">${</span><span class="nv">INTERNAL_IP</span><span class="si">}</span>:2379 <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --initial-cluster--token etcd-cluster-0 <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --initial-cluster controller-0<span class="o">=</span>https://<span class="si">${</span><span class="nv">CONTROLLER0_</span><span class="si">}</span>...
</span></span><span class="line"><span class="cl">  --initial-cluster-state new <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  --data-dir<span class="o">=</span>/var/lib/etcd <span class="c1"># this is where all the data will be stored</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>ETCD also comes with a built-in snapshot solution.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    snapshot save snapshot.db
</span></span><span class="line"><span class="cl">ls
</span></span><span class="line"><span class="cl">snapshot.db
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># view the status of the backup</span>
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    snapshot status snapshot.db
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="restore---etcd">Restore - ETCD</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">service kube-apiserver stop
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    snapshot restore snapshot.db <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    --data-dir /var/lib/etcd-from-backup
</span></span><span class="line"><span class="cl">    <span class="c1"># the path of the snapshot.db backup file</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1"># configure the etcd configuration file to use the new data directory</span>
</span></span><span class="line"><span class="cl"><span class="nv">ExecStart</span><span class="o">=</span>/usr/local/bin/etcd <span class="se">\\</span>
</span></span><span class="line"><span class="cl">  ......
</span></span><span class="line"><span class="cl">  --data-dir<span class="o">=</span>/var/lib/etcd-from-backup
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl">  systemctl daemon-reload
</span></span><span class="line"><span class="cl">  service etcd restart
</span></span><span class="line"><span class="cl">  service kube-apiserver start
</span></span></code></pre></td></tr></table>
</div>
</div><p>With all the etcdctl commands, remember to specify the certificate files for authentication:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  snapshot save snapshot.db <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --endpoints<span class="o">=</span>https://127.0.0.1:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cacert<span class="o">=</span>/etc/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cert<span class="o">=</span>/etc/etcd/etcdï¼server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --key<span class="o">=</span>/etc/etcd/etcd-server.key
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="backup-and-restore-1">Backup and Restore 1</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get deploy
</span></span><span class="line"><span class="cl">k get pod -n kube-system
</span></span><span class="line"><span class="cl">k describe po etcd-controlplane -n kube-system
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/manifests/
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests/etcd.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># Note the hostPath &#39;/etc/kubernetes/pki/etcd&#39; on the host or controlplane is mounted to the particular path within the container.</span>
</span></span><span class="line"><span class="cl">ls /var/lib/etcd
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/pki/etcd
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl snapshot
</span></span><span class="line"><span class="cl">etcdctl snapshot save --endpoints<span class="o">=</span>&lt;refer-to-listen-client-urls&gt;
</span></span><span class="line"><span class="cl">kubectl logs -n kube-system etcd-controlplane
</span></span><span class="line"><span class="cl"><span class="c1"># Task 6 (take a snapshot of the ETCD db using built-in snapshot functionality)</span>
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=[</span>127.0.0.1<span class="o">]</span>:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cacert<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cert<span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--key<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>snapshot save /opt/snapshot-pre-boot.db
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl  --data-dir /var/lib/etcd-from-backup <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>snapshot restore /opt/snapshot-pre-boot.db
</span></span><span class="line"><span class="cl"><span class="c1"># Task 9 is so confusing ... DNF</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="backup-and-restore-2">Backup and Restore 2</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get node
</span></span><span class="line"><span class="cl">kubectl config view
</span></span><span class="line"><span class="cl">kubectl config use-context cluster1
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl">kubectl config use-context cluster2
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /etc/kubernetes/manifests/
</span></span><span class="line"><span class="cl">ls
</span></span><span class="line"><span class="cl">kubectl get pods -n kube-system
</span></span><span class="line"><span class="cl">kubectl describe kube-apiserver-cluster2-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">ssh etcd-server
</span></span><span class="line"><span class="cl">ps -ef <span class="p">|</span> grep -i etcd 
</span></span><span class="line"><span class="cl"><span class="c1"># -e for displaying info about all processes on the system, not just those belonging to the current user</span>
</span></span><span class="line"><span class="cl"><span class="c1"># -f for showing a full-format listing which includes more detailed info like the user who owns the process, the process ID (PID), the parent process ID (PPID), start time, terminal, CPU usage and the command taht started the process</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">etcdctl member list
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span>https://127.0.0.1:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cacert<span class="o">=</span>/etc/etcd/pki/ca.pem <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cert<span class="o">=</span>/etc/etcd/pki/etcd.pem <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--key<span class="o">=</span>/etc/etcd/pki/etcd-key.pem member list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl config use-context cluster1
</span></span><span class="line"><span class="cl">kubectl get pod -n kube-system
</span></span><span class="line"><span class="cl">kubectl describe pod etcd-cluster1-controlplane -n kube-system
</span></span><span class="line"><span class="cl">kubectl get pod -n kube-system
</span></span><span class="line"><span class="cl">kubectl describe pod etcd-cluster1-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span>&lt;advertise-client-urls&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cacert<span class="o">=</span>&lt;trusted-ca-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cert<span class="o">=</span>&lt;cert-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --key<span class="o">=</span>&lt;key-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  snapshot save /opt/cluster1.db
</span></span><span class="line"><span class="cl"><span class="c1"># Task 14 tricky: ETCDCTL_API=3 etcdctl --endpoints=https://192.160.244.10:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --cert=/etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key snapshot save /opt/cluster1.db</span>
</span></span><span class="line"><span class="cl">scp cluster1-controlplane:/opt/cluster1.db /opt/
</span></span><span class="line"><span class="cl">ls /opt/
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl snapshot restore /root/cluster2.db --data-dir /var/lib/etcd-data-new
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /var/lib/
</span></span><span class="line"><span class="cl">ls -la
</span></span><span class="line"><span class="cl">chown -R etcd:etcd etcd-data-new/
</span></span><span class="line"><span class="cl">ls -la
</span></span><span class="line"><span class="cl">vi /etc/systemd/system/etcd.service
</span></span><span class="line"><span class="cl"><span class="c1"># change the --data-dir </span>
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart etcd
</span></span><span class="line"><span class="cl">systemctl status etcd
</span></span><span class="line"><span class="cl">kubectl delete pods kube-controller-manager-cluster2-controlplane kube-scheduler-cluster2-controlplane -n kube-system
</span></span><span class="line"><span class="cl">kubectl get pods -n kube-system
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl">systemctl restart kubelet
</span></span><span class="line"><span class="cl">systemctl status kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="134-back-up-and-restore-1">134. Back up and restore (1)</h3>
<p>Reference: <a href="https://github.com/mmumshad/kubernetes-the-hard-way/blob/feature/1.28-refresh/practice-questions-answers/cluster-maintenance/backup-etcd/etcd-backup-and-restore.md" target="_blank" rel="noopener noreffer ">back up etcd - kubernetes the hard way</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k -n kube-system logs etcd-controlplane <span class="p">|</span> grep -i version
</span></span><span class="line"><span class="cl">k -n kube-system describe po etcd-controlplane <span class="p">|</span> grep -i image
</span></span><span class="line"><span class="cl"><span class="c1"># Q3 check on which &lt;ip&gt;:&lt;port&gt; is this etcd reachable at</span>
</span></span><span class="line"><span class="cl">k -n kube-system describe po etcd-controlplane <span class="p">|</span> grep -i <span class="s1">&#39;\--listen-client-urls&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q4 the ETCD server certificate file</span>
</span></span><span class="line"><span class="cl">k -n kube-system describe po etcd-controlplane <span class="p">|</span> grep -i <span class="s1">&#39;\----cert-file&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q5 the ETCD CA certificate file</span>
</span></span><span class="line"><span class="cl">k -n kube-system describe po etcd-controlplane <span class="p">|</span> grep -i <span class="s1">&#39;\--peer-trusted-ca-file&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q6 take a snapshot of the ETCD DB using the built-in snapshot functionality, store the backup file at location /opt/snapshot-pre-boot.db</span>
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span>https://<span class="o">[</span>127.0.0.1<span class="o">]</span>:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cacert<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cert<span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--key<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>snapshot save /opt/snapshot-pre-boot.db
</span></span><span class="line"><span class="cl"><span class="c1"># Q9 restore the ETCD backup (at the same controlplane node server)</span>
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --data-dir /var/lib/etcd-from-backup <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>snapshot restore /opt/snapshot-pre-boot.db
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests.etcd.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># change the volumes.hostpath.name(etcd-data)</span>
</span></span><span class="line"><span class="cl">  - hostPath:
</span></span><span class="line"><span class="cl">      path: /var/lib/etcd-from-backup <span class="c1"># here</span>
</span></span><span class="line"><span class="cl">      type: DirectoryOrCreate
</span></span><span class="line"><span class="cl">    name: etcd-data
</span></span><span class="line"><span class="cl"><span class="c1"># also update the --data-dir argument</span>
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  containers:
</span></span><span class="line"><span class="cl">  - command:
</span></span><span class="line"><span class="cl">    - etcd
</span></span><span class="line"><span class="cl">    - ......
</span></span><span class="line"><span class="cl">    - --data-dir<span class="o">=</span>/var/lib/etcd-from-backup
</span></span><span class="line"><span class="cl"><span class="c1"># run crictl command to watch for etcd</span>
</span></span><span class="line"><span class="cl">crictl ps <span class="p">|</span> grep etcd
</span></span><span class="line"><span class="cl">watch <span class="s2">&#34;crictl ps | grep etcd&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="136-back-up-and-restore-2">136. Back up and restore (2)</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get no
</span></span><span class="line"><span class="cl">k config view
</span></span><span class="line"><span class="cl">k config use-context cluster1
</span></span><span class="line"><span class="cl">k get no
</span></span><span class="line"><span class="cl">k config use-context cluster2
</span></span><span class="line"><span class="cl">k get no
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl">k config use-context cluster2
</span></span><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl">k config use-context cluster1
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k describe po kube-apiserver-cluster1-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1"># check for --etcd-servers=&lt;url&gt;</span>
</span></span><span class="line"><span class="cl">k config use-context cluster2
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k get no
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /etc/kubernetes/manifests/
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k describe po kube-apiserver-cluster2-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1"># --etcd-servers is pointing to a separate IP address, meaning that it&#39;s an external etcd server that we used</span>
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># At student node</span>
</span></span><span class="line"><span class="cl">ps -ef <span class="p">|</span> grep -i etcd
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k describe po etcd-cluster1-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1"># check --data-dir for default data directory used for ETCD</span>
</span></span><span class="line"><span class="cl">ssh etcd-server
</span></span><span class="line"><span class="cl"><span class="c1"># At etcd-server </span>
</span></span><span class="line"><span class="cl">ps -ef <span class="p">|</span> grep -i etcd
</span></span><span class="line"><span class="cl">etcdctl member list
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span>&lt;listen-client-urls&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cacert<span class="o">=</span>&lt;tusted-ca-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cert<span class="o">=</span>&lt;cert-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --key<span class="o">=</span>&lt;key-file&gt; <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  member list
</span></span><span class="line"><span class="cl"><span class="c1"># take etcd back up on cluster1 and save it on the student-node</span>
</span></span><span class="line"><span class="cl"><span class="c1"># At student node</span>
</span></span><span class="line"><span class="cl">k config use-context cluster1
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k describe po etcd-cluster1-controlplane -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1">#  advertise-client-urls	https://192.33.162.8:2379</span>
</span></span><span class="line"><span class="cl"><span class="c1">#  trusted-ca-file				/etc/kubernetes/pki/etcd/ca.crt</span>
</span></span><span class="line"><span class="cl"><span class="c1">#  cert-file							/etc/kubernetes/pki/etcd/server.crt</span>
</span></span><span class="line"><span class="cl"><span class="c1">#  key-file								/etc/kubernetes/pki/etcd/server.key</span>
</span></span><span class="line"><span class="cl">k get node
</span></span><span class="line"><span class="cl">ssh cluster1-controlplane
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl --endpoints<span class="o">=</span>ttps://192.33.162.8:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cacert<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --cert<span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --key<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  snapshot save /opt/cluster1.db
</span></span><span class="line"><span class="cl">ls /opt/
</span></span><span class="line"><span class="cl">cluster1.db
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># At student node</span>
</span></span><span class="line"><span class="cl">scp cluster1-controlplane:/opt/cluster1.db /opt/
</span></span><span class="line"><span class="cl">ls /opt/
</span></span><span class="line"><span class="cl">scp /opt/cluster2.db etcd-server:/root 
</span></span><span class="line"><span class="cl"><span class="c1"># Switch to another terminal, at etcd-server node</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q15 snapshot restore</span>
</span></span><span class="line"><span class="cl"><span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span> etcdctl snapshot restore /root/cluster2.db <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --data-dir /var/lib/etcd-data-new 
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /var/lib/
</span></span><span class="line"><span class="cl">ls -la
</span></span><span class="line"><span class="cl"><span class="c1"># change the root user as the ownership to the ETCD user as the ownership</span>
</span></span><span class="line"><span class="cl">chown -R etcd:etcd etcd-data-new/
</span></span><span class="line"><span class="cl">vi /etc/systemd/system/etcd.service
</span></span><span class="line"><span class="cl"><span class="c1"># change the --data-dir from /var/lib/etcd-data to be /var/lib/etcd-data-new</span>
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart etcd
</span></span><span class="line"><span class="cl">systemctl status etcd
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># At student node</span>
</span></span><span class="line"><span class="cl">k get node
</span></span><span class="line"><span class="cl">k config use-context cluster2
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k delete po kube-controller-manager-cluster2-controlplane kube-scheduler-cluster2-controlplane -n kube-system
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k get no
</span></span><span class="line"><span class="cl">ssh cluster2-controlplane
</span></span><span class="line"><span class="cl">system restart kubelet
</span></span><span class="line"><span class="cl">systemctl status kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="138-references">138. References</h3>
<p><a href="https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/#backing-up-an-etcd-cluster" target="_blank" rel="noopener noreffer ">ETCD cluster back up å‚™ä»½</a></p>
<p><a href="https://github.com/etcd-io/website/blob/main/content/en/docs/v3.5/op-guide/recovery.md" target="_blank" rel="noopener noreffer ">etcd-io / website / disaster recovery</a></p>
<p><a href="https://www.youtube.com/watch?v=qRPNuT080Hk" target="_blank" rel="noopener noreffer ">CNCF / Disaster recovery for your K8s cluster</a></p>
<hr>
<h2 id="-security">ãˆ¦ Security</h2>
<p>TLS certificates</p>
<p>A certificated is used to guarantee trust between two parties during a transaction. For example, when a user tries to access a web server, TLS certificates ensure that the communication between the user then the server is encrypted and the server is who it says it is.</p>
<h4 id="certificate-authority">Certificate Authority</h4>
<ul>
<li>Root certificates</li>
<li>Server certificates</li>
<li>Client certificates</li>
</ul>
<table>
<thead>
<tr>
<th>Certificate (public key)</th>
<th>Private key</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>*.crt</code> <code>*.pem</code></td>
<td><code>*.key</code> <code>*-key.pem</code></td>
</tr>
<tr>
<td>server.crt</td>
<td>server.key</td>
</tr>
<tr>
<td>server.pem</td>
<td>server-key.pem</td>
</tr>
<tr>
<td>client.crt</td>
<td>client.key</td>
</tr>
<tr>
<td>client.pem</td>
<td>client-key.pem</td>
</tr>
</tbody>
</table>
<p>If you were to deploy a K8s cluster from scratch, you generate all the certificates by yourself. Or if you were to rely on an automated provisioning tool like kubeadm, it takes care of automatically generating and configuring the cluster for you.</p>
<p>In an environment set up by kubeadm, look for these parameters in a kube-apiserver yaml file:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">	</span><span class="nt">container</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span><span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">client-ca-file=/etc/kubernetes/pki/ca.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span><span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span><span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">kubectl-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">kubectl-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span><span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">tls-cert-file=/etc/kubernetes/pki/apiserver.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">		</span>- --<span class="l">tls-private-key-file=/etc/kubernetes/pki/apiserver.key</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="151-view-certification-details-">151. View certification details â›‘ï¸â›‘ï¸â›‘ï¸</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">cat /etc/kubernetes/manifests/kube-apiserver.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># look for certificate file used for the kube-api server itself</span>
</span></span><span class="line"><span class="cl">--tls-cert-file<span class="o">=</span>/etc/kubernetes/pki/apiserver.crt
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># the cert file used to authenticate kube-apiserver as a client to etcd-server</span>
</span></span><span class="line"><span class="cl">--etcd-certfile<span class="o">=</span>/etc/kubernetes/pki/apiserver-etcd-client.crt
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># the key used to authenticate kubeapi-server to the kubelet server</span>
</span></span><span class="line"><span class="cl">--kubelet-client-key<span class="o">=</span>/etc/kubernetes/pki/apiserver-kubelet-client.key
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/etcd.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># check the cert, key, ca-file... anything to do w/ the ETCD server itself ï¼ˆfor its hosting) is under the etc/kubernetes/pki/etcd directory. </span>
</span></span><span class="line"><span class="cl"><span class="c1"># the etcd server certificate used to host ETCD server</span>
</span></span><span class="line"><span class="cl">--cert-file<span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt
</span></span><span class="line"><span class="cl">--key-file<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key
</span></span><span class="line"><span class="cl"><span class="c1"># the etcd server CA Root Certificate used to serve etcd server</span>
</span></span><span class="line"><span class="cl">--trust-ca-file<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="the-common-name-configured-on-the-kube-apiserver-certificate">The common name configured on the kube-apiserver certificate</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -nout
</span></span><span class="line"><span class="cl">Certificate:
</span></span><span class="line"><span class="cl">    Data:
</span></span><span class="line"><span class="cl">        Issuer: <span class="nv">CN</span> <span class="o">=</span> kubernetes
</span></span><span class="line"><span class="cl">        Validity
</span></span><span class="line"><span class="cl">            Not Before: Apr <span class="m">17</span> 21:17:20 <span class="m">2022</span> GMT
</span></span><span class="line"><span class="cl">            Not After : Apr <span class="m">17</span> 21:17:20 <span class="m">2023</span> GMT
</span></span><span class="line"><span class="cl">        Subject: <span class="nv">CN</span> <span class="o">=</span> kube-apiserver
</span></span><span class="line"><span class="cl">  ......
</span></span><span class="line"><span class="cl">        X509v3 Subject Alternative Name:
</span></span><span class="line"><span class="cl">            DNS:controlplane, DNS:kubernetes, DNS:kubernetes.default, DNS:kubernetes.default.svc, DNS:kubernetes.default.svc.cluster.local, IP Address:10.96.0.1, IP Address:10.46.98.9
</span></span><span class="line"><span class="cl">   
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="the-common-name-configured-on-the-etcd-server-certificate">The common name configured on the ETCD Server certificate</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">openssl x509 -in /etc/kubernetes/pki/etcd/server.crt -text -nout
</span></span><span class="line"><span class="cl">Certificate:
</span></span><span class="line"><span class="cl">    Data:
</span></span><span class="line"><span class="cl">        ...
</span></span><span class="line"><span class="cl">        Issuer: <span class="nv">CN</span> <span class="o">=</span> etcd-ca
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="valid-duration-of-the-root-ca-certificate">Valid duration of the Root CA certificate</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">openssl x509 -in /etc/kubernetes/pki/ca.crt -text -nout
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="troubleshooting-etcdyaml">Troubleshooting etcd.yaml</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get pods   <span class="c1"># not responding - connection to the server controlplane:6443 was refused</span>
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep kube-apiserver
</span></span><span class="line"><span class="cl"><span class="c1"># check logs of the last created kube-apiserver-controlplane</span>
</span></span><span class="line"><span class="cl">docker logs 843d43ecff24
</span></span><span class="line"><span class="cl"><span class="c1"># ... Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused&#34;. Reconnecting ...</span>
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep etcd
</span></span><span class="line"><span class="cl"><span class="c1"># check logs of the last created k8s_etcd_etcd-controlplane</span>
</span></span><span class="line"><span class="cl">docker logs 4fc9986a2a24
</span></span><span class="line"><span class="cl">crictl logs 4fc9986a2a24
</span></span><span class="line"><span class="cl"><span class="c1"># etcdmain: open /etc/kubernetes/pki/etcd/server-certificate.crt: no such file or directory</span>
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/pki/etcd
</span></span><span class="line"><span class="cl"><span class="c1"># it&#39;s found that server.crt is under this directory but no derver-certificate.crt</span>
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/etcd.yaml <span class="p">|</span> grep server-certificate.crt
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests/etcd.yaml <span class="c1"># edit cert-file, save and exit</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep etcd
</span></span><span class="line"><span class="cl"><span class="c1"># check logs of the last created etcd server</span>
</span></span><span class="line"><span class="cl">docker logs 55af7d00934a
</span></span><span class="line"><span class="cl">kubectl get pods
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep kube-api
</span></span><span class="line"><span class="cl">docker logs 7397dc223c2e
</span></span><span class="line"><span class="cl"><span class="c1"># TLS handshake timeout</span>
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep kube-api
</span></span><span class="line"><span class="cl">docker logs 7397dc223c2e
</span></span><span class="line"><span class="cl"><span class="c1"># grpc: addrConn.createTransport failed to connect to https://127.0.0.1:2379 &lt;nil&gt; 0 &lt;nil&gt;. Err : connection error: desc = &#34;transport: authentication handshake failed: x509: certificated signed by unknown authority&#34;. Reconnecting...</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 2379=etcd server</span>
</span></span><span class="line"><span class="cl">docker ps -a <span class="p">|</span> grep etcd
</span></span><span class="line"><span class="cl">docker logs 55af7d00923
</span></span><span class="line"><span class="cl"><span class="c1"># error &#34;remote error: tls: bad certificate&#34;</span>
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/kube-apiserver.yaml <span class="p">|</span> grep <span class="s2">&#34;--etcd&#34;</span>
</span></span><span class="line"><span class="cl">    - --etcd-cafile<span class="o">=</span>/etc/kubernetes/pki/ca.crt
</span></span><span class="line"><span class="cl">    - --etcd-certfile<span class="o">=</span>/etc/kubernetes/pki/apiserver-etcd-client.crt
</span></span><span class="line"><span class="cl">    - --etcd-keyfile<span class="o">=</span>/etc/kubernetes/pki/apiserver-etcd-client.key
</span></span><span class="line"><span class="cl">    - --etcd-servers<span class="o">=</span>https://127.0.0.1:2379
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/pki/etcd/
</span></span><span class="line"><span class="cl"><span class="c1"># modify the etcd-cafile, add a directory &#34;/etc/kubernetes/pki/etcd/ca.crt&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="153-certificates-api-">153. Certificates API â›‘ï¸â›‘ï¸â›‘ï¸</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="nb">pwd</span> <span class="o">&amp;&amp;</span> ls
</span></span><span class="line"><span class="cl">cat akshay.csr
</span></span><span class="line"><span class="cl">cat akshay.csr <span class="p">|</span> base64 -w <span class="m">0</span> <span class="c1"># -w 0 : prints single line</span>
</span></span><span class="line"><span class="cl"><span class="c1"># copy the base64 encoded result</span>
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF | kubectl apply -f -
</span></span></span><span class="line"><span class="cl"><span class="s">apiVersion: certificates.k8s.io/v1
</span></span></span><span class="line"><span class="cl"><span class="s">kind: CertificateSigningRequest
</span></span></span><span class="line"><span class="cl"><span class="s">metadata:
</span></span></span><span class="line"><span class="cl"><span class="s">  name: john-developer
</span></span></span><span class="line"><span class="cl"><span class="s">  namespace: development
</span></span></span><span class="line"><span class="cl"><span class="s">spec:
</span></span></span><span class="line"><span class="cl"><span class="s">  request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1ZEQ0NBVHdDQVFBd0R6RU5NQXNHQTFVRUF3d0VhbTlvYmpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRApnZ0VQQURDQ0FRb0NnZ0VCQUxDQ1RSQUIrZlJYOEk4cHRRakUwMXY4VVJEQXdRdmRaMjdhWXhjbUZMblQrWUVGCjR6OVBlZTMwZzZqTUVOY2kwLzZvVytGOHNjVm9YM0JVOTJLUjV0Yi9xMm5hcUNwZnhTTXJ5QTZwVlZLOExQencKcVV2UUVaSUZRUUdIeGJFNWxzWldGYUNKNXFaeTBMV3hmVTY1cDN1ZWVYcVVMMDEyOTBKSW1RaUFuSXFMb25abAprSFpjSTQ2MUUzOVNGbitycENDaWQ3c0VIWmFNMk5jVzV4TGVUU2w3Z3NvYXRpbXMxZkRKRys0amtaYVpHdC81ClZ4bU9LVE9uS3ROQXhvNk05eWNQYzZUOW8wK0hZRWNxa2czUU5hQ1BTUUlEYnV6Q1Y5UnRIK2cvTW9pNjc3T2UKWWdtT0Y3YzNzVHZDUXR1NjBYWkwycHZVcHI4bUM0QUtneVVPT1NrQ0F3RUFBYUFBTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQjVqK0FSRXd4K2tCZ3JqN05SazVqRnEwemlQVU51UysyZmpXenR1c2Y0VUd4YmlvNjBHMG9nCnk0WDdvQzZqOTdqdkM5bnlqNGNuTG4yVGtlVXV1UFFKanlibGRyZC9OTUJHWml2U25jUHlLNXdoTlFVNU1VWksKb3g1ZTI0YXA3QU82ekNubzJiSTZxcmlSQVBiSkRQclcrK0o2RGJ3QUorNHNXaEY3TXgxVWRmZUNvQjd1amhTUgpzR1dIcnpqZFFkeHRYVWdNRWZ3VEplNnlnVVFSOHVYWjBrVFdaS0R1alRJenlWdFRyVFRSVElSQW43QjdGeFBBCm5mRlhxV09uMi9TMWkrQ2FhMlp1Z0lCbWhNMnRPcXZ5R1FpQ3p2REtPY21EcVhYSnFkQjZxVExsM3RBUVg2MWoKUkg2MGE0YklpNFhFYzZ3U2VTWjlJTFBaTlZVQWZKLzYKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==
</span></span></span><span class="line"><span class="cl"><span class="s">  signerName: kubernetes.io/kube-apiserver-client
</span></span></span><span class="line"><span class="cl"><span class="s">  usages:
</span></span></span><span class="line"><span class="cl"><span class="s">  - client auth
</span></span></span><span class="line"><span class="cl"><span class="s">EOF</span>
</span></span><span class="line"><span class="cl">k get csr 
</span></span><span class="line"><span class="cl"><span class="c1"># check that the newly created csr akshay is at pending state</span>
</span></span><span class="line"><span class="cl">k certificate approve akshay
</span></span><span class="line"><span class="cl">k get csr
</span></span><span class="line"><span class="cl"><span class="c1"># note that the condition of csr akshay is Approved</span>
</span></span><span class="line"><span class="cl">k get csr agent-smith -oyaml
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  groups:
</span></span><span class="line"><span class="cl">  - system:masters <span class="c1"># this priviledge is too great for agent smith&#39;</span>
</span></span><span class="line"><span class="cl">  - system:authenticatd
</span></span><span class="line"><span class="cl">k certificate deny agent-smith
</span></span><span class="line"><span class="cl">k get csr
</span></span></code></pre></td></tr></table>
</div>
</div><p>6443 | 2379 |</p>
<h3 id="155-kubeconfig">155. KubeConfig</h3>
<table>
<thead>
<tr>
<th>API args command</th>
<th>$HOME/.kube/config</th>
</tr>
</thead>
<tbody>
<tr>
<td>&ndash;server</td>
<td>Clusters section</td>
</tr>
<tr>
<td>&ndash;client-key</td>
<td>Users section</td>
</tr>
<tr>
<td>&ndash;client-certificate</td>
<td>Users section</td>
</tr>
<tr>
<td>&ndash;certificate-authority</td>
<td>Clusters section</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Config</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">current-context</span><span class="p">:</span><span class="w"> </span><span class="l">dev-user@google</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">clusters</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">= name</span><span class="p">:</span><span class="w"> </span><span class="l">my-kube-playground</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">cluster</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="c"># certificate-authority: ca.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">certificate-authority-data</span><span class="p">:</span><span class="w"> </span><span class="l">&lt;base64-encoded-ca.crt-file&gt;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">server</span><span class="p">:</span><span class="w"> </span><span class="l">https://my-kube-playground:6443</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">contexts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-kube-admin@my-kube-playground</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">context</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">cluster</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">user</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">test</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="l">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">users</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-kube-admin</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">user</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">client-certificate</span><span class="p">:</span><span class="w"> </span><span class="l">admin.crt</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">client-key</span><span class="p">:</span><span class="w"> </span><span class="l">admin.key</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span>- <span class="l">...</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>é€™äº›æ˜¯ api call kube-apiserver æœƒå¸¶çš„ argumentsï¼Œå¯ä»¥æ”¹å­˜åœ¨ kube config æª”</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl config current-context
</span></span><span class="line"><span class="cl">kubectl config view
</span></span><span class="line"><span class="cl">kubectl config use-context prod-user@production
</span></span><span class="line"><span class="cl">kubectl config set-context <span class="k">$(</span>k<span class="k">)</span> --namespace<span class="o">=</span><span class="nb">test</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="167-service-accounts">167. Service Accounts</h3>
<p>Monitoring tools (Prometheus) and automated build tools (Jenkins) use service accounts to interact with Kubernetes. <strong>When the service account is created, it also creates a token automatically</strong>. The service account token is what must be used by the external application while authenticating to the Kubernetes API.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k create serviceaccount dashboard-sa
</span></span><span class="line"><span class="cl">k describe serviceaccount dashboard-sa
</span></span><span class="line"><span class="cl"><span class="c1"># check tokens section</span>
</span></span><span class="line"><span class="cl">Name:
</span></span><span class="line"><span class="cl">Namespace:
</span></span><span class="line"><span class="cl">Labels:
</span></span><span class="line"><span class="cl">Anno
</span></span></code></pre></td></tr></table>
</div>
</div><p>(1) create a service account &ndash;&gt; (2) generate a token for the service account &ndash;&gt; (3) create a secret object and store the token inside the secret object</p>
<p>å¦‚æœ pod definition yaml file æ²’æœ‰åˆ— serviceAccountï¼Œåœ¨å»ºç«‹ pod ä¹‹å¾Œ describe å…§å®¹å¯ä»¥çœ‹åˆ°ä¸€å€‹ default token being mounted as volumeï¼Œ<code>/var/run/secrets/kubernetes.io/serviceaccount</code> æ˜¯é€™å€‹ volume æ›è¼‰åˆ°çš„ç›®éŒ„</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl <span class="nb">exec</span> -it my-kubernetes-dashboard -- ls /var/run/secrets/kubernetes.io/serviceaccount
</span></span><span class="line"><span class="cl">ca.crt  	namespace  	token
</span></span><span class="line"><span class="cl">kubectl <span class="nb">exec</span> -it my-kubernetes-dashboard cat /var/run/secrets/kubernetes.io/serviceaccount
</span></span></code></pre></td></tr></table>
</div>
</div><p>åœ¨ pod definition yaml file è‡ªå®šç¾© service account:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-kubernetes-dashboard</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">my-kubernetes-dashboard</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">my-kubernetes-dashboard</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">serviceAccountName</span><span class="p">:</span><span class="w"> </span><span class="l">dashboard-sa</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">automountServiceAccountToken</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="c"># choose not to mount default token automatically</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="version-122-update-kep-1205">version 1.22 update (KEP 1205)</h4>
<ul>
<li>Token æ²’æœ‰æœ‰æ•ˆæœŸé™ï¼šKEP 1205 æ–°å¢äº† TokenRequestAPIï¼Œé€é TokenRequestAPI å»ºç«‹çš„ token æœ‰ä¸‰å€‹ç‰¹é»ï¼š(1) time bound (2) audience bound (3) object bound</li>
<li>The service account token now becomes a <strong>projected volume</strong> that communicates with the token controller API</li>
</ul>
<h4 id="version-124-update-kep-2799">version 1.24 update (KEP 2799)</h4>
<ul>
<li>
<p>Reduction of Secret based service account tokens</p>
</li>
<li>
<p>ç•¶å»ºç«‹ service account æ™‚ï¼Œä¸å†è‡ªå‹•å»ºç«‹ secret / token access secret</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl create token &lt;name-of-the-service-account&gt;
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="170-image-security">170. Image Security</h3>
<p><code>&lt;(0) registry&gt;</code>/<code>&lt;(1) library&gt;</code>/<code>&lt;(2)name-of-the-image&gt;</code></p>
<p>(0) locations to be pulled from, default <code>docker.io</code>, other popular registries are <code>gcr.io</code>, etc.</p>
<p>(1) stands for user or account name ()</p>
<p>(2) image / repository</p>
<h4 id="private-repository">Private Repository</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">docker login private-registry.io
</span></span><span class="line"><span class="cl">docker run private-registry.io/apps/internal-app
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl create secret docker-registry regcred <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   --docker-server<span class="o">=</span>private-registry.io  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   --docker-username<span class="o">=</span>registry-user  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   --docker-password<span class="o">=</span>registry-password  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>   --docker-email<span class="o">=</span>registry-user@org.com
</span></span><span class="line"><span class="cl">   
</span></span><span class="line"><span class="cl">cat nginx-pod.yaml
</span></span><span class="line"><span class="cl">apiVersion: v1
</span></span><span class="line"><span class="cl">kind: Pod
</span></span><span class="line"><span class="cl">metadata:
</span></span><span class="line"><span class="cl">  name: nginx-pod
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  containers:
</span></span><span class="line"><span class="cl">  - name: nginx
</span></span><span class="line"><span class="cl">    image: private-registry.io/apps/internal-app
</span></span><span class="line"><span class="cl">  imagePullSecrets:
</span></span><span class="line"><span class="cl">  - name: regcred <span class="c1"># secret docker-registry </span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="177-network-policy">177. Network Policy</h3>
<p>Kubernetes is configured by default with an <strong>all-allow</strong> rules that allows traffic from any pod to any other pod or services within the cluster.</p>
<table>
<thead>
<tr>
<th>Solutions w/ netpol support âœ…</th>
<th>Solution w/out netpol support âŒ</th>
</tr>
</thead>
<tbody>
<tr>
<td>Kube-router, Calico, Romana, Weave-net</td>
<td>Flannel</td>
</tr>
</tbody>
</table>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">networking.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">NetworkPolicy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">db-policy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">podSelector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">role</span><span class="p">:</span><span class="w"> </span><span class="l">db</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">policyTypes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="l">Ingress</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ingress</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">from</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">podSelector</span><span class="p">:</span><span class="w">  </span><span class="c"># rule no.1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">api-pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">namespaceSelector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">prod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">ipBlock</span><span class="p">:</span><span class="w">      </span><span class="c"># rule no.2</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">cidr</span><span class="p">:</span><span class="w"> </span><span class="m">192.168.5.10</span><span class="l">/32</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">TCP</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">3306</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="211-explore-k8s-environments-ip-a-ip-link-netstat--anp">211. Explore K8s environments (<code>ip a</code>, <code>ip link</code>, <code>netstat -anp</code>)</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get nodes -o wide
</span></span><span class="line"><span class="cl">ip address 
</span></span><span class="line"><span class="cl">ip address show eth0
</span></span><span class="line"><span class="cl">kubectl get nodes -o wide
</span></span><span class="line"><span class="cl"><span class="c1"># get the ip address assigned to node1 ..Q6</span>
</span></span><span class="line"><span class="cl">ssh node01
</span></span><span class="line"><span class="cl">ip address
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q7</span>
</span></span><span class="line"><span class="cl">ip address show <span class="nb">type</span> bridge <span class="c1"># cni0 interface</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># what is the ip address of the default gateway</span>
</span></span><span class="line"><span class="cl">ip route
</span></span><span class="line"><span class="cl">defatul via x.x.x.x dev eth1
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Q10 netstat - to figure out what is listening on</span>
</span></span><span class="line"><span class="cl">netstat --help
</span></span><span class="line"><span class="cl">netstat -npl <span class="p">|</span> grep -i scheduler
</span></span><span class="line"><span class="cl"><span class="c1"># Q11</span>
</span></span><span class="line"><span class="cl">netstat -anp <span class="p">|</span> grep -i etcd <span class="p">|</span> grep -i <span class="m">2379</span> <span class="p">|</span> wc -l
</span></span><span class="line"><span class="cl">netstat -anp <span class="p">|</span> grep -i etcd <span class="p">|</span> grep -i <span class="m">2380</span> <span class="p">|</span> wc -l
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="212-pod-networking">212. Pod Networking</h3>
<p>There are network taht connects nodes together, but here the subject is another layer of networking that is crucial to the clusters functioning, which is the networking at the pod layer.</p>
<h4 id="networking-model">Networking Model</h4>
<ul>
<li>Every POD should have an IP address</li>
<li>Every POD should be able to communicate with every other POD in the same node</li>
<li>Every POD should be able to communicate with every other POD on the other nodes without NAT</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># create a network interface of bridge type called v-net-0</span>
</span></span><span class="line"><span class="cl">ip link add v-net-0 <span class="nb">type</span> bridge
</span></span><span class="line"><span class="cl"><span class="c1"># enable this bridge network interface v-net-0 (bring it up)</span>
</span></span><span class="line"><span class="cl">ip link <span class="nb">set</span> dev v-net-0 up
</span></span><span class="line"><span class="cl"><span class="c1"># configure a IP address (192.169.15.5/24) for this bridge network interface</span>
</span></span><span class="line"><span class="cl">ip addr add 192.168.15.5/24 dev v-net-0
</span></span><span class="line"><span class="cl"><span class="c1"># create veth pair</span>
</span></span><span class="line"><span class="cl">ip link add veth-red <span class="nb">type</span> veth peer name veth-red-br
</span></span><span class="line"><span class="cl"><span class="c1"># attach veth pair</span>
</span></span><span class="line"><span class="cl">ip link <span class="nb">set</span> veth-red netns red
</span></span><span class="line"><span class="cl"><span class="c1"># assign IP address (within namespace red)</span>
</span></span><span class="line"><span class="cl">ip -n red addr add 192.168.15.1 dev veth-red
</span></span><span class="line"><span class="cl">ip -n red link <span class="nb">set</span> veth-red up
</span></span><span class="line"><span class="cl"><span class="c1"># bring up interface</span>
</span></span><span class="line"><span class="cl">ip link <span class="nb">set</span> veth-red-br master v-net-0
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl">ip netns <span class="nb">exec</span> blue ip route add 192.168.1.0/24 via 192.168.15.5
</span></span><span class="line"><span class="cl"><span class="c1">#</span>
</span></span><span class="line"><span class="cl">iptables -t nat -A POSTROUTING -s 192.168.15.0/24 -j MASQUERADE
</span></span><span class="line"><span class="cl"><span class="c1"># delete veth pair</span>
</span></span><span class="line"><span class="cl">ip link del ......
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="215-cni-weave">215. CNI Weave</h3>
<p>How does the CNI <code>weaveworks</code> plugin work?</p>
<p>The weaveworks networking solution had a routing table which mapped what networks are on what hosts. So when a packet is sent from on pod to the other, it goest out to the network, to the router, and finds its way to the node that hosts that pod.</p>
<p>Weave can be deployed in the cluster with a single kubectl apply command. This deploys all the necessary components required for Weave in the cluster. Most importantly, the Weave peers are deployed as a daemon set. A daemon set ensures that one pod of the given kind is deployed on all nodes in the cluster. This works perfectly for the Weave cluster.I fyou deployed your cluster with a kubeadm tool and Weave plugin, you can see the Weave peers as pods deployed on each node.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl logs weave-net-5gcmb weave -n kube-system
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="217-explore-cni">217. Explore CNI</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># identify the container runtime endpoint value is set for Kubernetes</span>
</span></span><span class="line"><span class="cl">ps -aux <span class="p">|</span> grep -i kubelet
</span></span><span class="line"><span class="cl">ps -aux <span class="p">|</span> grep -i kubelet <span class="p">|</span> grep container-runtime
</span></span><span class="line"><span class="cl"><span class="c1"># check the path configured with all binaries of CNI supported plugins</span>
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> /opt/cni/bin
</span></span><span class="line"><span class="cl"><span class="c1"># identify which plugin is not available in the list of available CNI plugins</span>
</span></span><span class="line"><span class="cl">ls 
</span></span><span class="line"><span class="cl"><span class="c1"># check what CNI plugin is configured to be used on the kubernetes cluster</span>
</span></span><span class="line"><span class="cl">ls /etc/cni/net.d/
</span></span><span class="line"><span class="cl"><span class="c1"># check what binary executable file will be run by kubelet after a container and its associated ns are created</span>
</span></span><span class="line"><span class="cl">cat /etc/cni/net.d/10-flannel.conflist
</span></span><span class="line"><span class="cl"><span class="c1"># look for plugins.type</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="219-deploy-network-solution---weave">219. Deploy network solution - Weave</h3>
<p><a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener noreffer ">Installing Addons for Kubernetes</a></p>
<p><a href="https://github.com/weaveworks/weave/blob/master/site/kubernetes/kube-addon.md" target="_blank" rel="noopener noreffer ">Weave Net GitHub - things to watch out for</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k describe -n default po app 
</span></span><span class="line"><span class="cl"><span class="c1"># check event section: failed to set up network for sandbox</span>
</span></span><span class="line"><span class="cl">k apply -f /root/weave/weave-daemonset-k8s.yaml
</span></span><span class="line"><span class="cl">k get po -A grep weave
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># without the yaml pre-set by the lab</span>
</span></span><span class="line"><span class="cl">kubectl describe pod kube-proxy-bwtfb -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1"># the config file path=/var/lib/kube-proxy/config.conf</span>
</span></span><span class="line"><span class="cl"><span class="c1"># mounts /var/lib/kube-proxy from kube-proxy</span>
</span></span><span class="line"><span class="cl">kubectl get cm -n kube-system
</span></span><span class="line"><span class="cl">kubectl describe cm kube-proxy -n kube-system <span class="p">|</span> grep clusterCIDR
</span></span><span class="line"><span class="cl"><span class="c1"># update the clusterCIDR in the weave config yaml file</span>
</span></span><span class="line"><span class="cl">vi weave-daemonset-k8s.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># edit the spec.containers.env of container named weave</span>
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">	containers:
</span></span><span class="line"><span class="cl">	  - name: weave
</span></span><span class="line"><span class="cl">	    env:
</span></span><span class="line"><span class="cl">	      - name: IPALLOC_RANGE
</span></span><span class="line"><span class="cl">	        value: 10.244.0.0/16
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">k apply -f weave-daemonset-k8s.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="222-networking-weave">222. Networking Weave</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get no
</span></span><span class="line"><span class="cl">ls /etc/cni/net.d
</span></span><span class="line"><span class="cl"><span class="c1"># check plugins.name for name of the networking solution of this cluster</span>
</span></span><span class="line"><span class="cl">cat /etc/cni/net.d/10-weave.conflist
</span></span><span class="line"><span class="cl">k get po -n kube-system -owide
</span></span><span class="line"><span class="cl"><span class="c1"># identify the name of the bridge network/interface created by weave on each node</span>
</span></span><span class="line"><span class="cl">ip add
</span></span><span class="line"><span class="cl">k -n kube-system logs weave-net-mknr5 <span class="p">|</span> grep -i ipalloc-range
</span></span><span class="line"><span class="cl"><span class="c1"># find the default gateway configured on the pods scheduled on node01</span>
</span></span><span class="line"><span class="cl">kubectl run busybox --image busybox --dry-run<span class="o">=</span>client -o yaml -- sleep <span class="m">1000</span> &lt; 7.yaml
</span></span><span class="line"><span class="cl">vi 7.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># add nodeName under spec section</span>
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">  nodeName: node01
</span></span><span class="line"><span class="cl">  containers:
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">kubectl apply -f 7.yaml
</span></span><span class="line"><span class="cl">k get po
</span></span><span class="line"><span class="cl">k <span class="nb">exec</span> busybox -- ip route
</span></span><span class="line"><span class="cl"><span class="c1"># default via 10.244.192.0 dev eth0</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="225-service-networking">225. Service Networking</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># what network range are the nodes in the cluster part of</span>
</span></span><span class="line"><span class="cl">kubectl get nodes -o wide
</span></span><span class="line"><span class="cl"><span class="c1"># retrieve the internal ip of controlplane - 192.6.10.10</span>
</span></span><span class="line"><span class="cl"><span class="c1"># take a look at all the network interfaces, look for eth0 or eth1 </span>
</span></span><span class="line"><span class="cl">ip add 
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">207: eth0@if208:
</span></span><span class="line"><span class="cl">    link/ether 02:42:c0:06:0a:0a brd ff:ff:ff:ff:ff:ff link-netnsid <span class="m">0</span>
</span></span><span class="line"><span class="cl">    inet 192.6.10.10/24 brd 192.6.10.255 scope global eth0
</span></span><span class="line"><span class="cl"><span class="c1"># 24 means the last eight bits. The last octet is going to be reserved for the host addresses</span>
</span></span><span class="line"><span class="cl">kubectl get all --all-namespaces
</span></span><span class="line"><span class="cl">kubectl logs weave-net-rbx4p
</span></span><span class="line"><span class="cl"><span class="c1"># start at the top and find the subnet it&#39;s going to use</span>
</span></span><span class="line"><span class="cl">kubectl logs weave-net-rbx4p <span class="p">|</span> grep -i ipalloc-range
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/kube-apiserver.yaml <span class="p">|</span> grep -i service-cluster-ip-range
</span></span><span class="line"><span class="cl"><span class="c1"># check out how many kube-proxies are in this cluster</span>
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">kubectl logs kube-proxy-l25qk -n kube-system
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl"><span class="s2">&#34;Using iptables proxy&#34;</span>
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl"><span class="c1"># DaemonSet: the methodology that we use to normally deploy on every single node in a cluster</span>
</span></span><span class="line"><span class="cl">kubectl get ds --all-namespaces
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="226-dns-in-kubernetes">226. DNS in Kubernetes</h3>
<h4 id="pre-requisite">Pre-requisite</h4>
<ul>
<li>What is DNS?</li>
<li>Host/NS Lookup, Dig utility</li>
<li>Recorded types - A, CNAME</li>
<li>Domain Name Hierarchy</li>
</ul>
<h4 id="objectives">Objectives</h4>
<ul>
<li>What names are assigned to what objects?</li>
<li>Service DNS records</li>
<li>POD DNS records</li>
</ul>
<h3 id="243-kubeadm-introduction">243. kubeadm introduction</h3>
<p>The kubeadm tool helps to boostrap a k8s cluster (using k8s best practice to spin up a multi-node cluster).</p>
<h4 id="steps">Steps</h4>
<ol>
<li>Provision multiple systems or VMs (e.g. 3 physical or virtual machines) and designate master, worker node</li>
<li>Install a container runtime on the hosts (e.g. install <code>containerd</code> on all the nodes)</li>
<li>Install the <code>kubeadm</code> tool on all the nodes</li>
<li>Initialize the master server</li>
<li>Set up the POD network (solution between master and worker nodes)</li>
<li>Have the worker nodes join the master node(s)</li>
<li>Deploy application onto the kubernetes environment</li>
</ol>
<h3 id="245-provision-vms-with-vagrant">245. Provision VMs with Vagrant</h3>
<p>Using two pieces of softwares, need installation:</p>
<ul>
<li>VirtualBox as hypervisor</li>
<li>Vagrant as automation tool to spin up a whole bunch of VMs with a specific configuration</li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">git clone http://github.com/kodekloudhub/certified-kubernetes-administrator-course.git
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> certified-kubernetes-administrator-course/
</span></span><span class="line"><span class="cl">ls
</span></span><span class="line"><span class="cl">vi Vagrantfile
</span></span><span class="line"><span class="cl"><span class="c1"># check numbers of master node, worker node, etc.</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># check the status of the VM</span>
</span></span><span class="line"><span class="cl">vagrant status
</span></span><span class="line"><span class="cl"><span class="c1"># bring up the VMs</span>
</span></span><span class="line"><span class="cl">vagrant up
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">vagrant ssh &lt;name-of-the-node&gt;
</span></span><span class="line"><span class="cl">vagrant ssh kubemaster
</span></span><span class="line"><span class="cl">ls -la
</span></span><span class="line"><span class="cl"><span class="nb">logout</span>
</span></span><span class="line"><span class="cl">vagrant status
</span></span><span class="line"><span class="cl">vagrant ssh kubenode01
</span></span><span class="line"><span class="cl">uptime 
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="248-deploy-a--k8s-cluster-using-kubeadm">248. Deploy a  K8s Cluster using kubeadm</h3>
<p><a href="https://kubernetes.io/docs/setup/production-environment/container-runtimes/" target="_blank" rel="noopener noreffer ">https://kubernetes.io/docs/setup/production-environment/container-runtimes/</a></p>
<p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl" target="_blank" rel="noopener noreffer ">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#installing-kubeadm-kubelet-and-kubectl</a></p>
<p><a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener noreffer ">https://kubernetes.io/docs/concepts/cluster-administration/addons/</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># set up the forwarding rules at both nodes</span>
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; overlay
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; br_netfilter
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span><span class="line"><span class="cl">sudo modprobe overlay
</span></span><span class="line"><span class="cl">sudo modprobe br_netfilter
</span></span><span class="line"><span class="cl">cat <span class="s">&lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.bridge.bridge-nf-call-iptables  = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; net.ipv4.ip_forward                 = 1
</span></span></span><span class="line"><span class="cl"><span class="s">&gt; EOF</span>
</span></span><span class="line"><span class="cl">sudo sysctl --system
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># verify which distribution you are using</span>
</span></span><span class="line"><span class="cl">cat /etc/*-release
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># install kubeadm and kubelet package</span>
</span></span><span class="line"><span class="cl">sudo apt-get update
</span></span><span class="line"><span class="cl">sudo apt get install -y apt-transport-https ca-certificates curl
</span></span><span class="line"><span class="cl">mkdir /etc/apt/keyring
</span></span><span class="line"><span class="cl">sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyringg.gpg] https://apt.kubernetes.ip/ kubernetes-xenial main&#34;</span> <span class="p">|</span> sudo tee /etc/apt/sources.list.d/kubernetes.list
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">sudo apt-get update
</span></span><span class="line"><span class="cl">sudo apt install -y <span class="nv">kubeadm</span><span class="o">=</span>1.26.0-00 <span class="nv">kubelet</span><span class="o">=</span>1.26.0-00 <span class="nv">kubectl</span><span class="o">=</span>1.26.0-00
</span></span><span class="line"><span class="cl">sudo apt-mark hold kubelet kubeadm kubectl
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># check which version of kubelet is installed</span>
</span></span><span class="line"><span class="cl">kubelet --version
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl"><span class="c1"># Q5 bootstrap a kubernetes cluster using the kubeadm tool</span>
</span></span><span class="line"><span class="cl"><span class="c1"># get the ip address allocated to eth0 on the controlplane node</span>
</span></span><span class="line"><span class="cl">ip add
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">2607: eth0@if2608: ...... 
</span></span><span class="line"><span class="cl">    inet 192.7.220.6/24 brd 182.7.220.255 scope global cni0
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">kubeadm init --apiserver-advertise-address<span class="o">=</span>192.7.220.6 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --pod-network-cidr<span class="o">=</span>10.244.0.0/16 
</span></span><span class="line"><span class="cl">mkdir -p <span class="nv">$HOME</span>/.kube
</span></span><span class="line"><span class="cl">sudo cp -i /etc/kubernetes/admin.conf <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="cl">sudo chown <span class="k">$(</span>id -u<span class="k">)</span>:<span class="k">$(</span>id -g<span class="k">)</span> <span class="nv">$HOME</span>/.kube/config
</span></span><span class="line"><span class="cl">kubectl get nodes
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#Q6 generate a kubeadm join token (copy the one that was generated by kubeadm init command) @controlplane</span>
</span></span><span class="line"><span class="cl">kubeadm join 192.7.200.6:6443 --token 6cv4ox.ea6gvfiim94c9igu <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>  --discovery-token-ca-cert-hash sha256:xxxxxxxxDEACTEDxxx
</span></span><span class="line"><span class="cl"><span class="c1"># copy the kubeadm join token and paste it @node01 terminal</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Q8 install flannel</span>
</span></span><span class="line"><span class="cl">kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="instal-kubeadm">Instal kubeadm</h4>
<p><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/" target="_blank" rel="noopener noreffer ">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/</a></p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># check OS (Debian-based, Red Hat-based or without a package manager)</span>
</span></span><span class="line"><span class="cl">cat /etc/*-release 
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="226-dns-in-kubernetes-1">226. DNS in Kubernetes</h3>
<p>Objectives</p>
<ul>
<li>What names are assigned to what objects?</li>
<li>Service DNS records</li>
<li>POD DNS records</li>
</ul>
<h3 id="229-explore-dns">229. Explore DNS</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get po -n kube-system 
</span></span><span class="line"><span class="cl">coredns-74ff55c5b-glcxv
</span></span><span class="line"><span class="cl">coredns-74ff55c5b-kgtwz
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">k get svc -n kube-system
</span></span><span class="line"><span class="cl">kube-dns   ClusterIP   10.96.0.10
</span></span><span class="line"><span class="cl">k describe po coredns-74ff55c5b-glcxv -n kube-system
</span></span><span class="line"><span class="cl"><span class="c1"># check the image used by container coredns</span>
</span></span><span class="line"><span class="cl"><span class="c1"># check the args for the config file located for configuring the CoreDNS service</span>
</span></span><span class="line"><span class="cl">Containers:
</span></span><span class="line"><span class="cl">  coredns:
</span></span><span class="line"><span class="cl">    Args:
</span></span><span class="line"><span class="cl">      -conf
</span></span><span class="line"><span class="cl">      /etc/coredns/Corefile
</span></span><span class="line"><span class="cl"><span class="c1"># the Mounts</span>
</span></span><span class="line"><span class="cl">    Mounts:
</span></span><span class="line"><span class="cl">      /etc/coredns from config-volume <span class="o">(</span>ro<span class="o">)</span>
</span></span><span class="line"><span class="cl">k -n kube-system get po coredns-74ff55c5b-glcxv -oyaml
</span></span><span class="line"><span class="cl"><span class="c1"># check spec.containers[0].volumeMounts (name: config-volume)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># check spec.volumes of name config-volume</span>
</span></span><span class="line"><span class="cl">k -n kube-system get cm coredns
</span></span><span class="line"><span class="cl">k -n kube-system describe cm coredns
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl"><span class="nv">Data</span>
</span></span><span class="line"><span class="cl"><span class="o">====</span>
</span></span><span class="line"><span class="cl">Corefile:
</span></span><span class="line"><span class="cl">----
</span></span><span class="line"><span class="cl">.:53 <span class="o">{</span>
</span></span><span class="line"><span class="cl">    errors
</span></span><span class="line"><span class="cl">    health <span class="o">{</span> 
</span></span><span class="line"><span class="cl">        lamduck 5s
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl">    ready      
</span></span><span class="line"><span class="cl">    <span class="c1"># cluster.local: the rool domain configured for this cluster</span>
</span></span><span class="line"><span class="cl">    kubernetes cluster.local in-addr.arpa ip6.arpa <span class="o">{</span>
</span></span><span class="line"><span class="cl">       pods insecure
</span></span><span class="line"><span class="cl">       fallthrough in-addr.arpa ip6.arpa
</span></span><span class="line"><span class="cl">       ttl <span class="m">30</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl">    prometheus :9153
</span></span><span class="line"><span class="cl">    forward . /etc/resolv.conf <span class="o">{</span>
</span></span><span class="line"><span class="cl">       max_concurrent <span class="m">1000</span>
</span></span><span class="line"><span class="cl">    <span class="o">}</span>
</span></span><span class="line"><span class="cl">    cache <span class="m">30</span>
</span></span><span class="line"><span class="cl">    loop
</span></span><span class="line"><span class="cl">    reload
</span></span><span class="line"><span class="cl">    loadbalance
</span></span><span class="line"><span class="cl"><span class="o">}</span>
</span></span><span class="line"><span class="cl">k get po -n payroll
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="249-end-to-end-tests">249. End-to-End tests</h3>
<p>(no longer a part of CKA curriculum)</p>
<p>@Master Node</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">go get -u k8s.io/test-infra/kubetest
</span></span><span class="line"><span class="cl">kubetest --extract<span class="o">=</span>v1.11.3	
</span></span><span class="line"><span class="cl"><span class="c1"># version must match the kubernetes server version</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">cd</span> kubernetes
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">KUBE_MASTER_IP</span><span class="o">=</span><span class="s2">&#34;192.168.26.10:6443&#34;</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">KUBE_MASTER</span><span class="o">=</span>kube-master
</span></span><span class="line"><span class="cl">kubetest --test --provider<span class="o">=</span>skeleton &gt; testout.txt
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubetest --test --provider<span class="o">=</span>skeleton --test_args<span class="o">=</span><span class="s2">&#34;--ginkgo.focus=Secrets&#34;</span> &gt; testout.txt
</span></span><span class="line"><span class="cl">kubetest --test --provider<span class="o">=</span>skeleton --test_args<span class="o">=</span><span class="s2">&#34;--ginkgo.focus=\[Conformance\]&#34;</span> &gt; testout.txt
</span></span><span class="line"><span class="cl">cat testout.txt
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="257-controlplane-failure">257. Controlplane failure</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">k get deploy
</span></span><span class="line"><span class="cl">k describe deploy app
</span></span><span class="line"><span class="cl">k get pod
</span></span><span class="line"><span class="cl">k describe pod app-586bdddbc54-hc779
</span></span><span class="line"><span class="cl"><span class="c1"># the pod was not assigned to a node</span>
</span></span><span class="line"><span class="cl">k get po -n kube-system
</span></span><span class="line"><span class="cl">k -n kube-system describe po kube-scheduler-controlplane
</span></span><span class="line"><span class="cl"><span class="c1"># Event: the executable file is not found</span>
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests/kube-scheduler.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># edit the command and save </span>
</span></span><span class="line"><span class="cl">k get po -n kube-system -w
</span></span><span class="line"><span class="cl"><span class="c1"># watch until the new kube-scheduler-controplane is ready</span>
</span></span><span class="line"><span class="cl">k get po,deploy
</span></span><span class="line"><span class="cl">k get deploy 
</span></span><span class="line"><span class="cl">k scale --replicas <span class="m">2</span> deploy app
</span></span><span class="line"><span class="cl"><span class="c1"># the jobs of scaling replicaset is controller manager</span>
</span></span><span class="line"><span class="cl">k -n kube-system describe po kube-controller-manager-controlplane
</span></span><span class="line"><span class="cl">k -n kube-system logs kube-controller-manager-controlplane
</span></span><span class="line"><span class="cl"><span class="c1"># cannot access /etc/kubernetes/controller-manager-xxxx.conf, no such file</span>
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests/kube-controller-manager.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># find out what&#39;s wrong with the kubeconfig path</span>
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/controller-manager.conf
</span></span><span class="line"><span class="cl">k get pod,deploy
</span></span><span class="line"><span class="cl">k describe deploy app
</span></span><span class="line"><span class="cl">k -n kube-system logs kube-controller-manager-controlplane
</span></span><span class="line"><span class="cl"><span class="c1"># unable to load client CA file /etc/kubernetes/pki/ca.crt</span>
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/pki/ca.crt
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/manifests/kube-controller-manager.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># check the volumeMounts</span>
</span></span><span class="line"><span class="cl"><span class="c1"># check the volumes section *hostPath for k8s-certs*</span>
</span></span><span class="line"><span class="cl"><span class="c1"># wait until the kube controller manager is back running</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="254">254.</h3>
<h3 id="257">257.</h3>
<h3 id="260">260.</h3>
<p>=======</p>
<h3 id="260-workernode-failure">260. WorkerNode failure</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">k describe no node01
</span></span><span class="line"><span class="cl">ssh node01
</span></span><span class="line"><span class="cl"><span class="c1"># check the controller of the node - kubelet</span>
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl"><span class="c1"># state inactive</span>
</span></span><span class="line"><span class="cl">service kubelet start
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># At controlplane</span>
</span></span><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">k describe no node01
</span></span><span class="line"><span class="cl">ssh node01
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl"><span class="c1"># exit code status 255, let check logs of this service</span>
</span></span><span class="line"><span class="cl">journalctl -u kubelet 
</span></span><span class="line"><span class="cl"><span class="c1"># unable to load client CA file /etc/kubernetes/pki/wrong-ca-file.crt</span>
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/kubelet.conf <span class="c1"># the kubeconfig file used by kubelet to connect to the api-server</span>
</span></span><span class="line"><span class="cl">ls /var/lib/kubelet
</span></span><span class="line"><span class="cl">config.yaml ...
</span></span><span class="line"><span class="cl">cat /var/lib/kubelet/config.yaml
</span></span><span class="line"><span class="cl">apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span class="line"><span class="cl">authentication:
</span></span><span class="line"><span class="cl">  anonymous:
</span></span><span class="line"><span class="cl">    enabled: <span class="nb">false</span>
</span></span><span class="line"><span class="cl">  webhook:
</span></span><span class="line"><span class="cl">    cacheTTL: 0s
</span></span><span class="line"><span class="cl">    enabled: <span class="nb">true</span>
</span></span><span class="line"><span class="cl">  x509:
</span></span><span class="line"><span class="cl">    clientCAFile: /etc/kubernetes/pki/WRONG-CA-FILE.crt
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">ls /etc/kubernetes/pki/ca.crt 
</span></span><span class="line"><span class="cl"><span class="c1"># this should be the right client ca file (tab )</span>
</span></span><span class="line"><span class="cl">vi /var/lib/kubelet/config.yaml
</span></span><span class="line"><span class="cl"><span class="c1"># save and restart the kubelet service</span>
</span></span><span class="line"><span class="cl">service kubelet restart
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl"><span class="nb">exit</span> 
</span></span><span class="line"><span class="cl"><span class="c1"># At controlplane</span>
</span></span><span class="line"><span class="cl">k get nodes
</span></span><span class="line"><span class="cl">ssh node01
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl"><span class="c1"># why, it&#39;s active and running</span>
</span></span><span class="line"><span class="cl">journalctl -u kubelet
</span></span><span class="line"><span class="cl"><span class="c1"># scroll all the way to the end and scroll backward</span>
</span></span><span class="line"><span class="cl"><span class="c1"># unable to register node01 - Post &#34;https://controlplane:6554/api/v1/nodes&#34;: dial tcp 10.54.130.2:6553: connect: connection refused</span>
</span></span><span class="line"><span class="cl">vi /etc/kubernetes/kubelet.conf
</span></span><span class="line"><span class="cl"><span class="c1"># edit the clusters[0].cluster.server, set to 6443 port</span>
</span></span><span class="line"><span class="cl">service kubelet restart
</span></span><span class="line"><span class="cl">service kubelet status
</span></span><span class="line"><span class="cl">journalctl -u kubelet -f
</span></span><span class="line"><span class="cl"><span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="c1"># At controlplane</span>
</span></span><span class="line"><span class="cl">k get node
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="262-troubleshoot-network">262. Troubleshoot network</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">k -n triton get all
</span></span><span class="line"><span class="cl">k -n triton describe po mysql 
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">Failed to create pod sandbox: rpc error: <span class="nv">code</span> <span class="o">=</span> Unknown <span class="nv">desc</span> <span class="o">=</span> failed to setup network <span class="k">for</span> sandbox <span class="s2">&#34;ff12f3010deed44dffc3130bcf5d5dd50a9bdf4cc192e4db3be010ee1c1fc260&#34;</span>: plugin <span class="nv">type</span><span class="o">=</span><span class="s2">&#34;weave-net&#34;</span> <span class="nv">name</span><span class="o">=</span><span class="s2">&#34;weave&#34;</span> failed <span class="o">(</span>add<span class="o">)</span>: unable to allocate IP address: Post <span class="s2">&#34;http://127.0.0.1:6784/ip/ff12f3010deed44dffc3130bcf5d5dd50a9bdf4cc192e4db3be010ee1c1fc260&#34;</span>: dial tcp 127.0.0.1:6784: connect: connection refused
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">k -n kube-system get po
</span></span><span class="line"><span class="cl">curl -L https://github.com/weaveworks/weave/releases/download/latest_release/weave-daemonset-k8s-1.11.yaml <span class="p">|</span> kubectl apply -f -
</span></span><span class="line"><span class="cl">k -n kube-system get ds
</span></span><span class="line"><span class="cl">kubectl -n kube-system logs kube-proxy
</span></span><span class="line"><span class="cl">kubectl -n kube-system get po <span class="p">|</span> grep -i kube-proxy
</span></span><span class="line"><span class="cl">kubectl -n kube-system logs kube-proxy-m72cj 
</span></span><span class="line"><span class="cl">E1104 10:18:03.833053       <span class="m">1</span> run.go:74<span class="o">]</span> <span class="s2">&#34;command failed&#34;</span> <span class="nv">err</span><span class="o">=</span><span class="s2">&#34;failed complete: open /var/lib/kube-proxy/configuration.conf: no such file or directory&#34;</span>
</span></span><span class="line"><span class="cl">k -n kube-system edit ds kube-proxy
</span></span><span class="line"><span class="cl"><span class="c1"># edit command args</span>
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">spec:
</span></span><span class="line"><span class="cl">    containers:
</span></span><span class="line"><span class="cl">    - command:
</span></span><span class="line"><span class="cl">        - /usr/local/bin/kube-proxy
</span></span><span class="line"><span class="cl">        - --config<span class="o">=</span>/var/lib/kube-proxy/config.conf
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">k -n triton get po
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="264-json-path-">264. JSON Path ğŸš§ğŸš§ğŸš§</h3>
<p>TODO <a href="https://kodekloud.com/p/json-path-quiz" target="_blank" rel="noopener noreffer ">https://kodekloud.com/p/json-path-quiz</a></p>
<h3 id="268-lightning-lab---1-">268. Lightning Lab - 1 ğŸš§ğŸš§ğŸš§</h3>
<table>
<thead>
<tr>
<th>Question#</th>
<th>1st try</th>
<th>2nd</th>
<th>3rd</th>
<th>4th</th>
<th>5th</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>âŒ gan è¶…é›£çš„è¶…è¤‡é›œ åªè¨‚æ­£ä¸€åŠ</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>âœ…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>âœ…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>âœ…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>âŒ</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>6</td>
<td>âŒ</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>7</td>
<td>âœ…</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>Useful Docs:</strong></p>
<ul>
<li><a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/change-package-repository/" target="_blank" rel="noopener noreffer ">https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/change-package-repository/</a></li>
</ul>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># Q1 upgrade kubernetes version from 1.30.0 to 1.31.0 using kubeadm utility</span>
</span></span><span class="line"><span class="cl"><span class="c1"># make sure the upgrade is carried out one node at a time, starting with the controlplane</span>
</span></span><span class="line"><span class="cl"><span class="c1"># the deployment gold-nginx should be rescheduled on an alternate node before upgrading each node</span>
</span></span><span class="line"><span class="cl"><span class="c1"># update controlplane node first, then drain node01 before upgrading it</span>
</span></span><span class="line"><span class="cl">ssh controlplane
</span></span><span class="line"><span class="cl">vi /etc/apt/sources.list.d/kubernetes.list
</span></span><span class="line"><span class="cl"><span class="c1"># update the version in the URL, save the file and exit from text editor</span>
</span></span><span class="line"><span class="cl">deb <span class="o">[</span>signed-by<span class="o">=</span>/etc/apt/keyrings/kubernetes-apt-keyring.gpg<span class="o">]</span> https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">kubectl drain controlplane --ignore-daemonsets
</span></span><span class="line"><span class="cl">apt update
</span></span><span class="line"><span class="cl">apt-cache madison kubeadm
</span></span><span class="line"><span class="cl"><span class="c1"># from the result we know the available package version is 1.31.0-1.1, so we install kubeadm for k8s v1.31.0 with the following command:</span>
</span></span><span class="line"><span class="cl">apt-get install <span class="nv">kubeadm</span><span class="o">=</span>1.31.0-1.1
</span></span><span class="line"><span class="cl"><span class="c1"># run below commands to upgrade the k8s cluster</span>
</span></span><span class="line"><span class="cl">kubeadm upgrade plan v1.31.0
</span></span><span class="line"><span class="cl">kubeadm upgrade apply v1.31.0
</span></span><span class="line"><span class="cl"><span class="c1"># upgrade the version and restart </span>
</span></span><span class="line"><span class="cl">apt-get install <span class="nv">kubelet</span><span class="o">=</span>1.31.0-1.1
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart kubelet
</span></span><span class="line"><span class="cl">kubectl uncordon controlplane
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Q2 passed</span>
</span></span><span class="line"><span class="cl">    <span class="m">8</span>  k -n admin2406 get deploy -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items}&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="m">9</span>  k -n admin2406 get deploy -o --help
</span></span><span class="line"><span class="cl">   <span class="m">10</span>  k -n admin2406 get deploy --help
</span></span><span class="line"><span class="cl">   <span class="m">11</span>  k -n admin2406 get deploy --custom-columns<span class="o">=</span>DEPLOYMENT:.metadata.name
</span></span><span class="line"><span class="cl">   <span class="m">12</span>  k -n admin2406 get deploy -o --custom-columns<span class="o">=</span>DEPLOYMENT:.metadata.name
</span></span><span class="line"><span class="cl">   <span class="m">13</span>  k -n admin2406 get deploy -o --custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">14</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">15</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.containers[*].image&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">16</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.templates.containers[*].image&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">17</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.templates.spec.containers[0].image&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">18</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.containers[0].image&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">19</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.containers[0].image,READY_REPLICAS:.status,NAMESPACE:.metadata.namespace&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">20</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.containers[0].image,READY_REPLICAS:.status.availableReplicas,NAMESPACE:.metadata.namespace&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">21</span>  <span class="c1">#k -n admin2406 get deploy -o custom-columns=&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.containers[0].image,READY_REPLICAS:.status.availableReplicas,NAMESPACE:.metadata.namespace&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">22</span>  k -n admin2406 get deploy deploy1
</span></span><span class="line"><span class="cl">   <span class="m">23</span>  k -n admin2406 get deploy deploy1 -o yaml
</span></span><span class="line"><span class="cl">   <span class="m">24</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.template.spec.containers[0].image,READY_REPLICAS:.status.availableReplicas,NAMESPACE:.metadata.namespace&#34;</span>
</span></span><span class="line"><span class="cl">   <span class="m">25</span>  k -n admin2406 get deploy -o custom-columns<span class="o">=</span><span class="s2">&#34;DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.template.spec.containers[0].image,READY_REPLICAS:.status.availableReplicas,NAMESPACE:.metadata.namespace&#34;</span> &gt; /opt/admin2406_data
</span></span><span class="line"><span class="cl">   <span class="m">26</span>  ls /root/CKA
</span></span><span class="line"><span class="cl">   <span class="m">27</span>  vi admin.kubeconfig
</span></span><span class="line"><span class="cl">   <span class="m">28</span>  cat /root/CKA/admin.kubeconfig
</span></span><span class="line"><span class="cl">   <span class="m">29</span>  k get no
</span></span><span class="line"><span class="cl">   <span class="m">30</span>  k describe no controlplane
</span></span><span class="line"><span class="cl">   <span class="m">31</span>  k describe no controlplane <span class="p">|</span> grep -i port
</span></span><span class="line"><span class="cl">   <span class="m">32</span>  vi /etc/kubernetes/manifests/kube-apiserver.yaml 
</span></span><span class="line"><span class="cl">   <span class="m">33</span>  vi /root/CKA/admin.kubeconfig
</span></span><span class="line"><span class="cl">   <span class="m">34</span>  k create deploy nginx-deploy --image nginx:1.16 --replicas <span class="m">1</span> --dry-run<span class="o">=</span>client -o yaml &gt; 4.yaml
</span></span><span class="line"><span class="cl">   <span class="m">35</span>  vi 4.yaml 
</span></span><span class="line"><span class="cl">   <span class="m">36</span>  k create -f 4.yaml 
</span></span><span class="line"><span class="cl">   <span class="m">37</span>  k get deploy
</span></span><span class="line"><span class="cl">   <span class="m">38</span>  k get deploy nginx-deploy -oyaml
</span></span><span class="line"><span class="cl">   <span class="m">39</span>  k <span class="nb">set</span> image deploy/nginx-deploy <span class="nv">nginx</span><span class="o">=</span>nginx:1.17
</span></span><span class="line"><span class="cl">   <span class="m">40</span>  k rollout status deploy/nginx-deploy
</span></span><span class="line"><span class="cl">   <span class="m">41</span>  k -n alpha get deploy
</span></span><span class="line"><span class="cl">   <span class="m">42</span>  k -n alpha edit deploy alpha-mysql
</span></span><span class="line"><span class="cl">   <span class="m">43</span>  k -n alpha describe deploy alpha-mysql
</span></span><span class="line"><span class="cl">   <span class="m">44</span>  k get po -n alpha
</span></span><span class="line"><span class="cl">   <span class="m">45</span>  k -n alpha get pv,pvc
</span></span><span class="line"><span class="cl">   <span class="m">46</span>  k -n alpha edit pvc alpha-claim 
</span></span><span class="line"><span class="cl">   <span class="m">47</span>  k replace --force --grace-period<span class="o">=</span><span class="m">0</span> -f /tmp/kubectl-edit-4056409266.yaml
</span></span><span class="line"><span class="cl">   <span class="m">48</span>  k get po -n alpha
</span></span><span class="line"><span class="cl">   <span class="m">49</span>  k -n alpha describe po alpha-mysql-78f449b485-vvrqg
</span></span><span class="line"><span class="cl">   <span class="m">50</span>  k -n alpha get pvc
</span></span><span class="line"><span class="cl">   <span class="m">51</span>  k -n alpha get pvc,pv
</span></span><span class="line"><span class="cl">   <span class="m">52</span>  k -n alpha edit deploy alpha-mysql
</span></span><span class="line"><span class="cl">   <span class="m">53</span>  k get po -n alpha
</span></span><span class="line"><span class="cl">   <span class="m">54</span>  k -n alpha get deploy,po
</span></span><span class="line"><span class="cl">   <span class="m">55</span>  k -n alpha describe po alpha-mysql-67cb6c85-z7f8x 
</span></span><span class="line"><span class="cl">   <span class="m">56</span>  k -n alpha get po
</span></span><span class="line"><span class="cl">   <span class="m">57</span>  k -n alpha delete po alpha-mysql-67cb6c85-z7f8x
</span></span><span class="line"><span class="cl">   <span class="m">58</span>  k -n alpha delete po alpha-mysql-78f449b485-vvrqg
</span></span><span class="line"><span class="cl">   <span class="m">59</span>  k get po
</span></span><span class="line"><span class="cl">   <span class="m">60</span>  k -n alpha get po
</span></span><span class="line"><span class="cl">   <span class="m">61</span>  k get po -n kube-system
</span></span><span class="line"><span class="cl">   <span class="m">62</span>  k -n admin1401 run secret-1401 --image busybox -- sleep <span class="m">4800</span> --dry-run<span class="o">=</span>client -o yaml &gt; 7.yaml
</span></span><span class="line"><span class="cl">   <span class="m">63</span>  vi 7.yaml 
</span></span><span class="line"><span class="cl">   <span class="m">64</span>  k -n admin1401 get po secret-1401
</span></span><span class="line"><span class="cl">   <span class="m">65</span>  k -n admin1401 edit po secret-1401
</span></span><span class="line"><span class="cl">   <span class="m">66</span>  k replace --force --grace-period<span class="o">=</span><span class="m">0</span> -f /tmp/kubectl-edit-1158032255.yaml
</span></span><span class="line"><span class="cl">   <span class="m">67</span>  k -n admin1401 edit po secret-1401
</span></span><span class="line"><span class="cl">   <span class="m">68</span>  vi /tmp/kubectl-edit-1158032255.yaml
</span></span><span class="line"><span class="cl">   <span class="m">69</span>  k replace --force --grace-period<span class="o">=</span><span class="m">0</span> -f /tmp/kubectl-edit-1158032255.yaml
</span></span><span class="line"><span class="cl">   <span class="m">70</span>  k get po -n admin1401
</span></span><span class="line"><span class="cl">   <span class="m">71</span>  <span class="nb">history</span>
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<h4 id="q1">Q1</h4>
<p>Here is the solution for this task. Please note that the output of these commands have not been added here.</p>
<p>To seamlessly transition from Kubernetes v1.30 to v1.31 and gain access to the packages specific to the desired Kubernetes minor version, follow these essential steps during the upgrade process. This ensures that your environment is appropriately configured and aligned with the features and improvements introduced in Kubernetes v1.31.</p>
<p>On the <code>controlplane</code> node:</p>
<p>Use any text editor you prefer to open the file that defines the Kubernetes apt repository.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">vim /etc/apt/sources.list.d/kubernetes.list
</span></span></code></pre></td></tr></table>
</div>
</div><p>Update the version in the URL to the next available minor release, i.e v1.31.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">deb <span class="o">[</span>signed-by<span class="o">=</span>/etc/apt/keyrings/kubernetes-apt-keyring.gpg<span class="o">]</span> https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /
</span></span></code></pre></td></tr></table>
</div>
</div><p>After making changes, save the file and exit from your text editor. Proceed with the next instruction.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl drain controlplane --ignore-daemonsets
</span></span><span class="line"><span class="cl">apt update
</span></span><span class="line"><span class="cl">apt-cache madison kubeadm
</span></span></code></pre></td></tr></table>
</div>
</div><p>Based on the version information displayed by <code>apt-cache madison</code>, it indicates that for Kubernetes version <code>1.31.0</code>, the available package version is <code>1.31.0-1.1</code>. Therefore, to install kubeadm for Kubernetes <code>v1.31.0</code>, use the following command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apt-get install <span class="nv">kubeadm</span><span class="o">=</span>1.31.0-1.1
</span></span></code></pre></td></tr></table>
</div>
</div><p>Run the following command to upgrade the Kubernetes cluster.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubeadm upgrade plan v1.31.0
</span></span><span class="line"><span class="cl">kubeadm upgrade apply v1.31.0
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, upgrade the version and restart Kubelet. Also, mark the node (in this case, the &ldquo;controlplane&rdquo; node) as schedulable.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apt-get install <span class="nv">kubelet</span><span class="o">=</span>1.31.0-1.1
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart kubelet
</span></span><span class="line"><span class="cl">kubectl uncordon controlplane
</span></span></code></pre></td></tr></table>
</div>
</div><p>Before draining <code>node01</code>, if the controlplane gets taint during an upgrade, we have to remove it.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># Identify the taint first. </span>
</span></span><span class="line"><span class="cl">kubectl describe node controlplane <span class="p">|</span> grep -i taint
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Remove the taint with help of &#34;kubectl taint&#34; command.</span>
</span></span><span class="line"><span class="cl">kubectl taint node controlplane node-role.kubernetes.io/control-plane:NoSchedule-
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Verify it, the taint has been removed successfully.  </span>
</span></span><span class="line"><span class="cl">kubectl describe node controlplane <span class="p">|</span> grep -i taint
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, drain the <code>node01</code> as follows: -</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl drain node01 --ignore-daemonsets
</span></span></code></pre></td></tr></table>
</div>
</div><p><code>SSH</code> to the <code>node01</code> and perform the below steps as follows: -</p>
<p>Use any text editor you prefer to open the file that defines the Kubernetes apt repository.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">vim /etc/apt/sources.list.d/kubernetes.list
</span></span></code></pre></td></tr></table>
</div>
</div><p>Update the version in the URL to the next available minor release, i.e v1.31.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">deb <span class="o">[</span>signed-by<span class="o">=</span>/etc/apt/keyrings/kubernetes-apt-keyring.gpg<span class="o">]</span> https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /
</span></span></code></pre></td></tr></table>
</div>
</div><p>After making changes, save the file and exit from your text editor. Proceed with the next instruction.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apt update
</span></span><span class="line"><span class="cl">apt-cache madison kubeadm
</span></span></code></pre></td></tr></table>
</div>
</div><p>Based on the version information displayed by <code>apt-cache madison</code>, it indicates that for Kubernetes version <code>1.31.0</code>, the available package version is <code>1.31.0-1.1</code>. Therefore, to install kubeadm for Kubernetes <code>v1.31.0</code>, use the following command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apt-get install <span class="nv">kubeadm</span><span class="o">=</span>1.31.0-1.1
</span></span><span class="line"><span class="cl"><span class="c1"># Upgrade the node </span>
</span></span><span class="line"><span class="cl">kubeadm upgrade node
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, upgrade the version and restart Kubelet.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">apt-get install <span class="nv">kubelet</span><span class="o">=</span>1.31.0-1.1
</span></span><span class="line"><span class="cl">systemctl daemon-reload
</span></span><span class="line"><span class="cl">systemctl restart kubelet
</span></span></code></pre></td></tr></table>
</div>
</div><p>To exit from the specific node, type <code>exit</code> or <code>logout</code> on the terminal.</p>
<p>Back on the <code>controlplane</code> node: -</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl uncordon node01
</span></span><span class="line"><span class="cl">kubectl get pods -o wide <span class="p">|</span> grep gold <span class="c1"># make sure this is scheduled on a node</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q2">Q2</h4>
<p>Run the below command to get the correct output:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl -n admin2406 get deployment -o custom-columns<span class="o">=</span>DEPLOYMENT:.metadata.name,CONTAINER_IMAGE:.spec.template.spec.containers<span class="o">[]</span>.image,READY_REPLICAS:.status.readyReplicas,NAMESPACE:.metadata.namespace --sort-by<span class="o">=</span>.metadata.name &gt; /opt/admin2406_data
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q3">Q3</h4>
<p>Make sure the port for the <code>kube-apiserver</code> is correct. So for this change port from <code>4380</code> to <code>6443</code>.</p>
<p>Run the below command to know the cluster information:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl cluster-info --kubeconfig /root/CKA/admin.kubeconfig
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q4">Q4</h4>
<h3 id="deployment-creation-and-update-with-annotation">Deployment Creation and Update with Annotation</h3>
<p>Follow these steps to create a deployment, update its image, and record the change using annotations.</p>
<h3 id="step-1-create-the-deployment">Step 1: Create the Deployment</h3>
<p>Use the <code>kubectl create</code> command to create a deployment named <code>nginx-deploy</code> with the <code>nginx:1.16</code> image.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl create deployment nginx-deploy --image<span class="o">=</span>nginx:1.16
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="step-2-update-the-deployment-image">Step 2: Update the Deployment Image</h3>
<p>Update the <code>nginx-deploy</code> deployment to use the <code>nginx:1.17</code> image.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl <span class="nb">set</span> image deployment/nginx-deploy <span class="nv">nginx</span><span class="o">=</span>nginx:1.17
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="step-3-annotate-the-deployment-to-record-the-change">Step 3: Annotate the Deployment to Record the Change</h3>
<p>Manually annotate the deployment to log the change, replacing the functionality of the deprecated <code>--record</code> option.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl annotate deployment nginx-deploy kubernetes.io/change-cause<span class="o">=</span><span class="s2">&#34;Updated nginx image to 1.17&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>This annotation acts as a record of the image update.</p>
<h4 id="q5">Q5</h4>
<p>Use the command <code>kubectl describe</code> and try to fix the issue.</p>
<p>Solution manifest file to create a pvc called <code>mysql-alpha-pvc</code> as follows:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">PersistentVolumeClaim</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">mysql-alpha-pvc</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">alpha</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">accessModes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="l">ReadWriteOnce</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">resources</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">requests</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">storage</span><span class="p">:</span><span class="w"> </span><span class="l">1Gi</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">storageClassName</span><span class="p">:</span><span class="w"> </span><span class="l">slow</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h6 id="q6">Q6</h6>
<p>Take a help of command <code>etcdctl snapshot save --help</code> options.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span>
</span></span><span class="line"><span class="cl">etcdctl snapshot save <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cacert<span class="o">=</span>/etc/kubernetes/pki/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cert<span class="o">=</span>/etc/kubernetes/pki/etcd/server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--key<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--endpoints<span class="o">=</span>127.0.0.1:2379 /opt/etcd-backup.db
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q7">Q7</h4>
<p>Use the command <code>kubectl run</code> to create a pod definition file. Add secret volume and update container name in it.</p>
<p>Alternatively, run the following command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl run secret-1401 -n admin1401 --image<span class="o">=</span>busybox --dry-run<span class="o">=</span>client -oyaml --command -- sleep <span class="m">4800</span> &gt; admin.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><p>Add the <code>secret</code> volume and mount path to create a pod called <code>secret-1401</code> in the <code>admin1401</code> namespace as follows:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nn">---</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">creationTimestamp</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l">secret-1401</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secret-1401</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">namespace</span><span class="p">:</span><span class="w"> </span><span class="l">admin1401</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secret-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># secret volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">secret</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">secretName</span><span class="p">:</span><span class="w"> </span><span class="l">dotfile-secret</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">command</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="l">sleep</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="s2">&#34;4800&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">busybox</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secret-admin</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># volumes&#39; mount path</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">volumeMounts</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">secret-volume</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">readOnly</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">mountPath</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;/etc/secret-volume&#34;</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><hr>
<h3 id="269270-mock-exam---1">269/270. Mock Exam - 1</h3>
<p>100% at the first attempt! Well-done.</p>
<h3 id="271272-mock-exam---2-">271/272. Mock Exam - 2 ğŸš§ğŸš§ğŸš§</h3>
<p>60% at the first attempt</p>
<h4 id="q1---solution">Q1 - Solution:</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl"><span class="c1"># take a backup</span>
</span></span><span class="line"><span class="cl"><span class="nb">export</span> <span class="nv">ETCDCTL_API</span><span class="o">=</span><span class="m">3</span>
</span></span><span class="line"><span class="cl">etcdctl snapshot save <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--endpoints 127.0.0.1:2379 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cacert /etc/kubernetes/pki/etcd/ca.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--cert /etc/kubernetes/pki/etcd/server.crt <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>--key<span class="o">=</span>/etc/kubernetes/pki/etcd/server.key  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>/opt/etcd-backup.db
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">cat /etc/kubernetes/manifests/etcd.yaml <span class="p">|</span> grep file
</span></span><span class="line"><span class="cl">...
</span></span><span class="line"><span class="cl">--cacert &lt;the trusted ca file&gt;
</span></span><span class="line"><span class="cl">--cert &lt;the cert file&gt;
</span></span><span class="line"><span class="cl">--key &lt;the key file&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q7---solution">Q7 - Solution:</h4>
<p>Use the command <code>kubectl run</code> and create a nginx pod and busybox pod. Resolve it, nginx service and its pod name from <code>busybox</code> pod.</p>
<p>To create a pod <code>nginx-resolver</code> and expose it internally:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl run nginx-resolver --image<span class="o">=</span>nginx
</span></span><span class="line"><span class="cl">kubectl expose pod nginx-resolver --name<span class="o">=</span>nginx-resolver-service --port<span class="o">=</span><span class="m">80</span> --target-port<span class="o">=</span><span class="m">80</span> --type<span class="o">=</span>ClusterIP
</span></span></code></pre></td></tr></table>
</div>
</div><p>To create a pod <code>test-nslookup</code>. Test that you are able to look up the service and pod names from within the cluster:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl run test-nslookup --image<span class="o">=</span>busybox:1.28 --rm -it --restart<span class="o">=</span>Never -- nslookup nginx-resolver-service
</span></span><span class="line"><span class="cl">kubectl run test-nslookup --image<span class="o">=</span>busybox:1.28 --rm -it --restart<span class="o">=</span>Never -- nslookup nginx-resolver-service &gt; /root/CKA/nginx.svc
</span></span><span class="line"><span class="cl"><span class="c1"># --rm -it --restart=Never</span>
</span></span><span class="line"><span class="cl"><span class="c1"># -- nslookup &lt;name-of-the-service-we-just-created&gt;.&lt;ns&gt;.&lt;svc&gt;.&lt;rootdomain&gt;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Get the IP of the <code>nginx-resolver</code> pod and replace the dots(.) with hyphon(-) which will be used below.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get pod nginx-resolver -o wide
</span></span><span class="line"><span class="cl">kubectl run test-nslookup --image<span class="o">=</span>busybox:1.28 --rm -it --restart<span class="o">=</span>Never -- nslookup &lt;P-O-D-I-P.default.pod&gt; &gt; /root/CKA/nginx.pod
</span></span><span class="line"><span class="cl"><span class="c1"># k exec busybox -- nslookup 10-50-192-4.default.cluster.local &gt; /root/CKA/nginx.pod</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q8---solution">Q8 - Solution:</h4>
<p>To create a static pod called <code>nginx-critical</code> by using below command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl run nginx-critical --image<span class="o">=</span>nginx --dry-run<span class="o">=</span>client -o yaml &gt; static.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><p>Copy the contents of this file or use <code>scp</code> command to transfer this file from <code>controlplane</code> to <code>node01</code> node.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@controlplane:~# scp static.yaml node01:/root/
</span></span></code></pre></td></tr></table>
</div>
</div><p>To know the IP Address of the <code>node01</code> node:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@controlplane:~# kubectl get nodes -o wide
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Perform SSH</span>
</span></span><span class="line"><span class="cl">root@controlplane:~# ssh node01
</span></span><span class="line"><span class="cl">OR
</span></span><span class="line"><span class="cl">root@controlplane:~# ssh &lt;IP of node01&gt;
</span></span></code></pre></td></tr></table>
</div>
</div><p>On <code>node01</code> node:</p>
<p>Check if static pod directory is present which is <code>/etc/kubernetes/manifests</code>, if it&rsquo;s not present then create it.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@node01:~# mkdir -p /etc/kubernetes/manifests
</span></span></code></pre></td></tr></table>
</div>
</div><p>Add that complete path to the <code>staticPodPath</code> field in the kubelet <code>config.yaml</code> file.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@node01:~# vi /var/lib/kubelet/config.yaml
</span></span></code></pre></td></tr></table>
</div>
</div><p>now, move/copy the static.yaml to path <code>/etc/kubernetes/manifests/</code>.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@node01:~# cp /root/static.yaml /etc/kubernetes/manifests/
</span></span></code></pre></td></tr></table>
</div>
</div><p>Go back to the <code>controlplane</code> node and check the status of static pod:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">root@node01:~# <span class="nb">exit</span>
</span></span><span class="line"><span class="cl"><span class="nb">logout</span>
</span></span><span class="line"><span class="cl">root@controlplane:~# kubectl get pods 
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="273274-mock-exam---3-">273/274. Mock Exam - 3 ğŸš§</h3>
<p>40% scored at the first attempt</p>
<p>74% scored at the second attempt</p>
<h4 id="q2-1">Q2</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">kubectl get nodes -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items[*].status.addresses[?(@.type==&#34;InternalIP&#34;)].address}&#39;</span> &gt; /root/CKA/node_ips
</span></span><span class="line"><span class="cl"><span class="c1"># expected output should look like below</span>
</span></span><span class="line"><span class="cl">192.5.232.8 192.5.232.11
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># This is considered bad answer</span>
</span></span><span class="line"><span class="cl">k get no -o <span class="nv">jsonpath</span><span class="o">=</span><span class="s1">&#39;{.items[*].status.addresses[?(@.type==&#34;InternalIP&#34;)]}&#39;</span> <span class="p">|</span> jq .
</span></span><span class="line"><span class="cl"><span class="nb">echo</span> <span class="s2">&#34;InternalIP of controlplane 192.5.232.8 InternalIP of node01 192.5.232.11&#34;</span> &gt; /root/CKA/node_ips
</span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q3-">Q3 âœ…</h4>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">creationTimestamp</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">labels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l">multi-pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">multi-pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">alpha</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">env</span><span class="p">:</span><span class="w">           </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">name  </span><span class="w"> </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">alpha</span><span class="w"> </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">busybox</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">beta</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="c"># command: [ &#34;/bin/sh&#34;, &#34;-c&#34;, &#34;sleep 4800&#34; ]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="s2">&#34;sleep&#34;</span><span class="p">,</span><span class="w"> </span><span class="s2">&#34;4800&#34;</span><span class="w"> </span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">env</span><span class="p">:</span><span class="w">          </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">name </span><span class="w"> </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">value</span><span class="p">:</span><span class="w"> </span><span class="l">beta</span><span class="w"> </span><span class="c">#</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">dnsPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">ClusterFirst</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">restartPolicy</span><span class="p">:</span><span class="w"> </span><span class="l">Always</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">status</span><span class="p">:</span><span class="w"> </span>{}<span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="l">~                </span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h5 id="q5-1">Q5</h5>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">networking.k8s.io/v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">NetworkPolicy</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">ingress-to-nptest</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">podSelector</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">matchLabels</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">run</span><span class="p">:</span><span class="w"> </span><span class="l">np-test-1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">policyTypes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="l">Ingress</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">ingress</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c"># - from:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c">#   - podSelector:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c">#       matchLabels:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c">#         run: np-test-1  You don&#39;t need these</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c"># - from:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"> </span><span class="c">#   - podSelector: {}     This too you don&#39;t need</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">ports</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span>- <span class="nt">protocol</span><span class="p">:</span><span class="w"> </span><span class="l">TCP</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span><span class="nt">port</span><span class="p">:</span><span class="w"> </span><span class="m">80</span><span class="w">
</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="q9-">Q9 âœ…</h4>
<p>Unknown error; <code> kubelet  Error: failed to create containerd task: failed to create shim task: OCI runtime create failed: runc create failed: unable to start container process: exec: &quot;kube-contro1ler-manager&quot;: executable file not found in $PATH: unknown</code></p>
<h5 id="solution">Solution:</h5>
<p>Use the command <code>kubectl scale</code> to increase the replica count to 3.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl scale deploy nginx-deploy --replicas<span class="o">=</span><span class="m">3</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The <code>controller-manager</code> is responsible for scaling up pods of a replicaset. If you inspect the control plane components in the <code>kube-system</code> namespace, you will see that the <code>controller-manager</code> is not running.</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get pods -n kube-system
</span></span></code></pre></td></tr></table>
</div>
</div><p>The command running inside the <code>controller-manager</code> pod is incorrect.
After fix all the values in the file and wait for <code>controller-manager</code> pod to restart.</p>
<p>Alternatively, you can run <code>sed</code> command to change all values at once:</p>
<pre tabindex="0"><code>sed -i &#39;s/kube-contro1ler-manager/kube-controller-manager/g&#39; /etc/kubernetes/manifests/kube-controller-manager.yaml
</code></pre><p>This will fix the issues in <code>controller-manager</code> yaml file.</p>
<p>At last, inspect the deployment by using below command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">kubectl get deploy
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<h3 id="notes-on-mousepad">Notes on Mousepad</h3>
<pre tabindex="0"><code>vi /etc/vim/vimrc   
set ts=2 sw=2 sts=2 ai
:wq

export do=&#39;--dry-run=client -o yaml&#39;
export fgp=&#39;--force --grace-period=0&#39;
</code></pre></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2024-11-30</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://localhost:1313/posts/cncf-kubestronaut-02cka/" data-hashtag="Cloud Native"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://localhost:1313/posts/cncf-kubestronaut-02cka/" data-title="Kubestronaut 02 CKA"><i data-svg-src="/lib/simple-icons/icons/line.min.svg" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="/tags/cloud-native/">Cloud Native</a>,&nbsp;<a href="/tags/kubernetes/">Kubernetes</a>,&nbsp;<a href="/tags/cka/">CKA</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/posts/kong-hq-academy/" class="prev" rel="prev" title="Kong Academy ç¶²é—œå­¸ç¿’ç­†è¨˜"><i class="fas fa-angle-left fa-fw" aria-hidden="true"></i>Kong Academy ç¶²é—œå­¸ç¿’ç­†è¨˜</a>
            <a href="/posts/kk_learn_by_doing_apache_kafka/" class="next" rel="next" title="Apache Kafka åšä¸­å­¸">Apache Kafka åšä¸­å­¸<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">strict with yourself; lenient with others.</div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2024</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank"></a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/twemoji/twemoji.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"twemoji":true};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
